{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from load_model_ver3 import load_model\n",
    "from load_model_barlowtwins import load_barlowtwins_model\n",
    "\n",
    "from rn50_auxiliary_dm import rn50_auxiliary_dm\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d20eee-0504-444a-a132-2e0697b60f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_model import load_model\n",
    "from rn50_auxiliary_dm import rn50_auxiliary_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebb535-e0e1-4611-b971-cd577e3f1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b00ce3-f23f-42d6-8eee-5d038c59e014",
   "metadata": {
    "tags": []
   },
   "source": [
    "# extract feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890e307-3e2f-4e8a-813b-6ab47e4964c0",
   "metadata": {},
   "source": [
    "## extract feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment list summarized\n",
    "\n",
    "exp_names_list_textures = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_color_texture_resized/id0',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_color_texture_resized/id1',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_gray_downsampled/camel_colored_gray',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_gray_downsampled/elephant_colored_gray',\n",
    "    \n",
    "    # '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_downsampled/camel_colored',\n",
    "    # '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_downsampled/elephant_colored',\n",
    "]\n",
    "\n",
    "exp_names_list_basics = [\n",
    "    # 1. Josh - Elias/Neptune neutral\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_elias',\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_neptune',\n",
    "\n",
    "    # 2. Seojin - Elias/Neptune neutral\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_neptune/vbsle151_neptune_neutral',\n",
    "\n",
    "    # 3a. Josh - Sophie/Praneeth\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_sophie_praneeth/20230406_Var6vbsl_set0_im151_praneeth_dur200ms_lab',\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_sophie_praneeth/20230406_Var6vbsl_set0_im151_sophie_dur200ms_lab',\n",
    "\n",
    "    # 3b. Josh - Basel - texture\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood/20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_dur200ms_lab',\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood/20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_dur200ms_lab',\n",
    "\n",
    "    # 3c.Josh - Basel - no texture\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_notexture_dur200ms_lab',\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_notexture_dur200ms_lab',\n",
    "\n",
    "    # 3d. Josh - Camel/Elephant\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_camel',\n",
    "    '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant',\n",
    "\n",
    "    # 3e.     \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_dog_horse/vbsle_151_dog', \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_dog_horse/vbsle_151_horse',\n",
    "\n",
    "    # textured elais/neptune\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/textured_elias_grayscaled', \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/textured_neptune_grayscaled',\n",
    "\n",
    "]\n",
    "\n",
    "exp_names_list_imagenet = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/shark151/shark1',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/shark151/shark2',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/bird151/bird1',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/bird151/bird2',\n",
    "    \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/vehicle151/bike',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/vehicle151/car'\n",
    "]\n",
    "\n",
    "exp_names_list_GFR = [\n",
    "    # 1. Elias - Neptune\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_neptune/vbsle151_neptune_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_seojin/vbsle151_seojin_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_dan/vbsle151_dan_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sreyas/vbsle151_sreyas_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_younah/vbsle151_younah_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_ashley/vbsle151_ashley_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_kedar/vbsle151_kedar_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_josh/vbsle151_josh_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_ani/vbsle151_ani_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_tony/vbsle151_tony_neutral',\n",
    "]\n",
    "\n",
    "exp_names_list_GFR_texture_colorbg = [\n",
    "    # 1. Elias - Neptune\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_neptune_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_seojin_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_sophie_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_dan_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_sreyas_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_younah_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_ashley_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_kedar_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_josh_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_ani_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_tony_neutral',\n",
    "]\n",
    "exp_names_list_GFR_texture_graybg = [\n",
    "    # 1. Elias - Neptune\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_neptune_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_seojin_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_sophie_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_dan_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_sreyas_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_younah_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_ashley_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_kedar_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_josh_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_ani_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_tony_neutral',\n",
    "]\n",
    "\n",
    "exp_names_list_GER_sophie = [ # Sophie emotion 4\n",
    "    # 1. n-h\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_disgust_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_sophie/vbsle151_sophie_surprise_4',\n",
    "   ]\n",
    "\n",
    "exp_names_list_GER_elias  = [ # elias emotion 4\n",
    "    # 1. n-h\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_disgust_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/vbsle151_elias_surprise_4',\n",
    "    ]\n",
    "\n",
    "exp_names_list_GER_elias_texture_colorbg = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_disgust_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_elias_surprise_4',\n",
    "]\n",
    "\n",
    "exp_names_list_GER_elias_texture_graybg = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_disgust_4'\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_elias_surprise_4',\n",
    "]\n",
    "\n",
    "exp_names_list_lfw = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell/Bush',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell/Powell',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell_inverted/Bush',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell_inverted/Powell',\n",
    "]\n",
    "\n",
    "exp_names_list_ytface = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Stanca',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Beard',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Kennedy',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Macdonald',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names_list_basel = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id10',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id11',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id12',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id13',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id14',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id15',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id16',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id17',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id18',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id19',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id20',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id21',\n",
    "]\n",
    "\n",
    "exp_names_list_basel_texture_colorbg = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id10',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id11',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id12',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id13',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id14',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id15',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id16',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id17',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id18',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id19',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id20',\n",
    "'/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id21',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b652cb-5949-4c6e-9f60-416e171ad265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard models \n",
    "exp_names_list = exp_names_list_GFR\n",
    "\n",
    "def update_state_dict_keys(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        # print(k)\n",
    "        # if k.startswith('module.shared_layers.'):\n",
    "        #     new_key = k.replace('module.shared_layers.', 'module.')\n",
    "        # print(k)\n",
    "        if k.startswith('module.'):\n",
    "            new_key = k.replace('module.', 'module.module.')\n",
    "            # print(new_key)\n",
    "        # else:\n",
    "        #     new_key = 'module.' + k if not k.startswith('module.') else k\n",
    "        new_state_dict[new_key] = v\n",
    "        # print(\"new\", new_key)\n",
    "    return new_state_dict\n",
    "\n",
    "def adjust_fc_layer(model, state_dict):\n",
    "    for key in state_dict.keys():\n",
    "        if 'fc.weight' in key:\n",
    "            final_layer_key = key\n",
    "            break\n",
    "    num_classes = state_dict[final_layer_key].shape[0]\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "# Pick the experiment set\n",
    "# model_names_list=[\n",
    "# # 'off_the_shelf_barlowtwins_finetune_7way_EM_sophie_colorbg_seed77_model_best',\n",
    "# # 'off_the_shelf_barlowtwins_finetune_7way_EM_dan_colorbg_seed77__model_best',\n",
    "# # 'off_the_shelf_barlowtwins_finetune_7way_EM_kedar_colorbg_seed77__model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_4way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_4way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_4way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_6way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_6way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_6way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_8way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_8way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_8way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_10way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_10way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_10way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_12way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_12way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_12way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "# ]\n",
    "# model_names_list = [\n",
    "#     # 'off_the_shelf_barlowtwins_seojin_dan_epochs50',\n",
    "#     'off_the_shelf_barlowtwins_2way_seojin_sophie',\n",
    "#     'off_the_shelf_barlowtwins_2way_sophie_kedar',\n",
    "#     'off_the_shelf_barlowtwins_finetune_4way_SSKD',\n",
    "#     # 'off_the_shelf_barlowtwins_finetune_6way_final',\n",
    "#     # 'off_the_shelf_barlowtwins_ID_8way_epochs50',\n",
    "\n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_2way_seojin_dan',\n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_seojin', \n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_kedar',\n",
    "#     # 'off_the_shelf_barlowtwins_texture_colorbg_4way',\n",
    "#     # 'off_the_shelf_barlowtwins_texture_colorbg_6way',\n",
    "#     # 'off_the_shelf_barlowtwins_ID_8way_colorbg_epochs50',\n",
    "\n",
    "#     # 'off_the_shelf_barlowtwins_finetune_texture_colorbg_em_neutral_anger',\n",
    "#     # 'off_the_shelf_barlowtwins_finetune_texture_colorbg_em_4way_NHAS',\n",
    "#     # 'off_the_shelf_barlowtwins_finetune_texture_colorbg_em_6way_excl_fear'\n",
    "# ]\n",
    "model_names_list = ['barlowtwins_finetune_7way_EM_seojin_seed77__model_best'\n",
    "                    ]\n",
    "filename_postfix = ''\n",
    "save_label = False\n",
    "\n",
    "for model_name in model_names_list:\n",
    "    # flatten & subsample for previous layers of resnet50\n",
    "    if 'layer' in model_name or \"subsampled\" in model_name:\n",
    "        if \"layerC2\" in model_name and \"layerC2_subsampled\" not in model_name:\n",
    "            subsample = False\n",
    "        else:\n",
    "            subsample = True\n",
    "    else:\n",
    "        subsample = False\n",
    "    \n",
    "    # load model\n",
    "    model = load_model(model_name)\n",
    "    model.eval()\n",
    "    \n",
    "    # add hook\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    if 'simplecnn' in model_name:\n",
    "        model.fc2.register_forward_hook(get_activation('feats'))\n",
    "    elif 'alexnet' in model_name:\n",
    "        if 'layer4' in model_name:\n",
    "            print(\"add hook in layer4\")\n",
    "            model.features[4].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer8' in model_name:\n",
    "            print(\"add hook in layer8\")\n",
    "            model.features[8].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer12' in model_name:\n",
    "            print(\"add hook in layer12\")\n",
    "            model.features[12].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layerC2' in model_name:\n",
    "            model.classifier[2].register_forward_hook(get_activation('feats'))\n",
    "        else: # final layer\n",
    "            model.classifier[5].register_forward_hook(get_activation('feats'))\n",
    "    elif model_name == 'vgg16':\n",
    "        model.classifier[4].register_forward_hook(get_activation('feats'))\n",
    "    elif model_name == 'vggface':\n",
    "        model.fc7.register_forward_hook(get_activation('feats'))\n",
    "    elif 'onlyDM' in model_name:\n",
    "        model.depth_predictor.encoder[4].register_forward_hook(get_activation('feats'))\n",
    "        # model.depth_predictor.decoder[30].register_forward_hook(get_activation('feats'))\n",
    "        # model.depth_predictor.encoder[6].register_forward_hook(get_activation('feats'))\n",
    "    elif 'head' in model_name :\n",
    "        model.module.backbone.avgpool.register_forward_hook(get_activation('feats'))\n",
    "    elif 'remapping' in model_name :\n",
    "        model.module.backbone.avgpool.register_forward_hook(get_activation('feats'))\n",
    "    else: # resnet50\n",
    "        if 'layer1' in model_name:\n",
    "            print(\"add hook in layer1\")\n",
    "            model.layer1.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer2' in model_name:\n",
    "            print(\"add hook in layer2\")\n",
    "            model.layer2.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer3' in model_name:\n",
    "            print(\"add hook in layer3\")\n",
    "            model.layer3.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer4_no_pooling' in model_name:\n",
    "            print(\"add hook in layer4_no_pooling\")\n",
    "            model.layer4.register_forward_hook(get_activation('feats'))\n",
    "        else:\n",
    "            model.fc.register_forward_hook(get_activation('feats'))\n",
    "        \n",
    "    # load data\n",
    "    for exp_index, exp_name in enumerate(exp_names_list):\n",
    "        print(model_name, exp_name)\n",
    "        valdir = exp_name\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        _trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "        ## read & sort img filenames\n",
    "        all_filenames = []\n",
    "        # read img filenames\n",
    "        for filename in os.listdir(valdir):\n",
    "            if filename[-4:]=='.png':\n",
    "                # for basal dataset / new controled exps\n",
    "                assert(filename[:13]=='canvasvisible' or filename[:8]=='trialnum')\n",
    "                all_filenames.append(filename)\n",
    "            \n",
    "                \n",
    "        ## sort img filenames -> fix bug of sorting by value\n",
    "        # for basal dataset / new controled exps\n",
    "        if all_filenames[0][:13]=='canvasvisible':\n",
    "            all_filenames = sorted(all_filenames, key=lambda x: int(x[:-4].split(\"_\")[-1][5:]))\n",
    "        elif all_filenames[0][:8]=='trialnum':\n",
    "            all_filenames = sorted(all_filenames, key=lambda x: int(x[8:-4]))\n",
    "        else:\n",
    "            assert False, 'unsupported filename'\n",
    "        print(len(all_filenames))\n",
    "        \n",
    "        # extract feats\n",
    "        FEATS = []\n",
    "        LABELS = []\n",
    "        # loop through batches\n",
    "        for idx, filename in enumerate(all_filenames):\n",
    "            # read & transform img\n",
    "            img = Image.open(os.path.join(valdir, filename)).convert(\"RGB\")\n",
    "            img_trans = _trans(img)\n",
    "            # move to device\n",
    "            inputs = img_trans.unsqueeze(0).cuda()\n",
    "            # forward pass [with feature extraction]\n",
    "            preds = model(inputs)\n",
    "            # preds = model.forward_single(inputs)\n",
    "            # add feats and preds to lists\n",
    "            # if 'simplecnn' in model_name:\n",
    "            #     activation['feats'] = F.relu(activation['feats'])\n",
    "            FEATS.append(activation['feats'].cpu().squeeze().unsqueeze(0).numpy())\n",
    "            if save_label:\n",
    "                LABELS.append(outputs.cpu().squeeze().unsqueeze(0).numpy())\n",
    "        FEATS = np.concatenate(FEATS, axis=0)\n",
    "        if save_label:\n",
    "            LABELS = np.concatenate(LABELS, axis=0)\n",
    "        print(FEATS.shape)\n",
    "        \n",
    "        if subsample:\n",
    "            FEATS = FEATS.reshape([FEATS.shape[0], -1])\n",
    "            if exp_index == 0: # use the same subset indexes for all exp\n",
    "                # sampled_indexes = np.random.permutation()\n",
    "                # sampled_indexes = np.random.permutation(FEATS.shape[1])[:2048]\n",
    "                sampled_indexes = np.random.choice(FEATS.shape[1], 2048, replace=False)\n",
    "            FEATS = FEATS[:, sampled_indexes]\n",
    "            print(f\"subsample to 2048 feats, {FEATS.shape}\")\n",
    "        \n",
    "        # save feats\n",
    "        filename = exp_name+'_'+model_name+filename_postfix+'_fc.pth'\n",
    "        torch.save(FEATS, filename)\n",
    "        print(f'saving to {filename}\\n')\n",
    "        \n",
    "        if save_label:\n",
    "            filename = exp_name+'_'+model_name+filename_postfix+'_label.pth'\n",
    "            torch.save(LABELS, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879c730-90b7-4169-a512-e3c0a66cb5de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## extract pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) exp_names_list_GER_21_elias\n",
    "useful_stats = {}\n",
    "\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/'\n",
    "]\n",
    "\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsle151_elias_neutral', 'vbsle151_elias_happiness_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_sadness_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_disgust_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_sadness_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_disgust_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_disgust_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_disgust_4', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_disgust_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_disgust_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_fear_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_fear_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_anger_4', 'vbsle151_elias_surprise_4']\n",
    "\n",
    "                ]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10, 11, 12, 13,14, 15, 16, 17, 18, 19, 20]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f8f3c-29b8-4264-92bd-be1073f9749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract pixels\n",
    "\n",
    "# SL\n",
    "# updated loc\n",
    "exp_names_list = ['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_elias',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_neptune']\n",
    "\n",
    "exp_names_list = [\n",
    "                  # AppleFace Elias/Neptune 151 (w/ inverse contrast)\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_elias',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_neptune',\n",
    "\n",
    "                  # AppleFace Elias/Neptune 101 \n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_101/20210920_Var6vbsl_set0_im101_elias',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_101/20210920_Var6vbsl_set0_im101_neptune', \n",
    "\n",
    "                  # OOD AppleFace Sophie/Praneeth\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_sophie_praneeth/20230406_Var6vbsl_set0_im151_praneeth_dur200ms_lab',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_sophie_praneeth/20230406_Var6vbsl_set0_im151_sophie_dur200ms_lab',\n",
    "                  \n",
    "                  # OOD Basel (w/ texture)\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood/20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_dur200ms_lab',                  \n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood/20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_dur200ms_lab',\n",
    "\n",
    "                  # OOD Basel \n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_notexture_dur200ms_lab',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_notexture_dur200ms_lab',\n",
    "                  \n",
    "                  # OOD Object camel/elephant\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_camel',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant',\n",
    "                  \n",
    "                  # OOD Object camel/elephant\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20220412_Var6vbsp_set1_im101_camel',\n",
    "                  '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20220412_Var6vb_same_as_camel_sp_set1_im101_elephant']\n",
    "\n",
    "for exp_name in exp_names_list:\n",
    "    valdir = exp_name\n",
    "\n",
    "    ## read & sort img filenames\n",
    "    all_filenames = []\n",
    "    # read img filenames\n",
    "    for filename in os.listdir(valdir):\n",
    "        if filename[-4:]=='.png':\n",
    "            # for basal dataset / new controled exps\n",
    "            assert(filename[:13]=='canvasvisible' or filename[:8]=='trialnum')\n",
    "            all_filenames.append(filename)\n",
    "\n",
    "    ## sort img filenames -> fix bug of sorting by value\n",
    "    # for basal dataset / new controled exps\n",
    "    if all_filenames[0][:13]=='canvasvisible':\n",
    "        all_filenames = sorted(all_filenames, key=lambda x: int(x[:-4].split(\"_\")[-1][5:]))\n",
    "    elif all_filenames[0][:8]=='trialnum':\n",
    "        all_filenames = sorted(all_filenames, key=lambda x: int(x[8:-4]))\n",
    "    else:\n",
    "        assert False, 'unsupported filename'\n",
    "    print(len(all_filenames))\n",
    "    \n",
    "    # extract feats\n",
    "    FEATS = []\n",
    "    # loop through batches\n",
    "    for idx, filename in enumerate(all_filenames):\n",
    "        # read & transform img\n",
    "        img = Image.open(os.path.join(valdir, filename)).convert('L')\n",
    "        img = img.resize((64, 64))\n",
    "        FEATS.append(np.array(img).reshape(-1))\n",
    "    FEATS = np.array(FEATS)\n",
    "    print(FEATS.shape)\n",
    "\n",
    "    # save feats\n",
    "    filename = exp_name+'_'+'pixel'+'.pth'\n",
    "    torch.save(FEATS, filename)\n",
    "    print(f'saving to {filename}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68162c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_list = ['lowpassfilter_colored_noblur', \n",
    "                    'lowpassfilter_colored_linearblur',\n",
    "                    'lowpassfilter_colored_nonlinearblur',\n",
    "                    # 'lowpassfilter_colored',\n",
    "                    # 'lowpassfilter_colored_nonlinearblur1',\n",
    "                    # 'lowpassfilter_colored_nonlinearblur2'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aca114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) exp_names_list_GFR_21 - BASEL color texture\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/'] * 66\n",
    "\n",
    "exp_name_list = [\n",
    "                ['id10', 'id11'],\n",
    "                 ['id10', 'id12'],\n",
    "                 ['id10', 'id13'],\n",
    "                 ['id10', 'id14'],\n",
    "                 ['id10', 'id15'],\n",
    "                 ['id10', 'id16'],\n",
    "                 ['id11', 'id12'],\n",
    "                 ['id11', 'id13'],\n",
    "                 ['id11', 'id14'],\n",
    "                 ['id11', 'id15'],\n",
    "                 ['id11', 'id16'],\n",
    "                 ['id12', 'id13'],\n",
    "                 ['id12', 'id14'],\n",
    "                 ['id12', 'id15'],\n",
    "                 ['id12', 'id16'],\n",
    "                 ['id13', 'id14'],\n",
    "                 ['id13', 'id15'],\n",
    "                 ['id13', 'id16'],\n",
    "                 ['id14', 'id15'],\n",
    "                 ['id14', 'id16'],\n",
    "                 ['id15', 'id16'],\n",
    "                ['id10', 'id17'],\n",
    "                ['id10', 'id18'],\n",
    "                ['id10', 'id19'],\n",
    "                ['id10', 'id20'],\n",
    "                ['id10', 'id21'],\n",
    "                ['id11', 'id17'],\n",
    "                ['id11', 'id18'],\n",
    "                ['id11', 'id19'],\n",
    "                ['id11', 'id20'],\n",
    "                ['id11', 'id21'],\n",
    "                ['id12', 'id17'],\n",
    "                ['id12', 'id18'],\n",
    "                ['id12', 'id19'],\n",
    "                ['id12', 'id20'],\n",
    "                ['id12', 'id21'],\n",
    "                ['id13', 'id17'],\n",
    "                ['id13', 'id18'],\n",
    "                ['id13', 'id19'],\n",
    "                ['id13', 'id20'],\n",
    "                ['id13', 'id21'],\n",
    "                ['id14', 'id17'],\n",
    "                ['id14', 'id18'],\n",
    "                ['id14', 'id19'],\n",
    "                ['id14', 'id20'],\n",
    "                ['id14', 'id21'],\n",
    "                ['id15', 'id17'],\n",
    "                ['id15', 'id18'],\n",
    "                ['id15', 'id19'],\n",
    "                ['id15', 'id20'],\n",
    "                ['id15', 'id21'],\n",
    "                ['id16', 'id17'],\n",
    "                ['id16', 'id18'],\n",
    "                ['id16', 'id19'],\n",
    "                ['id16', 'id20'],\n",
    "                ['id16', 'id21'],\n",
    "                ['id17', 'id18'],\n",
    "                ['id17', 'id19'],\n",
    "                ['id17', 'id20'],\n",
    "                ['id17', 'id21'],\n",
    "                ['id18', 'id19'],\n",
    "                ['id18', 'id20'],\n",
    "                ['id18', 'id21'],\n",
    "                ['id19', 'id20'],\n",
    "                ['id19', 'id21'],\n",
    "                ['id20', 'id21'],\n",
    "] \n",
    "   \n",
    "    \n",
    "# specify which dataset to use by index \n",
    "model_acc_across_tasks = {model_name: [] for model_name in model_names_list}\n",
    "\n",
    "\n",
    "for dataset_index in range(52, 66):# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        model_acc_across_tasks[model_name].append(np.array(all_scores).mean())\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, acc_list in model_acc_across_tasks.items():\n",
    "    print(model_name)\n",
    "    print('\\t'.join(f\"{acc}\" for acc in acc_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba54e5-979f-4628-a2df-96ae723e727c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# get bio i1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca46d7e-3930-40c6-aef8-44f5ba591fb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## vbsli* i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835d935-80c5-4356-adb9-f10165391b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_neptune/human_n_subs=37_20211011_Var6vbsl_set0_im151_elias_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_neptune_dur200ms_lab_updated.json_I1_partition_splithalf_trial_binsize=35245_n_rep=5\"\n",
    "_path = \"../data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_elias_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_neptune_dur200ms_lab_updated.json_n_rep=5\"\n",
    "\n",
    "# SL\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_elias_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_neptune_dur200ms_lab_updated.json_n_rep=5\"\n",
    "\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1_5rep = pickle.load(f).squeeze()\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_neptune/AJ_176_20211011_Var6vbsl_set0_im151_neptune_dur400ms_lab_updated.json_20211011_Var6vbsl_set0_im151_elias_dur400ms_lab_updated.json_0_I1_partition_splithalf_trial_binsize=24008n_rep=5\"\n",
    "_path = \"../data/face_data/bio_data/avg-monkey-i1_splithalf\"\n",
    "\n",
    "# SL\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/bio_data/avg-monkey-i1_splithalf\"\n",
    "\n",
    "with open(_path, 'rb') as f:\n",
    "    marmoset_i1_5rep = pickle.load(f).squeeze()\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_neptune/human_n_subs=37_20211011_Var6vbsl_set0_im151_elias_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_neptune_dur200ms_lab_updated.json_I1_partition_trial_binsize=35245\"\n",
    "_path = \"../data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_elias_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_neptune_dur200ms_lab_updated.json\"\n",
    "\n",
    "# SL\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_elias_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_neptune_dur200ms_lab_updated.json\"\n",
    "\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1 = pickle.load(f).squeeze().reshape(-1)\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_neptune/AJ_176_20211011_Var6vbsl_set0_im151_neptune_dur400ms_lab_updated.json_20211011_Var6vbsl_set0_im151_elias_dur400ms_lab_updated.json_0_I1_partition_trial_binsize=24008\"\n",
    "_path = \"../data/face_data/bio_data/avg-monkey-i1\"\n",
    "\n",
    "# SL\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/bio_data/avg-monkey-i1\"\n",
    "\n",
    "with open(_path, 'rb') as f:\n",
    "    marmoset_i1 = pickle.load(f).squeeze().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316c7d0-e390-46f0-8bb1-f367db8a5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize \n",
    "def NormalizeData(data, data_max=None, data_min=None): # normalize to [0,1]\n",
    "    if data_max is None and data_min is None:\n",
    "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    else:\n",
    "        return (data - data_min) / (data_max - data_min)\n",
    "is_normalized = True\n",
    "if is_normalized:\n",
    "    human_i1_5rep = NormalizeData(human_i1_5rep, 4, -4)\n",
    "    human_i1 = NormalizeData(human_i1, 4, -4)\n",
    "    marmoset_i1_5rep = NormalizeData(marmoset_i1_5rep, 4, -4)\n",
    "    marmoset_i1 = NormalizeData(marmoset_i1, 4, -4)\n",
    "human_i1_5rep.shape, marmoset_i1_5rep.shape, human_i1.shape, marmoset_i1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a3057-4e25-4c0e-9252-2560b1be30c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## human i1s - camel vs. elephant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651937c3-5dcf-44e1-859e-ffb1fad7c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read human i1s - camel vs. elephant\n",
    "_path = \"../../data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant/human_n_subs=31_20211011_Var6vbsl_set0_im151_camel_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_elephant_dur200ms_lab_updated.json_I1_partition_splithalf_trial_binsize=13738_n_rep=5\"\n",
    "\n",
    "# SL (path updated)\n",
    "# Human experiment, using set0, im151 -- elephant, subs=31, 20211011\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant/human_n_subs=31_20211011_Var6vbsl_set0_im151_camel_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_elephant_dur200ms_lab_updated.json_I1_partition_splithalf_trial_binsize=13738_n_rep=5\"\n",
    "\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1s_obj_vbsl151 = pickle.load(f).squeeze()\n",
    "_path = \"../../data/face_data/control_exp/objs/20220412_Var6vb_same_as_camel_sp_set1_im101_elephant/human_n_subs=26_20220412_Var6vbsp_set1_im101_camel_dur200ms.json_20220412_Var6vb_same_as_camel_sp_set1_im101_elephant_dur200ms.json_I1_partition_splithalf_trial_binsize=10043_n_rep=5\"\n",
    "\n",
    "# SL (path updated)\n",
    "# Human experiment, using set1, im101 -- elephant, subs=26, 20220412 \n",
    "_path = \"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/20220412_Var6vb_same_as_camel_sp_set1_im101_elephant/human_n_subs=26_20220412_Var6vbsp_set1_im101_camel_dur200ms.json_20220412_Var6vb_same_as_camel_sp_set1_im101_elephant_dur200ms.json_I1_partition_splithalf_trial_binsize=10043_n_rep=5\"\n",
    "\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1s_obj_vbsp101 = pickle.load(f).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ba3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL \n",
    "is_normalized = True\n",
    "if is_normalized:\n",
    "    human_i1s_obj_vbsl151 = NormalizeData(human_i1s_obj_vbsl151)\n",
    "    human_i1s_obj_vbsp101 = NormalizeData(human_i1s_obj_vbsp101)\n",
    "human_i1s_obj_vbsl151.shape, human_i1s_obj_vbsp101.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5878d7-39d3-47d6-8640-d4471ad5487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_i1s_obj_vbsl151.shape, human_i1s_obj_vbsp101.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d625086b-bcc8-4fa9-b151-c51a51388674",
   "metadata": {
    "tags": []
   },
   "source": [
    "# compute model i1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = 'barlowtwins_finetune_7way_EM_seojin_seed77__model_best.pth.tar'\n",
    "dst  = '/mnt/smb/locker/issa-locker/users/Seojin/saved_models/barlowtwins_finetune_7way_EM_seojin_seed77__model_best.pth.tar'\n",
    "shutil.copyfile(src, dst)\n",
    "\n",
    "print(f\"Copied file to: {dst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) exp_names_list_GFR_21\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/'\n",
    "]\n",
    "\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_neptune/vbsle151_neptune_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_seojin/vbsle151_seojin_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_sophie/vbsle151_sophie_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_seojin/vbsle151_seojin_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_sophie/vbsle151_sophie_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_sophie/vbsle151_sophie_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_younah/vbsle151_younah_neutral']\n",
    "]\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17, 18, 19,20]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_list=[\n",
    "# 'off_the_shelf_barlowtwins_texture_colorbg_2way_seojin_dan',\n",
    "# 'off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_seojin',\n",
    "# 'off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_kedar',\n",
    "# 'off_the_shelf_barlowtwins_finetune_32way_8ID_4EM_IDEM_colorbg',\n",
    "# 'SL_resnet50_finetune_vbsle_50k_elias_neptune_seed777_model_best',\n",
    "# 'Josh_256bs_pretrained_model_best',\n",
    "# 'off_the_shelf_barlowtwins_IDEM_28way_colorbg_epochs50'\n",
    "'lowpassfilter_grayscale_linearblur'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) exp_names_list_GFR_additional\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/'] * 45\n",
    "useful_stats = {}\n",
    "exp_name_list = [\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_younah/vbsle151_younah_neutral', 'vbsle151_ashley/vbsle151_ashley_neutral'],\n",
    "                ['vbsle151_younah/vbsle151_younah_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_younah/vbsle151_younah_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_younah/vbsle151_younah_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_younah/vbsle151_younah_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_ashley/vbsle151_ashley_neutral', 'vbsle151_kedar/vbsle151_kedar_neutral'],\n",
    "                ['vbsle151_ashley/vbsle151_ashley_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_ashley/vbsle151_ashley_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_ashley/vbsle151_ashley_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_kedar/vbsle151_kedar_neutral', 'vbsle151_josh/vbsle151_josh_neutral'],\n",
    "                ['vbsle151_kedar/vbsle151_kedar_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_kedar/vbsle151_kedar_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_josh/vbsle151_josh_neutral', 'vbsle151_ani/vbsle151_ani_neutral'],\n",
    "                ['vbsle151_josh/vbsle151_josh_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "                ['vbsle151_ani/vbsle151_ani_neutral', 'vbsle151_tony/vbsle151_tony_neutral'],\n",
    "] \n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40, 41, 42, 43, 44]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape and a few sample feature values\n",
    "print(\"Extracted feature shape:\", FEATS.shape)\n",
    "print(\"Sample features for the first image pair:\")\n",
    "print(FEATS[0])  # Print the first feature vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a12921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) exp_names_list_GFR_21_texture_colorbg\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'\n",
    "]\n",
    "\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_neptune_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_seojin_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_sophie_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_seojin_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_sophie_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_sophie_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_sophie_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_sophie_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_sophie_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_dan_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_dan_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_sreyas_neutral', 'vbsl151_younah_neutral']\n",
    "]\n",
    "\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0, 1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17, 18, 19,20]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f44c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) exp_names_list_GER_21_elias_texture_colorbg\n",
    "# model_names_list = ['SL_resnet50_finetune_vbsle_50k_10way_seed77_model_best', 'SL_resnet50_finetune_vbsle_50k_12way_seed77_model_best_12way']\n",
    "useful_stats = {}\n",
    "\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'\n",
    "]\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_happiness_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_sadness_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_disgust_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_sadness_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_disgust_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_disgust_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_disgust_4', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_disgust_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_disgust_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_fear_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_fear_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_anger_4', 'vbsl151_elias_surprise_4']\n",
    "]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ee8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) exp_names_list_GFR_additional_texture_colorbg\n",
    "useful_stats = {}\n",
    "# (4) exp_names_list_GFR_additional\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'] * 45\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_neptune_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_neptune_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_neptune_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_neptune_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_neptune_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_seojin_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_seojin_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_seojin_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_seojin_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_seojin_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_sophie_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_sophie_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_sophie_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_sophie_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_sophie_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_dan_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_dan_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_dan_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_dan_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_dan_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_sreyas_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_sreyas_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_sreyas_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_sreyas_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_sreyas_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_younah_neutral', 'vbsl151_ashley_neutral'],\n",
    "                ['vbsl151_younah_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_younah_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_younah_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_younah_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_ashley_neutral', 'vbsl151_kedar_neutral'],\n",
    "                ['vbsl151_ashley_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_ashley_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_ashley_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_kedar_neutral', 'vbsl151_josh_neutral'],\n",
    "                ['vbsl151_kedar_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_kedar_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_josh_neutral', 'vbsl151_ani_neutral'],\n",
    "                ['vbsl151_josh_neutral', 'vbsl151_tony_neutral'],\n",
    "                ['vbsl151_ani_neutral', 'vbsl151_tony_neutral'],\n",
    "] \n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10, 11, 12, 13,14, 15, 16, 17, 18, 19, 20, 21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40, 41, 42, 43, 44]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) exp_names_list_GER_21_elias\n",
    "useful_stats = {}\n",
    "\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_elias/'\n",
    "]\n",
    "\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsle151_elias_neutral', 'vbsle151_elias_happiness_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_sadness_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_disgust_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_neutral', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_sadness_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_disgust_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_happiness_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_disgust_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_sadness_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_disgust_4', 'vbsle151_elias_fear_4'],\n",
    "                 ['vbsle151_elias_disgust_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_disgust_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_fear_4', 'vbsle151_elias_anger_4'],\n",
    "                 ['vbsle151_elias_fear_4', 'vbsle151_elias_surprise_4'],\n",
    "                 ['vbsle151_elias_anger_4', 'vbsle151_elias_surprise_4']\n",
    "\n",
    "                ]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10, 11, 12, 13,14, 15, 16, 17, 18, 19, 20]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) exp_names_list_GER_21_elias_texture_colorbg\n",
    "\n",
    "useful_stats = {}\n",
    "\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'\n",
    "]\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_happiness_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_sadness_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_disgust_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_sadness_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_disgust_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_happiness_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_happiness_4',\n",
    "                 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_disgust_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_sadness_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_disgust_4', 'vbsl151_elias_fear_4'],\n",
    "                ['vbsl151_elias_disgust_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_disgust_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_fear_4', 'vbsl151_elias_anger_4'],\n",
    "                ['vbsl151_elias_fear_4', 'vbsl151_elias_surprise_4'],\n",
    "                ['vbsl151_elias_anger_4', 'vbsl151_elias_surprise_4']\n",
    "]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df581aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) exp_names_list_GFR_21 - BASEL\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/'] * 66\n",
    "\n",
    "exp_name_list = [\n",
    "                ['id988', 'id989'],\n",
    "                 ['id988', 'id990'],\n",
    "                 ['id988', 'id991'],\n",
    "                 ['id988', 'id992'],\n",
    "                 ['id988', 'id993'],\n",
    "                 ['id988', 'id994'],\n",
    "                 ['id989', 'id990'],\n",
    "                 ['id989', 'id991'],\n",
    "                 ['id989', 'id992'],\n",
    "                 ['id989', 'id993'],\n",
    "                 ['id989', 'id994'],\n",
    "                 ['id990', 'id991'],\n",
    "                 ['id990', 'id992'],\n",
    "                 ['id990', 'id993'],\n",
    "                 ['id990', 'id994'],\n",
    "                 ['id991', 'id992'],\n",
    "                 ['id991', 'id993'],\n",
    "                 ['id991', 'id994'],\n",
    "                 ['id992', 'id993'],\n",
    "                 ['id992', 'id994'],\n",
    "                 ['id993', 'id994'],\n",
    "                ['id988', 'id995'],\n",
    "                ['id988', 'id996'],\n",
    "                ['id988', 'id997'],\n",
    "                ['id988', 'id998'],\n",
    "                ['id988', 'id999'],\n",
    "                ['id989', 'id995'],\n",
    "                ['id989', 'id996'],\n",
    "                ['id989', 'id997'],\n",
    "                ['id989', 'id998'],\n",
    "                ['id989', 'id999'],\n",
    "                ['id990', 'id995'],\n",
    "                ['id990', 'id996'],\n",
    "                ['id990', 'id997'],\n",
    "                ['id990', 'id998'],\n",
    "                ['id990', 'id999'],\n",
    "                ['id991', 'id995'],\n",
    "                ['id991', 'id996'],\n",
    "                ['id991', 'id997'],\n",
    "                ['id991', 'id998'],\n",
    "                ['id991', 'id999'],\n",
    "                ['id992', 'id995'],\n",
    "                ['id992', 'id996'],\n",
    "                ['id992', 'id997'],\n",
    "                ['id992', 'id998'],\n",
    "                ['id992', 'id999'],\n",
    "                ['id993', 'id995'],\n",
    "                ['id993', 'id996'],\n",
    "                ['id993', 'id997'],\n",
    "                ['id993', 'id998'],\n",
    "                ['id993', 'id999'],\n",
    "                ['id994', 'id995'],\n",
    "                ['id994', 'id996'],\n",
    "                ['id994', 'id997'],\n",
    "                ['id994', 'id998'],\n",
    "                ['id994', 'id999'],\n",
    "                ['id995', 'id996'],\n",
    "                ['id995', 'id997'],\n",
    "                ['id995', 'id998'],\n",
    "                ['id995', 'id999'],\n",
    "                ['id996', 'id997'],\n",
    "                ['id996', 'id998'],\n",
    "                ['id996', 'id999'],\n",
    "                ['id997', 'id998'],\n",
    "                ['id997', 'id999'],\n",
    "                ['id998', 'id999'],\n",
    "] \n",
    "   \n",
    "model_acc_across_tasks = {model_name: [] for model_name in model_names_list}\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in range(66):# for dataset_index in [3,4,5]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        model_acc_across_tasks[model_name].append(np.array(all_scores).mean())\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "print(\"\\n=== Summary: Average Accuracy Across Datasets ===\")\n",
    "for model_name in model_names_list:\n",
    "    accs = []\n",
    "    for data_root in data_root_list:\n",
    "        if model_name in useful_stats[data_root]:\n",
    "            acc_mean, acc_std = useful_stats[data_root][model_name]['acc']\n",
    "            accs.append(acc_mean)\n",
    "    if accs:\n",
    "        overall_mean = np.mean(accs)\n",
    "        overall_std = np.std(accs)\n",
    "        print(f\"{model_name}: {overall_mean:.4f}  {overall_std:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da1bd7-dbc5-4944-b5c0-77275fc01aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# useful_stats = {}\n",
    "# with open('useful_stats_ablation.pkl', 'wb') as f:SL_20240715\n",
    "#     pickle.dump(useful_stats, f)\n",
    "\n",
    "# useful_stats = {}\n",
    "\n",
    "import pickle\n",
    "# SL Path updated\n",
    "with open('useful_stats_SL_20240715.pkl', 'rb') as f: # useful_stats_ablation, useful_stats_tuning, useful_stats_penn\n",
    "    useful_stats = pickle.load(f)\n",
    "    \n",
    "# hierachy: [task_dir][model_name][acc/acc_per_img/dist/i1]\n",
    "# acc [list]: acc over all datapoints and trails -> [acc_mean, acc_std]\n",
    "# acc_per_img [array]: acc per image averaged over all trails -> shape [2, num_img_per_class]\n",
    "# dist [array]: all svm distance (note that the second class dist is negated) -> shape [2, num_repetition, num_img_per_class]\n",
    "# i1_5rep [array]: random split-half i1 with 5 repetition -> shape [5, 2*num_img_per_class]\n",
    "# i1 [array]: model i1 (the same as dist averaging over trails) -> shape [2, num_img_per_class]\n",
    "# i1_corr [list]: model i1 correlation with bio systems. For vbsl101, the order is [Bourgeois, Sausage, AJ]. \n",
    "# For vbsl151, the order is [Human, AJ]. For each corr, I record [i1_corr_mean, i1_corr_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a02cd-1736-4451-99f3-fe512ccb0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, acc_list in model_acc_across_tasks.items():\n",
    "    print(model_name)\n",
    "    print('\\t'.join(f\"{acc}\" for acc in acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d89487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # START HERE\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from load_model import load_model\n",
    "# 4200 images, category order\n",
    "\n",
    "combined_folder = '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsl50_texture/combined_vbsl50_texture_registered' # contains 4200 images\n",
    "combined_folder = '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsl50_registered/combined_vbsl50_registered' # contains 4200 images\n",
    "\n",
    "save_rdm_path = '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/correlation_analysis/vbsl50_registered_avgpool/'\n",
    "\n",
    "os.makedirs(save_rdm_path, exist_ok=True)\n",
    "\n",
    "# Strict category order (identity_emotion)\n",
    "category_order = [\n",
    "    \"Elias_neutral\", \"Elias_happiness_4\", \"Elias_sadness_4\", \"Elias_surprise_4\", \"Elias_fear_4\", \"Elias_disgust_4\", \"Elias_anger_4\",\n",
    "    \"Neptune_neutral\", \"Neptune_happiness_4\", \"Neptune_sadness_4\", \"Neptune_surprise_4\", \"Neptune_fear_4\", \"Neptune_disgust_4\", \"Neptune_anger_4\",\n",
    "    \"Seojin_neutral\", \"Seojin_happiness_4\", \"Seojin_sadness_4\", \"Seojin_surprise_4\", \"Seojin_fear_4\", \"Seojin_disgust_4\", \"Seojin_anger_4\",\n",
    "    \"Sophie_neutral\", \"Sophie_happiness_4\", \"Sophie_sadness_4\", \"Sophie_surprise_4\", \"Sophie_fear_4\", \"Sophie_disgust_4\", \"Sophie_anger_4\",\n",
    "    \"Dan_neutral\", \"Dan_happiness_4\", \"Dan_sadness_4\", \"Dan_surprise_4\", \"Dan_fear_4\", \"Dan_disgust_4\", \"Dan_anger_4\",\n",
    "    \"Sreyas_neutral\", \"Sreyas_happiness_4\", \"Sreyas_sadness_4\", \"Sreyas_surprise_4\", \"Sreyas_fear_4\", \"Sreyas_disgust_4\", \"Sreyas_anger_4\",\n",
    "    \"Younah_neutral\", \"Younah_happiness_4\", \"Younah_sadness_4\", \"Younah_surprise_4\", \"Younah_fear_4\", \"Younah_disgust_4\", \"Younah_anger_4\",\n",
    "    \"Ashley_neutral\", \"Ashley_happiness_4\", \"Ashley_sadness_4\", \"Ashley_surprise_4\", \"Ashley_fear_4\", \"Ashley_disgust_4\", \"Ashley_anger_4\",\n",
    "    \"Josh_neutral\", \"Josh_happiness_4\", \"Josh_sadness_4\", \"Josh_surprise_4\", \"Josh_fear_4\", \"Josh_disgust_4\", \"Josh_anger_4\",\n",
    "    \"Kedar_neutral\", \"Kedar_happiness_4\", \"Kedar_sadness_4\", \"Kedar_surprise_4\", \"Kedar_fear_4\", \"Kedar_disgust_4\", \"Kedar_anger_4\",\n",
    "    \"Ani_neutral\", \"Ani_happiness_4\", \"Ani_sadness_4\", \"Ani_surprise_4\", \"Ani_fear_4\", \"Ani_disgust_4\", \"Ani_anger_4\",\n",
    "    \"Tony_neutral\", \"Tony_happiness_4\", \"Tony_sadness_4\", \"Tony_surprise_4\", \"Tony_fear_4\", \"Tony_disgust_4\", \"Tony_anger_4\"\n",
    "]\n",
    "\n",
    "\n",
    "# model_names_list = ['resnet50']\n",
    "# category_order = [\n",
    "#     \"Elias_neutral_textured\", \"Elias_happiness_4_textured\", \"Elias_sadness_4_textured\", \"Elias_surprise_4_textured\", \"Elias_fear_4_textured\", \"Elias_disgust_4_textured\", \"Elias_anger_4_textured\",\n",
    "#     \"Neptune_neutral_textured\", \"Neptune_happiness_4_textured\", \"Neptune_sadness_4_textured\", \"Neptune_surprise_4_textured\", \"Neptune_fear_4_textured\", \"Neptune_disgust_4_textured\", \"Neptune_anger_4_textured\",\n",
    "#     \"Seojin_neutral_textured\", \"Seojin_happiness_4_textured\", \"Seojin_sadness_4_textured\", \"Seojin_surprise_4_textured\", \"Seojin_fear_4_textured\", \"Seojin_disgust_4_textured\", \"Seojin_anger_4_textured\",\n",
    "#     \"Sophie_neutral_textured\", \"Sophie_happiness_4_textured\", \"Sophie_sadness_4_textured\", \"Sophie_surprise_4_textured\", \"Sophie_fear_4_textured\", \"Sophie_disgust_4_textured\", \"Sophie_anger_4_textured\",\n",
    "#     \"Dan_neutral_textured\", \"Dan_happiness_4_textured\", \"Dan_sadness_4_textured\", \"Dan_surprise_4_textured\", \"Dan_fear_4_textured\", \"Dan_disgust_4_textured\", \"Dan_anger_4_textured\",\n",
    "#     \"Sreyas_neutral_textured\", \"Sreyas_happiness_4_textured\", \"Sreyas_sadness_4_textured\", \"Sreyas_surprise_4_textured\", \"Sreyas_fear_4_textured\", \"Sreyas_disgust_4_textured\", \"Sreyas_anger_4_textured\",\n",
    "#     \"Younah_neutral_textured\", \"Younah_happiness_4_textured\", \"Younah_sadness_4_textured\", \"Younah_surprise_4_textured\", \"Younah_fear_4_textured\", \"Younah_disgust_4_textured\", \"Younah_anger_4_textured\",\n",
    "#     \"Ashley_neutral_textured\", \"Ashley_happiness_4_textured\", \"Ashley_sadness_4_textured\", \"Ashley_surprise_4_textured\", \"Ashley_fear_4_textured\", \"Ashley_disgust_4_textured\", \"Ashley_anger_4_textured\",\n",
    "#     \"Josh_neutral_textured\", \"Josh_happiness_4_textured\", \"Josh_sadness_4_textured\", \"Josh_surprise_4_textured\", \"Josh_fear_4_textured\", \"Josh_disgust_4_textured\", \"Josh_anger_4_textured\",\n",
    "#     \"Kedar_neutral_textured\", \"Kedar_happiness_4_textured\", \"Kedar_sadness_4_textured\", \"Kedar_surprise_4_textured\", \"Kedar_fear_4_textured\", \"Kedar_disgust_4_textured\", \"Kedar_anger_4_textured\",\n",
    "#     \"Ani_neutral_textured\", \"Ani_happiness_4_textured\", \"Ani_sadness_4_textured\", \"Ani_surprise_4_textured\", \"Ani_fear_4_textured\", \"Ani_disgust_4_textured\", \"Ani_anger_4_textured\",\n",
    "#     \"Tony_neutral_textured\", \"Tony_happiness_4_textured\", \"Tony_sadness_4_textured\", \"Tony_surprise_4_textured\", \"Tony_fear_4_textured\", \"Tony_disgust_4_textured\", \"Tony_anger_4_textured\"\n",
    "# ]\n",
    "\n",
    "# model_names_list = [\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_2id_seed777_model_best',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_6id_seed77_model_best',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_10id_seed77_model_best',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_20ID_seed777',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_30ID_seed777',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_40ID_seed777',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_50ID_seed777',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_100id_seed777_model_best',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_500id_seed777__best',\n",
    "#     'SL_resnet50_finetune_Basel_color_texture_1kid_seed777_model_best',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_2ID_seed777_model_best_SL',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_4ID_seed777_model_best_SL',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_6ID_seed777_model_best_SL',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_8ID_seed777_model_best_SL',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_10ID_seed777_model_best_SL',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_12ID_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_20ID_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_30ID_seed777_',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_40ID_seed777_',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_50ID_seed777_',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_500ID2_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_100ID2_seed777_model_best',\n",
    "# 'SL_resnet50_finetune_Basel_no_texture_1000ID_seed777_model_best'\n",
    "# ]\n",
    "# Image preprocessing\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "# ==== Main Loop ====\n",
    "for j, model_name in enumerate(model_names_list):\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "    \n",
    "    model = load_model(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    if 'simplecnn' in model_name:\n",
    "        model.fc2.register_forward_hook(get_activation('feats'))\n",
    "    elif 'alexnet' in model_name:\n",
    "        if 'layer4' in model_name:\n",
    "            print(\"add hook in layer4\")\n",
    "            model.features[4].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer8' in model_name:\n",
    "            print(\"add hook in layer8\")\n",
    "            model.features[8].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer12' in model_name:\n",
    "            print(\"add hook in layer12\")\n",
    "            model.features[12].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layerC2' in model_name:\n",
    "            model.classifier[2].register_forward_hook(get_activation('feats'))\n",
    "        else: # final layer\n",
    "            model.classifier[5].register_forward_hook(get_activation('feats'))\n",
    "    elif model_name == 'vgg16':\n",
    "        model.classifier[4].register_forward_hook(get_activation('feats'))\n",
    "    elif model_name == 'vggface':\n",
    "        model.fc7.register_forward_hook(get_activation('feats'))\n",
    "    elif 'onlyDM' in model_name:\n",
    "        model.depth_predictor.encoder[4].register_forward_hook(get_activation('feats'))\n",
    "        # model.depth_predictor.decoder[30].register_forward_hook(get_activation('feats'))\n",
    "        # model.depth_predictor.encoder[6].register_forward_hook(get_activation('feats'))\n",
    "    else: # resnet50\n",
    "        if 'layer1' in model_name:\n",
    "            print(\"add hook in layer1\")\n",
    "            model.layer1.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer2' in model_name:\n",
    "            print(\"add hook in layer2\")\n",
    "            model.layer2.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer3' in model_name:\n",
    "            print(\"add hook in layer3\")\n",
    "            model.layer3.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer4_no_pooling' in model_name:\n",
    "            print(\"add hook in layer4_no_pooling\")\n",
    "            model.layer4.register_forward_hook(get_activation('feats'))\n",
    "        else:\n",
    "            model.avgpool.register_forward_hook(get_activation('feats'))\n",
    "        \n",
    "\n",
    "    # Step 1: Extract all 4200 features in strict order\n",
    "    all_feats = []\n",
    "\n",
    "    for category in category_order:\n",
    "        for i in range(50):\n",
    "            fname = f\"{category}_trialnum{i}.png\"\n",
    "            fpath = os.path.join(combined_folder, fname)\n",
    "            if not os.path.exists(fpath):\n",
    "                print(f\"Missing: {fpath}\")\n",
    "                continue\n",
    "            img = Image.open(fpath).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).cuda()\n",
    "            with torch.no_grad():\n",
    "                _ = model(img_tensor)\n",
    "            feat = activation['feats'].cpu().squeeze().numpy().flatten()\n",
    "            all_feats.append(feat)\n",
    "\n",
    "    all_feats = np.stack(all_feats).astype(np.float32)  # shape: (4200, D)\n",
    "\n",
    "    # Step 2: Compute full 4200x4200 correlation RDM\n",
    "    full_rdm = 1 - np.corrcoef(all_feats)  # shape: (4200, 4200)\n",
    "\n",
    "    # Step 3: Block-average into 84x84\n",
    "    block_size = 50\n",
    "    num_categories = len(category_order)\n",
    "    avg_rdm = np.zeros((num_categories, num_categories))\n",
    "\n",
    "    for i in range(num_categories):\n",
    "        for j in range(num_categories):\n",
    "            block = full_rdm[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]\n",
    "            avg_rdm[i, j] = block.mean()\n",
    "\n",
    "    # Step 4: Save\n",
    "    rdm_path = os.path.join(save_rdm_path, f\"combined_vbsl50_{model_name}_rdm_blockavg.npy\")\n",
    "    np.save(rdm_path, avg_rdm)\n",
    "    print(f\"Saved block-averaged RDM to: {rdm_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_names_list = [\n",
    "#  'SL_resnet50_finetune_vbsle_50k_texture_colorbg_seojin_ani_seed777_model_best',\n",
    "#     'SL_resnet50_finetune_vbsle_50k_texture_colorbg_seojin_tony_seed777_model_best',\n",
    "#     'SL_resnet50_finetune_vbsle_50k_texture_colorbg_seojin_kedar_seed777_model_best',\n",
    "    'off_the_shelf_barlowtwins_finetune_12way_6ID_2EM_IDEM_colorbg',\n",
    "    'off_the_shelf_barlowtwins_finetune_24way_6ID_4EM_IDEM_colorbg',\n",
    "    'off_the_shelf_barlowtwins_finetune_16way_8ID_2EM_IDEM_colorbg',\n",
    "    'off_the_shelf_barlowtwins_finetune_32way_8ID_4EM_IDEM_colorbg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_model_ver3 import load_model\n",
    "model_names_list = [\n",
    " \"SL_resnet50_finetune_vbsle_50k_4way_SSKD_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_vbsle_50k_6way_final_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_vbsle_50k_8way_far_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_7way_EM_seojin_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_vbsle_50k_sophie_seojin_colorbg_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_texture_colorbg_2way_seojin_dan_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_vbsle_50k_sophie_kedar_colorbg_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_vbsle_50k_4way_SSKD_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_vbsle_50k_6way_final_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_texture_colorbg_8way_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_texture_colorbg_em_neutral_anger_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_texture_colorbg_em_4way_NHAS_seed77_model_best\",\n",
    "\"SL_colorbg_resnet50_finetune_7way_EM_seojin_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_7way_EM_sophie_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_7way_EM_dan_colorbg_seed77__model_best\",\n",
    "\"SL_resnet50_finetune_7way_EM_kedar_colorbg_seed77__model_best\",\n",
    "\"SL_resnet50_finetune_4way_IDEM_seojin_sophie_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_4way_IDEM_seojin_dan_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_4way_IDEM_sophie_kedar_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_8way_IDEM_seojin_sophie_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_8way_IDEM_seojin_dan_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_8way_IDEM_sophie_kedar_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_14way_IDEM_seojin_sophie_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_14way_IDEM_seojin_dan_colorbg_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_14way_IDEM_sophie_kedar_colorbg_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_8way_IDEM_ssskd_colorbg_seed77_model_best\",\n",
    "\"SL_resnet50_finetune_16way_IDEM_ssskd_colorbg_seed777\",\n",
    "\"SL_resnet50_finetune_28way_IDEM_colorbg_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_12way_6ID_2EM_IDEM_colorbg\",\n",
    "\"SL_resnet50_finetune_24way_6ID_4EM_IDEM_colorbg\",\n",
    "\"SL_resnet50_finetune_42way_IDEM_colorbg_seed777_model_best\",\n",
    "\"SL_resnet50_finetune_16way_8ID_2EM_IDEM_colorbg\",\n",
    "\"SL_resnet50_finetune_32way_8ID_4EM_IDEM_colorbg\",\n",
    "\"SL_resnet50_finetune_56way_IDEM_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_vbsle_50k_4way_SSKD_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_vbsle_50k_6way_final_one\",\n",
    "\"off_the_shelf_barlowtwins_ID_8way_epochs50\",\n",
    "\"off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_seojin\",\n",
    "\"off_the_shelf_barlowtwins_texture_colorbg_2way_seojin_dan\",\n",
    "\"off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_kedar\",\n",
    "\"off_the_shelf_barlowtwins_finetune_vbsle_50k_4way_SSKD_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_6way_final_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_ID_8way_colorbg_epochs50\",\n",
    "\"off_the_shelf_barlowtwins_finetune_texture_colorbg_em_neutral_anger\",\n",
    "\"off_the_shelf_barlowtwins_finetune_texture_colorbg_em_4way_NHAS\",\n",
    "\"off_the_shelf_barlowtwins_finetune_7way_EM_seojin_seed77_texture_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_7way_EM_sophie_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_7way_EM_dan_colorbg_seed77__model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_7way_EM_kedar_colorbg_seed77__model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_4way_IDEM_seojin_sophie_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_4way_IDEM_seojin_dan_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_4way_IDEM_sophie_kedar_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_8way_IDEM_seojin_sophie_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_8way_IDEM_seojin_dan_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_8way_IDEM_sophie_kedar_colorbg_seed77_model_best\",\n",
    "\"off_the_shelf_barlowtwins_IDEM_14way_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_finetune_14way_IDEM_seojin_dan_colorbg_seed777_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_14way_IDEM_sophie_kedar_colorbg_seed777_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_8way_IDEM_ssskd_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_finetune_16way_IDEM_ssskd_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_IDEM_28way_colorbg_epochs50\",\n",
    "\"off_the_shelf_barlowtwins_finetune_12way_6ID_2EM_IDEM_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_finetune_24way_6ID_4EM_IDEM_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_finetune_42way_IDEM_colorbg_seed777_model_best\",\n",
    "\"off_the_shelf_barlowtwins_finetune_16way_8ID_2EM_IDEM_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_finetune_32way_8ID_4EM_IDEM_colorbg\",\n",
    "\"off_the_shelf_barlowtwins_finetune_56way_IDEM_colorbg_seed77_model_best\"\n",
    "]\n",
    "for model_name in model_names_list :\n",
    "    model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4559c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_list = [\n",
    "    # 'SL_resnet50_finetune_7way_EM_seojin_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_7way_EM_sophie_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_7way_EM_dan_colorbg_seed77__model_best',\n",
    "# 'SL_resnet50_finetune_7way_EM_kedar_colorbg_seed77__model_best',\n",
    "\n",
    "# 'SL_resnet50_finetune_4way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_4way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_4way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "# 'SL_resnet50_finetune_6way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_6way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_6way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "# 'SL_resnet50_finetune_8way_IDEM_seojin_sophie_colorbg_seed77_model_best', \n",
    "# 'SL_resnet50_finetune_8way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_8way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "# 'SL_resnet50_finetune_10way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_10way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_10way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "# 'SL_resnet50_finetune_12way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_12way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_12way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "#         \"SL_resnet50_finetune_14way_IDEM_seojin_sophie_colorbg_seed77_model_best\",\n",
    "#         'SL_resnet50_finetune_14way_IDEM_seojin_dan_colorbg_seed777_model_best',\n",
    "#         'SL_resnet50_finetune_14way_IDEM_sophie_kedar_colorbg_seed777_model_best',\n",
    "\n",
    "# 'SL_resnet50_finetune_28way_IDEM_colorbg_seed777_model_best',\n",
    "# 'SL_resnet50_finetune_42way_IDEM_colorbg_seed777_model_best',\n",
    "# 'SL_resnet50_finetune_56way_IDEM_colorbg_seed77_model_best',\n",
    "# 'SL_resnet50_finetune_12way_6ID_2EM_IDEM_colorbg',\n",
    "# 'SL_resnet50_finetune_24way_6ID_4EM_IDEM_colorbg',\n",
    "# 'SL_resnet50_finetune_16way_8ID_2EM_IDEM_colorbg',\n",
    "# 'SL_resnet50_finetune_32way_8ID_4EM_IDEM_colorbg',\n",
    "\n",
    "\n",
    "#     'off_the_shelf_barlowtwins_seojin_dan_epochs50',\n",
    "#     'off_the_shelf_barlowtwins_2way_seojin_sophie',\n",
    "#     'off_the_shelf_barlowtwins_2way_sophie_kedar',\n",
    "#     'off_the_shelf_barlowtwins_finetune_4way_SSKD',\n",
    "#     'off_the_shelf_barlowtwins_finetune_vbsle_50k_6way_final_one',\n",
    "#     'off_the_shelf_barlowtwins_ID_8way_epochs50',\n",
    "\n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_2way_seojin_dan',\n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_seojin', \n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_2way_sophie_kedar',\n",
    "#     'off_the_shelf_barlowtwins_texture_colorbg_4way',\n",
    "#     'off_the_shelf_barlowtwins_finetune_6way_final_colorbg',\n",
    "#     'off_the_shelf_barlowtwins_ID_8way_colorbg_epochs50',\n",
    "\n",
    "#     'off_the_shelf_barlowtwins_finetune_texture_colorbg_em_neutral_anger',\n",
    "#     'off_the_shelf_barlowtwins_finetune_texture_colorbg_em_4way_NHAS',\n",
    "#     'off_the_shelf_barlowtwins_finetune_texture_colorbg_em_6way_excl_fear',\n",
    "\n",
    "# 'off_the_shelf_barlowtwins_finetune_7way_EM_seojin_seed77_texture_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_7way_EM_sophie_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_7way_EM_dan_colorbg_seed77__model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_7way_EM_kedar_colorbg_seed77__model_best',\n",
    "\n",
    "'off_the_shelf_barlowtwins_finetune_4way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_4way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_4way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "'off_the_shelf_barlowtwins_finetune_6way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_6way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_6way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "'off_the_shelf_barlowtwins_finetune_8way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_8way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_8way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "'off_the_shelf_barlowtwins_finetune_10way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_10way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_10way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "'off_the_shelf_barlowtwins_finetune_12way_IDEM_seojin_sophie_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_12way_IDEM_seojin_dan_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_12way_IDEM_sophie_kedar_colorbg_seed77_model_best',\n",
    "\n",
    "'off_the_shelf_barlowtwins_IDEM_28way_colorbg_epochs50',\n",
    "'off_the_shelf_barlowtwins_finetune_42way_IDEM_colorbg_seed777_model_best',\n",
    "    'off_the_shelf_barlowtwins_finetune_56way_IDEM_colorbg_seed77_model_best'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3e0ce-1e68-42a0-9231-c4e4431a966c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name_list = ['face-vbsl151', 'face-vbsl101', 'face-ood-vbsl151', \n",
    "                    'basel-ood', 'basel-ood-notexture',\n",
    "#                    'basel-ood-vbsl101', 'basel-ood-notexture-vbsl101', \n",
    "                    'obj-vbsl151', ]\n",
    "\n",
    "data_root_list = ['../../data/face_data/vbsl_151/',\n",
    "                  '../../data/face_data/control_exp/objs/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl151_sophie_praneeth/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl151_basel_ood/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl101_ood_texture/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl101_ood_notexture/', \n",
    "                 '../../data/face_data/vbsl_101/',]\n",
    "\n",
    "# SL (update path)\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/',\n",
    "                 '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_101/',\n",
    "                 '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_sophie_praneeth/',\n",
    "                 '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood/',\n",
    "                 '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/',\n",
    "                 '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/', \n",
    "                ]\n",
    "\n",
    "useful_stats = {}\n",
    "\n",
    "exp_name_list = [['20211011_Var6vbsl_set0_im151_elias', '20211011_Var6vbsl_set0_im151_neptune'],\n",
    "                    ['20210920_Var6vbsl_set0_im101_elias', '20210920_Var6vbsl_set0_im101_neptune'],\n",
    "                    ['20230406_Var6vbsl_set0_im151_praneeth_dur200ms_lab', '20230406_Var6vbsl_set0_im151_sophie_dur200ms_lab'],\n",
    "                    ['20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_dur200ms_lab', '20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_dur200ms_lab'],\n",
    "                    ['20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_notexture_dur200ms_lab', '20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_notexture_dur200ms_lab'],\n",
    "                    ['20211011_Var6vbsl_set0_im151_camel', '20211011_Var6vbsl_set0_im151_elephant']\n",
    "                ]\n",
    "model_names_list = [\"rn50_preIN_texture_sizeVar_best\", \"rn50_preIN_notexture_sizeVar_best\", \"resnet50-trained-pretrained-vbsl\", \"rn50_vbsl-dist-ft_epoch15\"]\n",
    "model_names_list = [\"SL_resnet50_finetune_vbsl_50k_seed77_model_best\", \"SL_resnet50_finetune_vbsl_50k_obj_seed777_model_best\"]\n",
    "model_names_list = [\"resnet50\"]\n",
    "model_names_list =  [\"resnet50\", \"resnet50_layer1\", \"resnet50_layer2\", \"resnet50_layer3\", \"resnet50_layer4_no_pooling\", 'alexnet', 'vggface']\n",
    "\n",
    "### standard models\n",
    "# model_name_list = ['resnet50', 'alexnet', 'vggface',  # baseline\n",
    "#                     'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft', # stylized imagenet\n",
    "#                     'rn50_preIN_notexture_sizeVar_best', 'rn50_preIN_texture_sizeVar_best', # basel finetuned\n",
    "#                    'rn50_FromScratch_notexture_sizeVar_best', 'rn50_FromScratch_texture_sizeVar_best', # basel FromScratch\n",
    "#                     'rn50_preIN_notexture_sizeVar_2losses', # DepthMap prediction\n",
    "#                    'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'rn50_vbsl-dist-ft_epoch15'] # vbsl\n",
    "# model_name_list = ['Basel_50k_2id']\n",
    "# model_name_list = ['vbsl50k_subset_0.5', 'vbsl50k_subset_0.25', 'vbsl50k_subset_0.1', 'vbsl50k_subset_0.05']\n",
    "### intermediate layers\n",
    "# model_name_list = [\"resnet50_layer1\", \"resnet50_layer2\", \"resnet50_layer3\", 'resnet50']\n",
    "# model_name_list = [\"resnet50_layer4_no_pooling\", \"resnet50-trained-pretrained-vbsl_layer1\", \"resnet50-trained-pretrained-vbsl_layer2\", \n",
    "#                     \"resnet50-trained-pretrained-vbsl_layer3\", \"resnet50-trained-pretrained-vbsl_layer4_no_pooling\"]\n",
    "# model_name_list = ['Basel_50k_2id']\n",
    "\n",
    "### 1 epoch ft\n",
    "# model_name_list = []\n",
    "# for i in range(41):\n",
    "#     step = (i+1)*15\n",
    "#     model_name_list.append(f'vbsl50k_step{step}')\n",
    "    # model_name_list.append(f'vbsl50kobj_step{step}')\n",
    "\n",
    "# ## tuning epochs\n",
    "# model_name_list = ['resnet50']\n",
    "# for i in range(24):\n",
    "#     model_name_list.append(f'PennTuning-face-epoch{i}')\n",
    "#     model_name_list.append(f'PennTuning-obj-epoch{i}')\n",
    "\n",
    "### intermediate layers\n",
    "# model_name_list = [\"resnet50_layer1\", \"resnet50_layer2\", \n",
    "#                     \"resnet50_layer3\", \"resnet50_layer4_no_pooling\"]\n",
    "\n",
    "\n",
    "### pixel\n",
    "# model_name_list = ['pixel']\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "\n",
    "                \n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "        # fig, ax = plt.subplots(figsize=(9, 8))\n",
    "        # bars_neptune, bars_elias = [], []\n",
    "\n",
    "        # Calculate percentages\n",
    "        # for neptune_count, elias_count in mat_pred_by_bg:\n",
    "        #     total = neptune_count + elias_count\n",
    "        #     bars_neptune.append(-(neptune_count / total) * 100)\n",
    "        #     bars_elias.append((elias_count / total) * 100)\n",
    "\n",
    "        # ax.barh(unique_bg_name, bars_neptune, color='blue', label='Neptune')\n",
    "        # ax.barh(unique_bg_name, bars_elias, color='orange', label='Elias')\n",
    "\n",
    "        # Add text for percentages\n",
    "        # for i, (neptune_count, elias_count) in enumerate(mat_pred_by_bg):\n",
    "        #     total = neptune_count + elias_count\n",
    "        #     neptune_percent, elias_percent = (neptune_count / total) * 100, (elias_count / total) * 100\n",
    "        #     ax.text(bars_neptune[i], i, f'{neptune_percent:.1f}%', va='center', ha='right', fontsize=15)\n",
    "        #     ax.text(bars_elias[i], i, f'{elias_percent:.1f}%', va='center', ha='left', fontsize=15)\n",
    "\n",
    "        # ax.set_xlabel('Percentage', fontsize=17)\n",
    "        # ax.set_ylabel('Background', fontsize=17)\n",
    "        # ax.set_title(f'Model Prediction %', fontsize=20)\n",
    "        # ax.set_xlim(-100, 100)\n",
    "        # ax.tick_params(axis='y', labelsize=15)\n",
    "        # ax.legend()\n",
    "        # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "unique_bg_name = [\"bg1\", \"bg2\", \"bg3\", \"bg4\", \"bg5\", \"bg6\", \"bg7\", \"bg8\", \"bg9\", \"bg10\"]\n",
    "bars_neptune, bars_elias = [], []\n",
    "\n",
    "# Calculate percentages\n",
    "for neptune_count, elias_count in mat_pred_by_bg:\n",
    "    total = neptune_count + elias_count\n",
    "    bars_neptune.append(-(neptune_count / total) * 100)\n",
    "    bars_elias.append((elias_count / total) * 100)\n",
    "\n",
    "ax.barh(unique_bg_name, bars_neptune, color='blue', label='Neptune')\n",
    "ax.barh(unique_bg_name, bars_elias, color='orange', label='Elias')\n",
    "\n",
    "# Add text for percentages\n",
    "for i, (neptune_count, elias_count) in enumerate(mat_pred_by_bg):\n",
    "    total = neptune_count + elias_count\n",
    "    neptune_percent, elias_percent = (neptune_count / total) * 100, (elias_count / total) * 100\n",
    "    ax.text(bars_neptune[i], i, f'{neptune_percent:.1f}%', va='center', ha='right', fontsize=13)\n",
    "    ax.text(bars_elias[i], i, f'{elias_percent:.1f}%', va='center', ha='left', fontsize=13)\n",
    "\n",
    "ax.set_xlabel('Percentage', fontsize=15)\n",
    "ax.set_ylabel('Background', fontsize=15)\n",
    "ax.set_title(f'Model Prediction Percentages in {model_name}', fontsize=20)\n",
    "ax.set_xlim(-100, 100)\n",
    "ax.tick_params(axis='y', labelsize=15)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc646c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the background bias on vbsl 151\n",
    "\n",
    "# Background indices \n",
    "imageidx_elias = [188,298,1448,16,427,16,427,463,1177,463,188,1177,1406,16,16,298,1406,463,427,463,1448,463,16,188,463,463,1177,463,188,1177,463,1177,1406,298,156,427,1424,1406,1177,1406,427,1424,\n",
    "            427,1424,16,16,16,1448,16,156,188,1177,463,1424,16,1448,1424,298,463,1424,1448,427,1424,1448,16,16,463,427,1424,16,188, 463,1424,188,298,16,463,188,16,1424,16,463,156, 298,16,1177,\n",
    "            188,1424,1406,1424,427,1177,427,188,156,188,188,298,1424,156,188,156,156,298,1177,1177,298,1406,188,1424,188,16,1177,156,156,1424,1406,16,427,1406,188,1177,298,16,1424,427,156,427,\n",
    "            16,298,298,298,1424,463,1448,427,298,1448,156,1448,463,1448,298,298,427,427,427,1448,156,1177, \"\"]\n",
    "\n",
    "imageidx_neptune = [1177,1406,188,1177,1406,1406,1424,1406,188,298,298,188,1177,188,427,463,427,188,463,1424,188,298,427,1424,463,16,188,1177,1448,298,1406,427,298,1177,463,427,188,1177,1406,1424,\n",
    "                    1424,188,1448,16,16,298,188,1406,1424,156,16,1448,156,188,1424,1424,188,463,427,463,298,188,16,188,1424,1177,156,16,1406,156,427,1177,1424,16,298,298,463,16,463,1448,156,1448,16,\n",
    "                    156,188,1448,298,463,1424,16,1406,1406,1177,1424,1424,156,188,298,298,1448,298,156,1424,1406,16,16,427,1424,1406,463,156,188,1424,463,1424,427,427,16,298,298,427,1424,1177,427,156,\n",
    "                    427,1424,1424,16,1448,298,1424,1406,463,1406,188,156,1448,427,1406,427,427,1177,463,427,156,156,427,298,1177,\"\"]\n",
    "\n",
    "assert len(imageidx_elias) == 151 # check the length\n",
    "assert len(imageidx_neptune) == 151 # check the length\n",
    "\n",
    "unique_bg = sorted(np.unique(imageidx_elias)[1:].astype(int))\n",
    "\n",
    "bg_indices_elias = {bg: [] for bg in unique_bg}\n",
    "bg_indices_neptune = {bg: [] for bg in unique_bg}\n",
    "\n",
    "# sort backgrounds by indices \n",
    "for idx, bg in enumerate(imageidx_elias[:-1]):\n",
    "    bg_indices_elias[int(bg)].append(idx)\n",
    "\n",
    "for idx, bg in enumerate(imageidx_neptune[:-1]):\n",
    "    bg_indices_neptune[int(bg)].append(idx)\n",
    "    \n",
    "def extract_pred_by_bg (y_pred, test_indices, unique_bg, imageidx_elias, imageidx_neptune) :\n",
    "    # Return the proportion of prediction given by the model, by background category\n",
    "    # y_pred: predictions generated by the model (either 0 or 1) (len = 151)\n",
    "    # test_indices: indices used for test \n",
    "    # bg_indices: dict of indices by backgrounds \n",
    "\n",
    "    # extract the bg indices for test indices\n",
    "    bg_elias, bg_neptune = [imageidx_elias[idx] for idx in test_indices], [imageidx_neptune[idx] for idx in test_indices]\n",
    "    bg_combined = np.concatenate((bg_elias, bg_neptune))\n",
    "    # print(bg_combined)\n",
    "    bg_indices = {bg: [] for bg in unique_bg}\n",
    "    for idx, bg in enumerate(bg_combined):\n",
    "        if bg != '' :\n",
    "            bg_indices[int(bg)].append(idx)\n",
    "    \n",
    "    unique_indices = bg_indices.keys()\n",
    "    model_pred_bg_indices = {bg: [] for bg in unique_indices}\n",
    "\n",
    "    for idx in unique_indices :\n",
    "        model_pred = y_pred[bg_indices[idx]]\n",
    "        unique, counts = np.unique(model_pred, return_counts=True)\n",
    "        counts_dict = dict(zip(unique, counts))\n",
    "        # print(counts_dict)\n",
    "        count_0 = counts_dict.get(0.0, 0)\n",
    "        count_1 = counts_dict.get(1.0, 0)\n",
    "        model_pred_bg_indices[idx] = [count_0, count_1]\n",
    "    return model_pred_bg_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(os.listdir(\"/mnt/smb/locker/issa-locker/users/Seojin/scene_files/zback/\"))\n",
    "selected_files = [files[i] for i in unique_bg if i < len(files)]\n",
    "\n",
    "# Load and display the images\n",
    "for i, file in enumerate(selected_files):\n",
    "    image_path = os.path.join(\"/mnt/smb/locker/issa-locker/users/Seojin/scene_files/zback/\", file)\n",
    "    fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "    image = Image.open(image_path)\n",
    "    ax.imshow(np.array(image), cmap='gray')\n",
    "    ax.set_title(f\"bg{i+1}\", fontsize=20)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "[imageidx_elias[idx] for idx in test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d24ff8-6a8f-49c5-8b66-2df1cedd32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute i1 and i1_5rep\n",
    "num_rep = 100\n",
    "for data_root in useful_stats.keys():\n",
    "    for model_name in useful_stats[data_root].keys():\n",
    "        i1_dists = useful_stats[data_root][model_name]['dist']\n",
    "        avg_i1s = i1_dists.mean(1)\n",
    "        i1_dists = np.concatenate((i1_dists[0], i1_dists[1]), axis=1)\n",
    "        model_i1s = []\n",
    "        for rep_index in range(5):\n",
    "            np.random.shuffle(i1_dists)\n",
    "            tmp = np.concatenate([i1_dists[:int(num_rep/2)].mean(0), \n",
    "                                  i1_dists[int(num_rep/2):].mean(0)])\n",
    "            model_i1s.append(np.expand_dims(tmp, axis=0))\n",
    "        model_i1s = np.concatenate(model_i1s, axis=0)\n",
    "        \n",
    "        useful_stats[data_root][model_name]['i1_5rep'] = model_i1s\n",
    "        useful_stats[data_root][model_name]['i1'] = avg_i1s\n",
    "\n",
    "        # SL ------------------ Normalize???\n",
    "        useful_stats[data_root][model_name]['i1_5rep'] = NormalizeData(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1'] = NormalizeData(avg_i1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f83a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/']['rn50_preIN_texture_sizeVar_best'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('useful_stats_SL_20240715', 'wb') as f:\n",
    "    pickle.dump(useful_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff9d10-b5c7-453e-b6a2-da905a02e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('useful_stats_penn.pkl', 'wb') as f:\n",
    "    pickle.dump(useful_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406889d-883e-4fbf-8e11-157fe6325b56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print acc\n",
    "subset_list = [[0,2], [1,3], [4,5]]\n",
    "subset_name_list = ['normal_face', 'inverted_face', 'reverse_contrast']\n",
    "is_print_subset = True\n",
    "\n",
    "for data_root in useful_stats.keys():\n",
    "    print(data_root)\n",
    "    if data_root != '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_101/':\n",
    "\n",
    "        for model_name in useful_stats[data_root].keys():\n",
    "            # print acc\n",
    "            acc = useful_stats[data_root][model_name]['acc']\n",
    "            print(f\"{model_name}: %.4f%.4f\" % (acc[0]*100, acc[1]*100))\n",
    "            # print subset acc\n",
    "            tmp = useful_stats[data_root][model_name]['acc_per_img'].mean(0)\n",
    "            if is_print_subset:\n",
    "                tmp_group = tmp[:150].reshape(6,25).mean(axis=1)\n",
    "                for subset_id, subset in enumerate(subset_list):\n",
    "                    # get acc\n",
    "                    print(\"%s acc: %.4f\" % (subset_name_list[subset_id], tmp_group[subset].mean()*100))\n",
    "                    useful_stats[data_root][model_name][f'{subset_name_list[subset_id]}'] = tmp_group[subset].mean()\n",
    "                print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03b8b1-8e59-47bf-929d-2e19f60e8fe9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # train decoder on vbsl200, and test on vbsli*151\n",
    "# # vbsli* 151\n",
    "# data_root = '../../data/face_data/vbsl_151/'\n",
    "# exp_name_0 = '20211011_Var6vbsl_set0_im151_elias'\n",
    "# exp_name_1 = '20211011_Var6vbsl_set0_im151_neptune'\n",
    "\n",
    "# # vbsl 200\n",
    "# vbsl200_data_root = '../../data/face_data/vbsl_200_new_bg/'\n",
    "# vbsl200_exp_name_0 = '2022105_Var6vbsl_set0_im200_elias'\n",
    "# vbsl200_exp_name_1 = '2022105_Var6vbsl_set0_im200_neptune'\n",
    "\n",
    "# filename_postfix = ''\n",
    "# num_rep = 100\n",
    "\n",
    "# model_name_list = ['resnet50', 'alexnet', 'vggface',  # baseline\n",
    "#                     'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft', # stylized imagenet\n",
    "#                     'rn50_preIN_notexture_sizeVar_2losses',\n",
    "#                     'rn50_preIN_notexture_sizeVar_best', # basel - missing 3\n",
    "#                    'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'rn50_vbsl-dist-ft_epoch15'] # vbsl\n",
    "# dict_scores = {}\n",
    "# dict_i1_dists = {}\n",
    "# dict_conf_mat = {}\n",
    "# acc_per_img = {}\n",
    "\n",
    "# for model_name in model_name_list:\n",
    "#     # load feats for vbsl200\n",
    "#     _path = os.path.join(vbsl200_data_root, vbsl200_exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "#     print(f\"loading input_1 from {_path}\")\n",
    "#     input_1 = torch.load(_path)\n",
    "#     _path = os.path.join(vbsl200_data_root, vbsl200_exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "#     print(f\"loading input_2 from {_path}\")\n",
    "#     input_2 = torch.load(_path)\n",
    "#     input_1 = input_1.reshape(len(input_1), -1)\n",
    "#     input_2 = input_2.reshape(len(input_2), -1)\n",
    "#     print(input_1.shape, input_2.shape)\n",
    "#     output_1 = np.ones(len(input_1))\n",
    "#     output_2 = np.zeros(len(input_2))\n",
    "#     vbsl200_inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "#     vbsl200_outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "#     # load feats\n",
    "#     _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "#     print(f\"loading input_1 from {_path}\")\n",
    "#     input_1 = torch.load(_path)\n",
    "#     _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "#     print(f\"loading input_2 from {_path}\")\n",
    "#     input_2 = torch.load(_path)\n",
    "#     input_1 = input_1.reshape(len(input_1), -1)\n",
    "#     input_2 = input_2.reshape(len(input_2), -1)\n",
    "#     print(input_1.shape, input_2.shape)\n",
    "#     output_1 = np.ones(len(input_1))\n",
    "#     output_2 = np.zeros(len(input_2))\n",
    "#     inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "#     outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "#     half_size = int(vbsl200_inputs.shape[0]/2)\n",
    "#     X_test, y_test = inputs, outputs\n",
    "    \n",
    "#     ## init\n",
    "#     # [num_class, num_rep, num_img_per_class]\n",
    "#     # [2, 1000, 101]\n",
    "#     dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "#     all_scores = []\n",
    "#     acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "#     # iter thru num_rep\n",
    "#     conf_mat = np.zeros((2,2))\n",
    "#     for rep_index in tqdm(range(num_rep)):\n",
    "#         # fit model\n",
    "#         train_idx = np.random.choice(half_size*2, half_size, replace=False)\n",
    "#         X_train = vbsl200_inputs[train_idx]\n",
    "#         y_train = vbsl200_outputs[train_idx]\n",
    "#         clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "#                              tol=1e-4,\n",
    "#                              fit_intercept=True,\n",
    "#                              C=1.0,\n",
    "#                             max_iter = 20000)\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         # record score\n",
    "#         y_predict = clf.predict(X_test)\n",
    "#         _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "#         _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "#         conf_mat += _conf_mat\n",
    "#         scores.append(_score)\n",
    "#         _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "#         acc[0][rep_index] = _acc_per_img[:151]\n",
    "#         acc[1][rep_index] = _acc_per_img[151:]\n",
    "#         # record dist\n",
    "#         _class1_dist = clf.decision_function(input_1)\n",
    "#         dists[0][rep_index] = _class1_dist\n",
    "#         _class2_dist = clf.decision_function(input_2)\n",
    "#         dists[1][rep_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "\n",
    "#         all_scores.append(np.array(scores).mean())\n",
    "\n",
    "#     dists = dists/num_rep\n",
    "#     print(model_name, '%.6f%.6f'%(np.array(all_scores).mean()*100, np.array(all_scores).std()*100))\n",
    "\n",
    "#     dict_scores[model_name] = all_scores\n",
    "#     dict_i1_dists[model_name] = dists\n",
    "#     conf_mat = conf_mat / num_rep / 2\n",
    "#     dict_conf_mat[model_name] = conf_mat\n",
    "#     acc_per_img[model_name] = acc\n",
    "\n",
    "#     # record useful stats\n",
    "#     if data_root not in useful_stats:\n",
    "#         useful_stats[data_root] = {}\n",
    "#     if model_name not in useful_stats[data_root]:\n",
    "#         useful_stats[data_root][model_name] = {}\n",
    "\n",
    "#     useful_stats[data_root][model_name]['dist_vbsl200'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24024002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_list = ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d16344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) exp_names_list_GFR_21\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/'\n",
    "]\n",
    "\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_neptune/vbsle151_neptune_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_seojin/vbsle151_seojin_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_sophie/vbsle151_sophie_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_elias/vbsle151_elias_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_seojin/vbsle151_seojin_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_sophie/vbsle151_sophie_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_neptune/vbsle151_neptune_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_sophie/vbsle151_sophie_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_seojin/vbsle151_seojin_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_dan/vbsle151_dan_neutral'],\n",
    "                 ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_sophie/vbsle151_sophie_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_sreyas/vbsle151_sreyas_neutral'],\n",
    "                 ['vbsle151_dan/vbsle151_dan_neutral', 'vbsle151_younah/vbsle151_younah_neutral'],\n",
    "                 ['vbsle151_sreyas/vbsle151_sreyas_neutral', 'vbsle151_younah/vbsle151_younah_neutral']\n",
    "]\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17, 18, 19,20]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096addfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) exp_names_list_GFR_21_texture_colorbg\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'\n",
    "]\n",
    "\n",
    "\n",
    "exp_name_list = [\n",
    "                ['vbsl151_elias_neutral', 'vbsl151_neptune_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_seojin_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_sophie_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_elias_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_seojin_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_sophie_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_neptune_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_sophie_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_seojin_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_sophie_neutral', 'vbsl151_dan_neutral'],\n",
    "                 ['vbsl151_sophie_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_sophie_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_dan_neutral', 'vbsl151_sreyas_neutral'],\n",
    "                 ['vbsl151_dan_neutral', 'vbsl151_younah_neutral'],\n",
    "                 ['vbsl151_sreyas_neutral', 'vbsl151_younah_neutral']\n",
    "]\n",
    "\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0, 1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17, 18, 19,20]:\n",
    "# for dataset_index in [3,4,5]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_elias, imageidx_neptune)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c64593-bf58-4b43-bd9d-d2711af51504",
   "metadata": {
    "tags": []
   },
   "source": [
    "# compare model and bio i1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012b82e-f2a0-46d9-88bf-48b4a5097d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_stats = {}\n",
    "import pickle\n",
    "with open('useful_stats_penn.pkl', 'rb') as f:\n",
    "    useful_stats = pickle.load(f)\n",
    "    \n",
    "# hierachy: [task_dir][model_name][acc/acc_per_img/dist/i1]\n",
    "# acc [list]: acc over all datapoints and trails -> [acc_mean, acc_std]\n",
    "# acc_per_img [array]: acc per image averaged over all trails -> shape [2, num_img_per_class]\n",
    "# dist [array]: all svm distance (note that the second class dist is negated) -> shape [2, num_repetition, num_img_per_class]\n",
    "# i1_5rep [array]: random split-half i1 with 5 repetition -> shape [5, 2*num_img_per_class]\n",
    "# i1 [array]: model i1 (the same as dist averaging over trails) -> shape [2, num_img_per_class]\n",
    "# i1_corr [list]: model i1 correlation with bio systems. For vbsl101, the order is [Bourgeois, Sausage, AJ]. \n",
    "# For vbsl151, the order is [Human, AJ]. For each corr, I record [i1_corr_mean, i1_corr_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc396eba-8c31-4321-9ec8-49b8809a3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f3fd1-2d8c-421d-ad36-6c9e92a64190",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e52f2-8928-4827-a4b7-16323fef2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_upright_5rep_604(array): # (5, 604) to (5, 200)\n",
    "    return np.concatenate([array[:, 0:25], array[:, 50:75], \n",
    "                            array[:, 151:151+25], array[:, 151+50:151+75], \n",
    "                            array[:, 302:302+25], array[:, 302+50:302+75], \n",
    "                            array[:, 302+151:302+151+25], array[:, 302+151+50:302+151+75], ], axis=1) \n",
    "\n",
    "# -------------- SL -----------------\n",
    "def subset_inverted_5rep_604(array): # (5, 604) to (5, 200)\n",
    "    return np.concatenate([array[:, 25:50], array[:, 75:100], \n",
    "                            array[:, 151+25:151+50], array[:, 151+75:151+100], \n",
    "                            array[:, 302+25:302+50], array[:, 302+75:302+100], \n",
    "                            array[:, 302+151+25:302+151+50], array[:, 302+151+75:302+151+100], ], axis=1) \n",
    "\n",
    "# -------------- SL -----------------\n",
    "def subset_reverse_contrast_5rep_604(array): # (5, 604) to (5, 200)\n",
    "    return np.concatenate([array[:, 100:150],  \n",
    "                            array[:, 151+100:151+150],  \n",
    "                            array[:, 302+100:302+150], \n",
    "                            array[:, 302+151+100:302+151+150], ], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ea52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats[data_root][model_name]['i1_5rep'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca76d35-359d-4ad6-9cdd-9e951416d078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## compute i1 corr\n",
    "\n",
    "upright_only = False  # set true to compute for only upright images of vbsli*\n",
    "\n",
    "bio_i1s_list = [human_i1_5rep, marmoset_i1_5rep]\n",
    "# bio_i1s_list = [human_i1_5rep]\n",
    "# bio_i1s_list = [human_i1s_vbsl]\n",
    "bio_i1s_list = [human_i1s_obj_vbsl151]\n",
    "\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "\n",
    "# SL\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'\n",
    "\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/'\n",
    "\n",
    "# model_name_list = ['resnet50_layer1']\n",
    "# model_name_list = ['resnet50', 'resnet50_layer1'] # SL\n",
    "# #SL\n",
    "# model_name_list = [\"resnet50\", \"resnet50_layer1\", \"resnet50_layer2\", \n",
    "#                     \"resnet50_layer3\", \"resnet50_layer4_no_pooling\"]\n",
    "# model_name_list = [\"rn50_preIN_texture_sizeVar_best\", \"rn50_preIN_notexture_sizeVar_best\", \"resnet50-trained-pretrained-vbsl\", \"rn50_vbsl-dist-ft_epoch15\"]\n",
    "\n",
    "# model_name_list = ['pixel', 'resnet50', 'alexnet', 'vggface',  # baseline\n",
    "#                     'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft', # stylized imagenet\n",
    "#                     'rn50_preIN_notexture_sizeVar_best', 'rn50_preIN_texture_sizeVar_best', # basel finetuned\n",
    "#                    'rn50_FromScratch_notexture_sizeVar_best', 'rn50_FromScratch_texture_sizeVar_best', # basel FromScratch\n",
    "#                     'rn50_preIN_notexture_sizeVar_2losses', # DepthMap prediction\n",
    "#                    'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'rn50_vbsl-dist-ft_epoch15'] # vbsl\n",
    "\n",
    "# model_name_list = ['Basel_50k_2id',]\n",
    "# model_name_list = []\n",
    "# for i in range(41):\n",
    "#     step = (i+1)*15\n",
    "#     model_name_list.append(f'vbsl50k_step{step}')\n",
    "#     # model_name_list.append(f'vbsl50kobj_step{step}')\n",
    "\n",
    "# model_name_list = ['pixel'', resnet50', 'alexnet', 'vggface',  # baseline\n",
    "#                     'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft', # stylized imagenet\n",
    "#                     'rn50_preIN_notexture_sizeVar_best', 'rn50_preIN_texture_sizeVar_best', # basel finetuned\n",
    "#                    'rn50_FromScratch_notexture_sizeVar_best', 'rn50_FromScratch_texture_sizeVar_best', # basel FromScratch\n",
    "#                     'rn50_preIN_notexture_sizeVar_2losses', # DepthMap prediction\n",
    "#                    'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'rn50_vbsl-dist-ft_epoch15'] # vbsl\n",
    "# model_name_list = ['vbsl50k_subset_0.5', 'vbsl50k_subset_0.25', 'vbsl50k_subset_0.1', 'vbsl50k_subset_0.05']\n",
    "### intermediate layers\n",
    "# model_name_list = ['resnet50', \"resnet50_layer1\", \"resnet50_layer2\", \"resnet50_layer3\", \"resnet50_layer4_no_pooling\", \n",
    "#                    \"resnet50-trained-pretrained-vbsl\",\n",
    "#                        \"resnet50-trained-pretrained-vbsl_layer1\", \"resnet50-trained-pretrained-vbsl_layer2\", \n",
    "#                     \"resnet50-trained-pretrained-vbsl_layer3\", \"resnet50-trained-pretrained-vbsl_layer4_no_pooling\"]\n",
    "# model_name_list = ['rn50_preIN_texture_sizeVar_best',\n",
    "#                    'rn50_FromScratch_texture_sizeVar_best', 'rn50_FromScratch_notexture_sizeVar_best']\n",
    "\n",
    "### tuning epochs\n",
    "# model_name_list = ['resnet50']\n",
    "# for i in range(24):\n",
    "#     model_names_list.append(f'PennTuning-face-epoch{i}')\n",
    "#     model_name_list.append(f'PennTuning-obj-epoch{i}')\n",
    "\n",
    "for model_name in model_names_list:\n",
    "    # get model i1s\n",
    "    model_i1s = useful_stats[data_root][model_name]['i1_5rep']\n",
    "    if upright_only:\n",
    "        model_i1s = subset_upright_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_upright'] = np.zeros((len(bio_i1s_list), 2))\n",
    "    else:\n",
    "        useful_stats[data_root][model_name]['i1_corr'] = np.zeros((len(bio_i1s_list), 2))\n",
    "    for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "        # get bio i1s\n",
    "        bio_i1s = bio_i1s.squeeze()\n",
    "        #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "        bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "        if upright_only:\n",
    "            bio_i1s = subset_upright_5rep_604(bio_i1s)\n",
    "        i1_corr = []\n",
    "        half_length = int(model_i1s.shape[1]/2)\n",
    "        bio_internal = []\n",
    "        for rep_index in range(5):\n",
    "            corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "            corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "            corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "            corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "            print(corr_1, corr_2, corr_3, corr_4, 0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "            i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "            bio_internal.append(corr_4)\n",
    "        if upright_only:\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "        else:\n",
    "            useful_stats[data_root][model_name]['i1_corr'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "\n",
    "    # ------------------------------- SL -------------------------------\n",
    "    model_i1s_concat = np.concatenate((useful_stats[data_root][model_name]['i1'][0], useful_stats[data_root][model_name]['i1'][1]))\n",
    "    useful_stats[data_root][model_name]['i1_corr_diff_per_img'] = [np.zeros(len(model_i1s_concat)), np.zeros(len(model_i1s_concat))]\n",
    "    for img_index, model_i1_per_img in enumerate(model_i1s_concat) :\n",
    "            useful_stats[data_root][model_name]['i1_corr_diff_per_img'][0][img_index] = 1 - np.abs(model_i1s_concat[img_index] - human_i1[img_index])\n",
    "            useful_stats[data_root][model_name]['i1_corr_diff_per_img'][1][img_index] = 1 - np.abs(model_i1s_concat[img_index] - marmoset_i1[img_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c09dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_upright = True\n",
    "compute_inverted = True\n",
    "compute_reverse_contrast = True \n",
    "\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/'\n",
    "bio_i1s_list = [human_i1_5rep, marmoset_i1_5rep]\n",
    "# bio_i1s_list = [human_i1_5rep]\n",
    "# bio_i1s_list = [human_i1s_vbsl]\n",
    "bio_i1s_list = [human_i1s_obj_vbsl151]\n",
    "\n",
    "# i1 corr - upright only \n",
    "for model_name in model_names_list:\n",
    "    # get model i1s\n",
    "    if compute_upright :\n",
    "        model_i1s = useful_stats[data_root][model_name]['i1_5rep'] \n",
    "        model_i1s = subset_upright_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_upright'] = np.zeros((len(bio_i1s_list), 2))\n",
    "        for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "            bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "            bio_i1s = subset_upright_5rep_604(bio_i1s)\n",
    "            print(model_name, bio_index)\n",
    "            i1_corr = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            bio_internal = []\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                print(corr_1, corr_2, corr_3, corr_4, 0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                bio_internal.append(corr_4)\n",
    "\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "\n",
    "    if compute_inverted : \n",
    "        model_i1s = useful_stats[data_root][model_name]['i1_5rep']\n",
    "        model_i1s = subset_inverted_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_inverted'] = np.zeros((len(bio_i1s_list), 2))\n",
    "\n",
    "        for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "            bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "            bio_i1s = subset_inverted_5rep_604(bio_i1s)\n",
    "            print(model_name, bio_index)\n",
    "            i1_corr = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            bio_internal = []\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                print(corr_1, corr_2, corr_3, corr_4)\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                bio_internal.append(corr_4)\n",
    "\n",
    "\n",
    "            # print(np.mean(np.array(bio_internal)), np.std(np.array(bio_internal)))\n",
    "    \n",
    "            useful_stats[data_root][model_name]['i1_corr_inverted'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_inverted'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "\n",
    "    if compute_reverse_contrast : \n",
    "        model_i1s = useful_stats[data_root][model_name]['i1_5rep']\n",
    "        model_i1s = subset_reverse_contrast_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_reverse_contrast'] = np.zeros((len(bio_i1s_list), 2))\n",
    "        for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "            bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "            bio_i1s = subset_reverse_contrast_5rep_604(bio_i1s)\n",
    "            print(model_name, bio_index)\n",
    "            i1_corr = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            bio_internal = []\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                print(corr_1, corr_2, corr_3, corr_4, 0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                bio_internal.append(corr_4)\n",
    "\n",
    "            # print(np.mean(np.array(bio_internal)), np.std(np.array(bio_internal)))\n",
    "    \n",
    "            useful_stats[data_root][model_name]['i1_corr_reverse_contrast'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_reverse_contrast'][bio_index][1] = np.std(np.array(i1_corr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9938dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import pickle\n",
    "with open('useful_stats_SL_20240723.pkl', 'wb') as f:\n",
    "    pickle.dump(useful_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062b621-f586-47d9-845d-c9fd7e9655db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import pickle\n",
    "with open('useful_stats_penn.pkl', 'wb') as f:\n",
    "    pickle.dump(useful_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ed325",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/']['SL_resnet50_finetune_vbsl_50k_seed77_model_best']['i1_corr_reverse_contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a664d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20c10c-6f3d-44c0-bef1-58157d453b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print acc and i1s\n",
    "# data_root = '../../data/face_data/vbsl_151/'\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/control_exp/objs/'\n",
    "\n",
    "# model_name_list = ['resnet50', 'alexnet', 'vggface',  # baseline\n",
    "#                     'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft', # stylized imagenet\n",
    "#                     'rn50_preIN_notexture_sizeVar_best', 'rn50_preIN_texture_sizeVar_best', # basel finetuned\n",
    "#                    'rn50_FromScratch_notexture_sizeVar_best', 'rn50_FromScratch_texture_sizeVar_best', # basel FromScratch\n",
    "#                     'rn50_preIN_notexture_sizeVar_2losses', # DepthMap prediction\n",
    "#                    'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'rn50_vbsl-dist-ft_epoch15'] # vbsl\n",
    "# model_name_list = ['vbsl50k_subset_0.5', 'vbsl50k_subset_0.25', 'vbsl50k_subset_0.1', 'vbsl50k_subset_0.05']\n",
    "# model_name_list = ['Basel_50k_2id',]\n",
    "# model_name_list = []\n",
    "# for i in range(41):\n",
    "#     step = (i+1)*15\n",
    "#     model_name_list.append(f'vbsl50k_step{step}')\n",
    "#     # model_name_list.append(f'vbsl50kobj_step{step}')\n",
    "# model_name_list = ['pixel']\n",
    "# model_name_list = ['resnet50', 'resnet50_layer1'] # SL\n",
    "# model_name_list = [\"resnet50\", \"resnet50_layer1\", \"resnet50_layer2\", \n",
    "#                     \"resnet50_layer3\", \"resnet50_layer4_no_pooling\"]\n",
    "# model_name_list = [\"rn50_preIN_texture_sizeVar_best\", \"rn50_preIN_notexture_sizeVar_best\", \"resnet50-trained-pretrained-vbsl\", \"rn50_vbsl-dist-ft_epoch15\"]\n",
    "\n",
    "acc_list = []\n",
    "acc_std_list = []\n",
    "\n",
    "\n",
    "i1_corr_human_list = []\n",
    "i1_corr_human_list_upright, i1_corr_human_list_inverted, i1_corr_human_list_reverse_contrast = [], [], []\n",
    "\n",
    "i1_corr_std_human_list = []\n",
    "i1_corr_std_human_list_upright, i1_corr_std_human_list_inverted, i1_corr_std_human_list_reverse_contrast = [], [], []\n",
    "\n",
    "i1_corr_AJ_list = []\n",
    "i1_corr_AJ_list_upright, i1_corr_AJ_list_inverted, i1_corr_AJ_list_reverse_contrast = [], [], []\n",
    "\n",
    "i1_corr_std_AJ_list = []\n",
    "i1_corr_std_AJ_list_upright, i1_corr_std_AJ_list_inverted, i1_corr_std_AJ_list_reverse_contrast = [], [], []\n",
    "\n",
    "for model_name in model_names_list:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_corr_upright = useful_stats[data_root][model_name]['i1_corr_upright']\n",
    "    i1_corr_inverted = useful_stats[data_root][model_name]['i1_corr_inverted']\n",
    "    i1_corr_reverse_contrast = useful_stats[data_root][model_name]['i1_corr_reverse_contrast']\n",
    "    print(i1_corr_reverse_contrast)\n",
    "    acc = useful_stats[data_root][model_name]['acc']\n",
    "    acc_list.append(acc[0])\n",
    "    acc_std_list.append(acc[1])\n",
    "    # print stats\n",
    "    print(f\"{model_name}\")\n",
    "    print(\"acc: %.6f%.6f\" % (acc[0],acc[1]))\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr):\n",
    "        print(f\"i1 #{i1_index}: %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list.append(cur_i1[0])\n",
    "            i1_corr_std_human_list.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list.append(cur_i1[1])\n",
    "    # ------------------ SL --------------------------\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr_upright):\n",
    "        print(f\"i1 #{i1_index} (upright): %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list_upright.append(cur_i1[0])\n",
    "            i1_corr_std_human_list_upright.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list_upright.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list_upright.append(cur_i1[1])\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr_inverted):\n",
    "        print(f\"i1 #{i1_index} (inverted): %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list_inverted.append(cur_i1[0])\n",
    "            i1_corr_std_human_list_inverted.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list_inverted.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list_inverted.append(cur_i1[1])\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr_reverse_contrast):\n",
    "        print(f\"i1 #{i1_index} (reverse contrast): %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list_reverse_contrast.append(cur_i1[0])\n",
    "            i1_corr_std_human_list_reverse_contrast.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list_reverse_contrast.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list_reverse_contrast.append(cur_i1[1])\n",
    "    # ------------------------------------------------\n",
    "       \n",
    "    # print subset acc\n",
    "    tmp = useful_stats[data_root][model_name]['acc_per_img'].mean(0)\n",
    "    if is_print_subset:\n",
    "        tmp_group = tmp[:150].reshape(6,25).mean(axis=1)\n",
    "        for subset_id, subset in enumerate(subset_list):\n",
    "            # get acc\n",
    "            print(\"%s acc: %.4f\" % (subset_name_list[subset_id], tmp_group[subset].mean()*100))\n",
    "    print()\n",
    "    # print(f\"{model_name} \\n%.2f/%.2f/%.2f\" % (i1_corr[0][0], i1_corr[1][0], i1_corr[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708ef26-e04b-4e15-bdc0-656ca55b7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for IDs ablation\n",
    "results_acc = np.array([[66.8236, 62.4998, 62.3229],\n",
    "                       [65.0423, 63.9602, 63.9973],\n",
    "                       [63.2063, 64.2012, 61.3207],\n",
    "                       [64.2957, 66.7939, 62.9402]])\n",
    "results_i1s = np.array([[0.000691, 0.021171, 0.023820],\n",
    "                       [0.062417, 0.070766, 0.108321],\n",
    "                       [0.105385, 0.058539, 0.005559],\n",
    "                       [0.136031, 0.195483, 0.081920]])\n",
    "xx = [\"2\",\"4\",\"6\",\"8\"]\n",
    "plt.errorbar(xx, results_acc.mean(1), yerr=results_acc.std(1))\n",
    "plt.title(\"Num IDs Ablation\")\n",
    "plt.xlabel(\"Num of IDs\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.show()\n",
    "\n",
    "xx = [\"2\",\"4\",\"6\",\"8\"]\n",
    "plt.errorbar(xx, results_i1s.mean(1), yerr=results_i1s.std(1))\n",
    "plt.title(\"Num IDs Ablation\")\n",
    "plt.xlabel(\"Num of IDs\")\n",
    "plt.ylabel(\"i1s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9507c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "models = [\"resnet50\", \"resnet50-layer1\", \"resnet50-layer2\", \"resnet50-layer3\", \"resnet50-layer4-no-pooling\"]\n",
    "models = [\"finetuned-Basel\", \"finetuned-Basel-NoTexture\", \"finetuned-AppleFaces\", \"finetuned-AppleFaces-dist\"]\n",
    "models = [\"finetuned-AppleFaces50k\", \"finetuned-Object50k\", \"vanilla resnet\"]\n",
    "# models = []\n",
    "\n",
    "# for model_name in model_names_list :\n",
    "#     models.append(model_name.split(\"-\")[-1])\n",
    "\n",
    "plt.figure(figsize=(8, 8))  \n",
    "acc_list = [69.7722/100, 85.6704/100,72.5794/100]\n",
    "acc_std_list = [2.2411/100, 1.4935/100, 2.2267/100]\n",
    "bars = plt.bar(models, acc_list, yerr=acc_std_list, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"accuracy\", fontsize=20)\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "plt.ylim(0.0, 1.05)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, accuracy\", fontsize=20)\n",
    "plt.title(\"ResNet50, tested on GOR vbsli*151\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "models = [\"finetuned-AppleFaces50k\", \"finetuned-Object50k\", \"vanilla resnet50\"]\n",
    "# Dummy data for demonstration purposes\n",
    "# Define the position of the bars\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "acc_list_upright = [val / 100 for val in [71.23,97.57,75.241]]\n",
    "                    # [71.23,97.57,74.38]]\n",
    "acc_list_inverted = [val / 100 for val in [70.83,83.6,71.79]]\n",
    "    # [70.83,83.6,71.2]]\n",
    "acc_list_reverse_contrast = [val / 100 for val in [67.55,75.61,70.56]]\n",
    "# [67.55,75.61,70.22]]\n",
    "\n",
    "# Plotting each set of bars\n",
    "bars0 = ax.bar(x - width * 1.5, acc_list, width,label='all', color='blue', alpha=1.0, capsize=5)\n",
    "bars1 = ax.bar(x - width * 0.5 , acc_list_upright, width,label='upright', color='blue', alpha=0.65, capsize=5)\n",
    "bars2 = ax.bar(x +  width * 0.5, acc_list_inverted, width,  label='inverted', color='blue', alpha=0.3, capsize=5)\n",
    "bars3 = ax.bar(x + width * 1.5, acc_list_reverse_contrast, width, label='reverse contrast', color='blue', alpha=0.1, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bars in [bars0, bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models', fontsize=18)\n",
    "ax.set_ylabel('Accuracy', fontsize=18)\n",
    "ax.set_title('Fine-tuned and vanilla ResNet50, tested on GOR vbsli*151', fontsize=22)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "ax.legend(fontsize=15, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f73dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becdaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "\n",
    "acc_list_upright = [val/100 for val in [98.65,65.91]]\n",
    "acc_std_list_upright = []\n",
    "acc_list_inverted = [val/100 for val in [76.39,61.16]]\n",
    "acc_std_list_inverted = []\n",
    "acc_list_reverse_contrast = [val/100 for val in [82.37,52.9]]\n",
    "acc_std_list_reverse_contrast = []\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, acc_list_upright, capsize=5)\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list_upright):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"acc\", fontsize=20)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50 (upright only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, acc_list_inverted, capsize=5)\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list_inverted):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "# plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"acc\", fontsize=20)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50 (inverted only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, acc_list_reverse_contrast, capsize=5)\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list_reverse_contrast):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"acc\", fontsize=20)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, (reverse contrast only)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19431808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "plt.figure(figsize=(7, 8)) \n",
    "i1_corr_human_list = [0.356536,0.398955,0.418159]\n",
    "i1_corr_std_human_list = [0.023619, 0.020221, 0.021829]\n",
    "# [0.023619, 0.020221, 0.023948]\n",
    "bars = plt.bar(models, i1_corr_human_list, yerr=i1_corr_std_human_list, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "#plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=15)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(-0.15, 1.05)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GOR vbsli* 151\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------- SL -------------------------------------\n",
    "plt.figure(figsize=(7, 8))  \n",
    "\n",
    "bars = plt.bar(models, i1_corr_AJ_list, yerr=i1_corr_std_AJ_list, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_AJ_list):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "#plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, marmoset i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GOR vbsli* 151\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d0b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "i1_corr_human_list_upright = [0.42481,0.512017,0.349363]\n",
    "# [0.424810,0.512017,0.347575]\n",
    "i1_corr_std_human_list_upright = [0.472004,0.392035,0.493194]\n",
    "# [0.035555, 0.030237, 0.031485]\n",
    "i1_corr_human_list_inverted = [0.472004,0.392035,0.493194]\n",
    "# [0.035555, 0.030237, 0.031485]\n",
    "i1_corr_std_human_list_inverted = [0.015472,0.037951,0.019945]\n",
    "# [0.034771,0.033141, 0.029989]\n",
    "i1_corr_human_list_reverse_contrast = [0.306668,0.319522,0.416907]\n",
    "i1_corr_std_human_list_reverse_contrast = [0.007847, 0.017272, 0.011585]\n",
    "# [0.010393,0.007654,0.014628]\n",
    "\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, i1_corr_human_list_upright, yerr=i1_corr_std_human_list_upright, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list_upright):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=15)\n",
    "\n",
    "#plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=15)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GOR\\nvbsli*151, (upright only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, i1_corr_human_list_inverted, yerr=i1_corr_std_human_list_inverted, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list_inverted):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=15)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GFR\\nvbsli*151, (inverted only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, i1_corr_human_list_reverse_contrast, yerr=i1_corr_std_human_list_reverse_contrast, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list_reverse_contrast):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=15)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GFR\\nvbsli*151, (reverse contrast only)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7bd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "models = [\"finetuned-AppleFaces50k\", \"finetuned-Object50k\", \"vanilla resnet\"]\n",
    "i1_corr_human_list = [0.356536,0.398955,0.418159]\n",
    "# Define the position of the bars\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "# Plotting each set of bars\n",
    "bars0 = ax.bar(x - width * 1.5, i1_corr_human_list, width,label='all', color='green', alpha=1.0, capsize=5)\n",
    "bars1 = ax.bar(x - width * 0.5 , i1_corr_human_list_upright, width,label='upright', color='green', alpha=0.65, capsize=5)\n",
    "bars2 = ax.bar(x +  width * 0.5, i1_corr_human_list_inverted, width,  label='inverted', color='green', alpha=0.3, capsize=5)\n",
    "bars3 = ax.bar(x + width * 1.5, i1_corr_human_list_reverse_contrast, width, label='reverse contrast', color='green', alpha=0.1, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bars in [bars0, bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models', fontsize=18)\n",
    "ax.set_ylabel('i1', fontsize=18)\n",
    "ax.set_title('Finetuned ResNet50, tested on GOR vbsli*151', fontsize=22)\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_xticklabels([label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "ax.legend(fontsize=15, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.ylim(-0.15, 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "\n",
    "\n",
    "plt.errorbar(models, i1_corr_human_list, yerr=i1_corr_std_human_list)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right')\n",
    "\n",
    "plt.xlabel(\"model\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\")\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\")\n",
    "plt.title(\"AppleFaces (no texture), human i1 corr\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# SL\n",
    "\n",
    "plt.errorbar(models, i1_corr_AJ_list, yerr=i1_corr_std_AJ_list)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right')\n",
    "\n",
    "plt.xlabel(\"model\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\")\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, marmoset i1 corr\")\n",
    "plt.title(\"AppleFaces (no texture), marmoset i1 corr\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc71c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.errorbar(models, i1_corr_human_list, yerr=i1_corr_std_human_list, label='human_i1', color='blue')\n",
    "plt.errorbar(models, i1_corr_AJ_list, yerr=i1_corr_std_AJ_list, label='marmoset_i1', color='orange')\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right')\n",
    "\n",
    "plt.xlabel(\"model\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\")\n",
    "plt.legend()\n",
    "plt.title(\"AppleFaces (no texture), human and marmoset i1 corr\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737cb7f4",
   "metadata": {},
   "source": [
    "### SL - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc45491",
   "metadata": {},
   "outputs": [],
   "source": [
    "elias_acc = useful_stats[data_root][model_name]['acc_per_img'][0]\n",
    "neptune_acc = useful_stats[data_root][model_name]['acc_per_img'][1]\n",
    "combined_acc = np.concatenate((elias_acc, neptune_acc))\n",
    "\n",
    "acc_top_idx = np.argsort(combined_acc)[-20:][::-1]\n",
    "acc_top_val = combined_acc[acc_top_idx]\n",
    "acc_top = list(zip(acc_top_idx, acc_top_val))\n",
    "acc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats_top_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa491925",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(human_i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vbsl151 -- Highest and lowest accuracy per model \n",
    "useful_stats_top_bottom = {}\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'\n",
    "human_i1_top_idx, human_i1_bottom_idx = np.argsort(human_i1)[-15:][::-1], np.argsort(human_i1)[:15]\n",
    "human_i1_top_val, human_i1_bottom_val  = human_i1[human_i1_top_idx], human_i1[human_i1_bottom_idx]\n",
    "human_i1_top, human_i1_bottom = list(zip(human_i1_top_idx, human_i1_top_val)), list(zip(human_i1_bottom_idx, human_i1_bottom_val))\n",
    "\n",
    "for model_name in [\"human\"] :\n",
    "    useful_stats_top_bottom[model_name] = {\n",
    "        'top' : {\n",
    "            'acc' : [[],[]],\n",
    "            'acc_u' : [[],[]],\n",
    "            'acc_i' : [[],[]],\n",
    "            'acc_rc' : [[],[]],\n",
    "            'human_i1' : [[],[]],\n",
    "            'marmoset_i1' : [[],[]],\n",
    "        },\n",
    "        'bottom'  : {\n",
    "            'acc' : [[],[]],\n",
    "            'acc_u' : [[],[]],\n",
    "            'acc_i' : [[],[]],\n",
    "            'acc_rc' : [[],[]],\n",
    "            'human_i1' : [[],[]],\n",
    "            'marmoset_i1' : [[],[]],\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    combined_idx = np.arange(0, 302)\n",
    "    combined_idx_u = np.concatenate([np.arange(0, 25), np.arange(50,75), np.arange(151,151+25), np.arange(151+50, 151+75)])\n",
    "    combined_idx_i = np.concatenate([np.arange(25, 50), np.arange(75,100), np.arange(151+25,151+50), np.arange(151+75, 151+100)])\n",
    "    combined_idx_rc = np.concatenate([np.arange(100, 150), np.arange(151+100,151+150)])\n",
    "\n",
    "    human_i1_u = human_i1[combined_idx_u]\n",
    "    human_i1_i = human_i1[combined_idx_i]\n",
    "    human_i1_rc = human_i1[combined_idx_rc]\n",
    "\n",
    "    random.Random(4).shuffle(combined_idx)\n",
    "    random.Random(4).shuffle(combined_acc)\n",
    "    \n",
    "\n",
    "    acc_top_idx, acc_bottom_idx = combined_idx[np.argsort(human_i1)[-15:][::-1]], combined_idx[np.argsort(human_i1)[:15]]\n",
    "    acc_top_idx_u, acc_bottom_idx_u = combined_idx_u[np.argsort(human_i1_u)[-5:][::-1]], combined_idx_u[np.argsort(human_i1_u)[:5]]\n",
    "    acc_top_idx_i, acc_bottom_idx_i = combined_idx_i[np.argsort(human_i1_i)[-5:][::-1]], combined_idx_i[np.argsort(human_i1_i)[:5]]\n",
    "    acc_top_idx_rc, acc_bottom_idx_rc = combined_idx_rc[np.argsort(human_i1_rc)[-5:][::-1]], combined_idx_rc[np.argsort(human_i1_rc)[:5]]\n",
    "\n",
    "    acc_top_val, acc_bottom_val = human_i1[acc_top_idx], human_i1[acc_bottom_idx]\n",
    "    acc_top_val_u, acc_bottom_val_u = human_i1[acc_top_idx_u], human_i1[acc_bottom_idx_u]\n",
    "    acc_top_val_i, acc_bottom_val_i = human_i1[acc_top_idx_i], human_i1[acc_bottom_idx_i]\n",
    "    acc_top_val_rc, acc_bottom_val_rc = human_i1[acc_top_idx_rc], human_i1[acc_bottom_idx_rc]\n",
    "\n",
    "    acc_top, acc_bottom = list(zip(acc_top_idx, acc_top_val)), list(zip(acc_bottom_idx, acc_bottom_val))\n",
    "    acc_top_u, acc_bottom_u = list(zip(acc_top_idx_u, acc_top_val_u)), list(zip(acc_bottom_idx_u, acc_bottom_val_u))\n",
    "    acc_top_i, acc_bottom_i = list(zip(acc_top_idx_i, acc_top_val_i)), list(zip(acc_bottom_idx_i, acc_bottom_val_i))\n",
    "    acc_top_rc, acc_bottom_rc = list(zip(acc_top_idx_rc, acc_top_val_rc)), list(zip(acc_bottom_idx_rc, acc_bottom_val_rc))\n",
    "\n",
    "    useful_stats_top_bottom[model_name]['top']['acc'] = acc_top\n",
    "    useful_stats_top_bottom[model_name]['top']['acc_u'] = acc_top_u\n",
    "    useful_stats_top_bottom[model_name]['top']['acc_i'] = acc_top_i\n",
    "    useful_stats_top_bottom[model_name]['top']['acc_rc'] = acc_top_rc\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc'] = acc_bottom\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc_u'] = acc_bottom_u\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc_i'] = acc_bottom_i\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc_rc'] = acc_bottom_rc\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "\n",
    "# Function to get the image paths based on the index\n",
    "def get_image_path(idx):\n",
    "    if idx < 151:\n",
    "        return f\"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_elias/trialnum{idx}.png\"\n",
    "    else:\n",
    "        return f\"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_neptune/trialnum{idx-151}.png\"\n",
    "\n",
    "# Displaying the images\n",
    "for model_name in [\"human\"]:\n",
    "    # Get the top 10 and bottom 10 image paths\n",
    "    \n",
    "    top_image_paths = [get_image_path(idx) for idx, _ in human_i1_top]\n",
    "    bottom_image_paths = [get_image_path(idx) for idx, _ in human_i1_bottom]\n",
    "\n",
    "    # Concatenate the top 10 images\n",
    "    top_concatenated_image = concatenate_images(top_image_paths)\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.imshow(top_concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths)} images for human\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths, human_i1_top)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, top_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Concatenate the bottom 10 images\n",
    "    bottom_concatenated_image = concatenate_images(bottom_image_paths)\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.imshow(bottom_concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(top_image_paths)} images for human\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths, human_i1_bottom)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, bottom_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(model_name)\n",
    "    acc_top_u, acc_top_i, acc_top_rc = useful_stats_top_bottom[model_name]['top']['acc_u'], useful_stats_top_bottom[model_name]['top']['acc_i'], useful_stats_top_bottom[model_name]['top']['acc_rc']\n",
    "    acc_bottom_u, acc_bottom_i, acc_bottom_rc = useful_stats_top_bottom[model_name]['bottom']['acc_u'], useful_stats_top_bottom[model_name]['bottom']['acc_i'], useful_stats_top_bottom[model_name]['bottom']['acc_rc']\n",
    "\n",
    "    top_image_paths_u, top_image_paths_i, top_image_paths_rc  = [get_image_path(idx) for idx, _ in acc_top_u], [get_image_path(idx) for idx, _ in acc_top_i], [get_image_path(idx) for idx, _ in acc_top_rc]\n",
    "    bottom_image_paths_u, bottom_image_paths_i, bottom_image_paths_rc  = [get_image_path(idx) for idx, _ in acc_bottom_u], [get_image_path(idx) for idx, _ in acc_bottom_i], [get_image_path(idx) for idx, _ in acc_bottom_rc]\n",
    "\n",
    "    acc_top_u_concat, acc_top_i_concat, acc_top_rc_concat = concatenate_images(top_image_paths_u), concatenate_images(top_image_paths_i), concatenate_images(top_image_paths_rc)\n",
    "    acc_bottom_u_concat, acc_bottom_i_concat, acc_bottom_rc_concat = concatenate_images(bottom_image_paths_u), concatenate_images(bottom_image_paths_i), concatenate_images(bottom_image_paths_rc)\n",
    "    # upright\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_top_u_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths_u)} upright for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths_u, acc_top_u)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_top_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # inverted\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_top_i_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths_i)} inverted for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths_i, acc_top_i)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_top_i_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # reverse contrast\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_top_rc_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths_rc)} reverse contrast for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths_rc, acc_top_rc)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_top_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #-------------- BOTTOM -------------------\n",
    "    # upright\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_bottom_u_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(bottom_image_paths_u)} upright for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths_u, acc_bottom_u)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_bottom_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # inverted\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_bottom_i_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(bottom_image_paths_i)} inverted for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths_i, acc_bottom_i)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_bottom_i_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # reverse contrast\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_bottom_rc_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(bottom_image_paths_rc)} reverse contrast for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths_rc, acc_bottom_rc)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_bottom_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats_top_bottom['rn50_preIN_texture_sizeVar_best']['top']['acc_u'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vbsl151 -- Highest and lowest accuracy per model \n",
    "import random\n",
    "\n",
    "useful_stats_top_bottom = {}\n",
    "model_names_list = [\"rn50_preIN_texture_sizeVar_best\", \"rn50_preIN_notexture_sizeVar_best\", \"resnet50-trained-pretrained-vbsl\", \"rn50_vbsl-dist-ft_epoch15\"]\n",
    "\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'\n",
    "for model_name in model_names_list :\n",
    "    useful_stats_top_bottom[model_name] = {\n",
    "        'top' : {\n",
    "            'acc' : [[],[]],\n",
    "            'acc_u' : [[],[]],\n",
    "            'acc_i' : [[],[]],\n",
    "            'acc_rc' : [[],[]],\n",
    "            'human_i1' : [[],[]],\n",
    "            'marmoset_i1' : [[],[]],\n",
    "        },\n",
    "        'bottom'  : {\n",
    "            'acc' : [[],[]],\n",
    "            'acc_u' : [[],[]],\n",
    "            'acc_i' : [[],[]],\n",
    "            'acc_rc' : [[],[]],\n",
    "            'human_i1' : [[],[]],\n",
    "            'marmoset_i1' : [[],[]],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    elias_acc = useful_stats[data_root][model_name]['acc_per_img'][0]\n",
    "    neptune_acc = useful_stats[data_root][model_name]['acc_per_img'][1]\n",
    "    combined_idx = np.arange(0, 302)\n",
    "    combined_idx_u = np.concatenate([np.arange(0, 25), np.arange(50,75), np.arange(151,151+25), np.arange(151+50, 151+75)])\n",
    "    combined_idx_i = np.concatenate([np.arange(25, 50), np.arange(75,100), np.arange(151+25,151+50), np.arange(151+75, 151+100)])\n",
    "    combined_idx_rc = np.concatenate([np.arange(100, 150), np.arange(151+100,151+150)])\n",
    "\n",
    "    combined_acc = np.concatenate((elias_acc, neptune_acc))\n",
    "    combined_acc_u = combined_acc[combined_idx_u]\n",
    "    combined_acc_i = combined_acc[combined_idx_i]\n",
    "    combined_acc_rc = combined_acc[combined_idx_rc]\n",
    "\n",
    "    random.Random(4).shuffle(combined_idx)\n",
    "    random.Random(4).shuffle(combined_acc)\n",
    "    \n",
    "\n",
    "    acc_top_idx, acc_bottom_idx = combined_idx[np.argsort(combined_acc)[-15:][::-1]], combined_idx[np.argsort(combined_acc)[:15]]\n",
    "    acc_top_idx_u, acc_bottom_idx_u = combined_idx_u[np.argsort(combined_acc_u)[-5:][::-1]], combined_idx_u[np.argsort(combined_acc_u)[:5]]\n",
    "    acc_top_idx_i, acc_bottom_idx_i = combined_idx_i[np.argsort(combined_acc_i)[-5:][::-1]], combined_idx_i[np.argsort(combined_acc_i)[:5]]\n",
    "    acc_top_idx_rc, acc_bottom_idx_rc = combined_idx_rc[np.argsort(combined_acc_rc)[-5:][::-1]], combined_idx_rc[np.argsort(combined_acc_rc)[:5]]\n",
    "\n",
    "    acc_top_val, acc_bottom_val = np.concatenate((elias_acc, neptune_acc))[acc_top_idx], np.concatenate((elias_acc, neptune_acc))[acc_bottom_idx]\n",
    "    acc_top_val_u, acc_bottom_val_u = np.concatenate((elias_acc, neptune_acc))[acc_top_idx_u], np.concatenate((elias_acc, neptune_acc))[acc_bottom_idx_u]\n",
    "    acc_top_val_i, acc_bottom_val_i = np.concatenate((elias_acc, neptune_acc))[acc_top_idx_i], np.concatenate((elias_acc, neptune_acc))[acc_bottom_idx_i]\n",
    "    acc_top_val_rc, acc_bottom_val_rc = np.concatenate((elias_acc, neptune_acc))[acc_top_idx_rc], np.concatenate((elias_acc, neptune_acc))[acc_bottom_idx_rc]\n",
    "\n",
    "    acc_top, acc_bottom = list(zip(acc_top_idx, acc_top_val)), list(zip(acc_bottom_idx, acc_bottom_val))\n",
    "    acc_top_u, acc_bottom_u = list(zip(acc_top_idx_u, acc_top_val_u)), list(zip(acc_bottom_idx_u, acc_bottom_val_u))\n",
    "    acc_top_i, acc_bottom_i = list(zip(acc_top_idx_i, acc_top_val_i)), list(zip(acc_bottom_idx_i, acc_bottom_val_i))\n",
    "    acc_top_rc, acc_bottom_rc = list(zip(acc_top_idx_rc, acc_top_val_rc)), list(zip(acc_bottom_idx_rc, acc_bottom_val_rc))\n",
    "\n",
    "    useful_stats_top_bottom[model_name]['top']['acc'] = acc_top\n",
    "    useful_stats_top_bottom[model_name]['top']['acc_u'] = acc_top_u\n",
    "    useful_stats_top_bottom[model_name]['top']['acc_i'] = acc_top_i\n",
    "    useful_stats_top_bottom[model_name]['top']['acc_rc'] = acc_top_rc\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc'] = acc_bottom\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc_u'] = acc_bottom_u\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc_i'] = acc_bottom_i\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc_rc'] = acc_bottom_rc\n",
    "\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "def concatenate_images(image_paths):\n",
    "    images = [PILImage.open(img_path) for img_path in image_paths]\n",
    "    widths, heights = zip(*(img.size for img in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    concatenated_image = PILImage.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        concatenated_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "\n",
    "    return concatenated_image\n",
    "\n",
    "# Function to get the image paths based on the index\n",
    "def get_image_path(idx):\n",
    "    if idx < 151:\n",
    "        return f\"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_elias/trialnum{idx}.png\"\n",
    "    else:\n",
    "        return f\"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_neptune/trialnum{idx-151}.png\"\n",
    "\n",
    "# Displaying the images\n",
    "for model_name in model_names_list:\n",
    "    # # Get the top 10 and bottom 10 image paths\n",
    "    # acc_top = useful_stats_top_bottom[model_name]['top']['acc']\n",
    "    # acc_bottom = useful_stats_top_bottom[model_name]['bottom']['acc']\n",
    "\n",
    "    # top_image_paths = [get_image_path(idx) for idx, _ in acc_top]\n",
    "    # bottom_image_paths = [get_image_path(idx) for idx, _ in acc_bottom]\n",
    "\n",
    "    # # Concatenate the top 10 images\n",
    "    # top_concatenated_image = concatenate_images(top_image_paths)\n",
    "    # plt.figure(figsize=(25, 8))\n",
    "    # plt.imshow(top_concatenated_image)\n",
    "    # plt.axis('off')\n",
    "    # plt.title(f\"Top {len(top_image_paths)} images for {model_name}\")\n",
    "\n",
    "    # # Add accuracy values below each image for top images\n",
    "    # x_offset = 0\n",
    "    # for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths, acc_top)):\n",
    "    #     img_width = PILImage.open(image_path).width\n",
    "    #     plt.text(x_offset + img_width / 2, top_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "    #     x_offset += img_width\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # # Concatenate the bottom 10 images\n",
    "    # bottom_concatenated_image = concatenate_images(bottom_image_paths)\n",
    "    # plt.figure(figsize=(25, 8))\n",
    "    # plt.imshow(bottom_concatenated_image)\n",
    "    # plt.axis('off')\n",
    "    # plt.title(f\"Bottom {len(top_image_paths)} images for {model_name}\")\n",
    "\n",
    "    # # Add accuracy values below each image for bottom images\n",
    "    # x_offset = 0\n",
    "    # for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths, acc_bottom)):\n",
    "    #     img_width = PILImage.open(image_path).width\n",
    "    #     plt.text(x_offset + img_width / 2, bottom_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "    #     x_offset += img_width\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # Concatnete the top 5 images per category (upright, inverted, reverse contrast)\n",
    "    # ----------------------- TOP ----------------------\n",
    "    print(model_name)\n",
    "    acc_top_u, acc_top_i, acc_top_rc = useful_stats_top_bottom[model_name]['top']['acc_u'], useful_stats_top_bottom[model_name]['top']['acc_i'], useful_stats_top_bottom[model_name]['top']['acc_rc']\n",
    "    acc_bottom_u, acc_bottom_i, acc_bottom_rc = useful_stats_top_bottom[model_name]['bottom']['acc_u'], useful_stats_top_bottom[model_name]['bottom']['acc_i'], useful_stats_top_bottom[model_name]['bottom']['acc_rc']\n",
    "\n",
    "    top_image_paths_u, top_image_paths_i, top_image_paths_rc  = [get_image_path(idx) for idx, _ in acc_top_u], [get_image_path(idx) for idx, _ in acc_top_i], [get_image_path(idx) for idx, _ in acc_top_rc]\n",
    "    bottom_image_paths_u, bottom_image_paths_i, bottom_image_paths_rc  = [get_image_path(idx) for idx, _ in acc_bottom_u], [get_image_path(idx) for idx, _ in acc_bottom_i], [get_image_path(idx) for idx, _ in acc_bottom_rc]\n",
    "\n",
    "    acc_top_u_concat, acc_top_i_concat, acc_top_rc_concat = concatenate_images(top_image_paths_u), concatenate_images(top_image_paths_i), concatenate_images(top_image_paths_rc)\n",
    "    acc_bottom_u_concat, acc_bottom_i_concat, acc_bottom_rc_concat = concatenate_images(bottom_image_paths_u), concatenate_images(bottom_image_paths_i), concatenate_images(bottom_image_paths_rc)\n",
    "    # upright\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_top_u_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths_u)} upright for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths_u, acc_top_u)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_top_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # inverted\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_top_i_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths_i)} inverted for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths_i, acc_top_i)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_top_i_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # reverse contrast\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_top_rc_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths_rc)} reverse contrast for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths_rc, acc_top_rc)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_top_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #-------------- BOTTOM -------------------\n",
    "    # upright\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_bottom_u_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(bottom_image_paths_u)} upright for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths_u, acc_bottom_u)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_bottom_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # inverted\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_bottom_i_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(bottom_image_paths_i)} inverted for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths_i, acc_bottom_i)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_bottom_i_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # reverse contrast\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(acc_bottom_rc_concat)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(bottom_image_paths_rc)} reverse contrast for {model_name}\", fontsize=15)\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths_rc, acc_bottom_rc)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, acc_bottom_u_concat.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((elias_acc, neptune_acc))[acc_top_idx_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ec456",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((elias_acc, neptune_acc))[acc_top_idx_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_idx_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d98ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_acc_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_idx[acc_top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48882faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((elias_acc, neptune_acc))[acc_top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e007e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vbsl151 -- Highest and lowest accuracy per model \n",
    "useful_stats_top_bottom = {}z\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/'\n",
    "for model_name in model_names_list :\n",
    "    useful_stats_top_bottom[model_name] = {\n",
    "        'top' : {\n",
    "            'acc' : [[],[]],\n",
    "            'human_i1' : [[],[]],\n",
    "            'marmoset_i1' : [[],[]],\n",
    "        },\n",
    "        'bottom'  : {\n",
    "            'acc' : [[],[]],\n",
    "            'human_i1' : [[],[]],\n",
    "            'marmoset_i1' : [[],[]],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    elias_acc = useful_stats[data_root][model_name]['acc_per_img'][0]\n",
    "    neptune_acc = useful_stats[data_root][model_name]['acc_per_img'][1]\n",
    "    combined_acc = np.concatenate((elias_acc, neptune_acc))\n",
    "\n",
    "    acc_top_idx, acc_bottom_idx = np.argsort(combined_acc)[-15:][::-1], np.argsort(combined_acc)[:15]\n",
    "    acc_top_val, acc_bottom_val = combined_acc[acc_top_idx], combined_acc[acc_bottom_idx]\n",
    "    acc_top, acc_bottom = list(zip(acc_top_idx, acc_top_val)), list(zip(acc_bottom_idx, acc_bottom_val))\n",
    "\n",
    "    useful_stats_top_bottom[model_name]['top']['acc'] = acc_top\n",
    "    useful_stats_top_bottom[model_name]['bottom']['acc'] = acc_bottom\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "def concatenate_images(image_paths):\n",
    "    images = [PILImage.open(img_path) for img_path in image_paths]\n",
    "    widths, heights = zip(*(img.size for img in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    concatenated_image = PILImage.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        concatenated_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "\n",
    "    return concatenated_image\n",
    "\n",
    "# Function to get the image paths based on the index\n",
    "def get_image_path(idx):\n",
    "    if idx < 151:\n",
    "        return f\"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_elias/trialnum{idx}.png\"\n",
    "    else:\n",
    "        return f\"/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_neptune/trialnum{idx-151}.png\"\n",
    "\n",
    "# Displaying the images\n",
    "for model_name in model_names_list:\n",
    "    # Get the top 10 and bottom 10 image paths\n",
    "    acc_top = useful_stats_top_bottom[model_name]['top']['acc']\n",
    "    acc_bottom = useful_stats_top_bottom[model_name]['bottom']['acc']\n",
    "\n",
    "    top_image_paths = [get_image_path(idx) for idx, _ in acc_top]\n",
    "    bottom_image_paths = [get_image_path(idx) for idx, _ in acc_bottom]\n",
    "\n",
    "    # Concatenate the top 10 images\n",
    "    top_concatenated_image = concatenate_images(top_image_paths)\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.imshow(top_concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths)} images for {model_name}\")\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths, acc_top)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, top_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Concatenate the bottom 10 images\n",
    "    bottom_concatenated_image = concatenate_images(bottom_image_paths)\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.imshow(bottom_concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(top_image_paths)} images for {model_name}\")\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths, acc_bottom)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, bottom_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0450c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/']['rn50_preIN_texture_sizeVar_best']['i1_corr_diff_per_img'][0][228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ad274",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/Josh/data/face_data/vbsl_151/']['rn50_preIN_texture_sizeVar_best']['i1'][1][228-151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd551c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_i1[228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c21662",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names_list :\n",
    "    print(useful_stats_top_bottom[model_name]['top']['human_i1'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vbsl151 -- Highest and lowest correlation with human i1 \n",
    "\n",
    "for model_name in model_names_list :\n",
    "    # elias_acc = useful_stats[data_root][model_name]['acc_per_img'][0]\n",
    "    # neptune_acc = useful_stats[data_root][model_name]['acc_per_img'][1]\n",
    "    combined_human_i1 = useful_stats[data_root][model_name]['i1_corr_diff_per_img'][0]\n",
    "    combined_marmoset_i1 = useful_stats[data_root][model_name]['i1_corr_diff_per_img'][1]\n",
    "\n",
    "    human_i1_top_idx, human_i1_bottom_idx = np.argsort(combined_human_i1)[-15:][::-1], np.argsort(combined_human_i1)[:15]\n",
    "    human_i1_top_val, human_i1_bottom_val = combined_human_i1[human_i1_top_idx], combined_human_i1[human_i1_bottom_idx]\n",
    "    human_i1_top, human_i1_bottom = list(zip(human_i1_top_idx, human_i1_top_val)), list(zip(human_i1_bottom_idx, human_i1_bottom_val))\n",
    "\n",
    "    marmoset_i1_top_idx, marmoset_i1_bottom_idx = np.argsort(combined_marmoset_i1)[-15:][::-1], np.argsort(combined_marmoset_i1)[:15]\n",
    "    marmoset_i1_top_val, marmoset_i1_bottom_val = combined_marmoset_i1[marmoset_i1_top_idx], combined_marmoset_i1[marmoset_i1_bottom_idx]\n",
    "    marmoset_i1_top, marmoset_i1_bottom = list(zip(marmoset_i1_top_idx, marmoset_i1_top_val)), list(zip(marmoset_i1_bottom_idx, marmoset_i1_bottom_val))\n",
    "\n",
    "    useful_stats_top_bottom[model_name]['top']['human_i1'] = human_i1_top\n",
    "    useful_stats_top_bottom[model_name]['bottom']['human_i1'] = human_i1_bottom\n",
    "\n",
    "    useful_stats_top_bottom[model_name]['top']['marmoset_i1'] = marmoset_i1_top\n",
    "    useful_stats_top_bottom[model_name]['bottom']['marmoset_i1'] = marmoset_i1_bottom\n",
    "\n",
    "# Displaying the images\n",
    "for model_name in model_names_list:\n",
    "    # Get the top 10 and bottom 10 image paths\n",
    "    human_i1_top_model = useful_stats_top_bottom[model_name]['top']['human_i1']\n",
    "    human_i1_bottom_model = useful_stats_top_bottom[model_name]['bottom']['human_i1']\n",
    "\n",
    "    top_image_paths = [get_image_path(idx) for idx, _ in human_i1_top_model]\n",
    "    bottom_image_paths = [get_image_path(idx) for idx, _ in human_i1_bottom_model]\n",
    "\n",
    "    # Concatenate the top 10 images\n",
    "    top_concatenated_image = concatenate_images(top_image_paths)\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.imshow(top_concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Top {len(top_image_paths)} images with human i1 corr, for {model_name}\")\n",
    "\n",
    "    # Add accuracy values below each image for top images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(top_image_paths, human_i1_top_model)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, top_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Concatenate the bottom 10 images\n",
    "    bottom_concatenated_image = concatenate_images(bottom_image_paths)\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.imshow(bottom_concatenated_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Bottom {len(top_image_paths)} images with human i1 corr, for {model_name}\")\n",
    "\n",
    "    # Add accuracy values below each image for bottom images\n",
    "    x_offset = 0\n",
    "    for idx, (image_path, (_, acc)) in enumerate(zip(bottom_image_paths, human_i1_bottom_model)):\n",
    "        img_width = PILImage.open(image_path).width\n",
    "        plt.text(x_offset + img_width / 2, bottom_concatenated_image.height + 25, f\"{acc:.2f}\", ha='center', fontsize=10)\n",
    "        x_offset += img_width\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_statstop_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cdb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NameError: name 'PILImage' is not defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy by layer \n",
    "layers = [\"ResNet50\", \"Layer1\"]\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Convert to numpy arrays (if needed)\n",
    "acc_list = np.array(acc_list)\n",
    "acc_std_list = np.array(acc_std_list)\n",
    "plt.plot(layers, acc_list, marker='o', label='accuracy')\n",
    "plt.fill_between(layers, acc_list - acc_std_list, acc_list + acc_std_list, color='blue', alpha=0.2)\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"ResNet50 from scratch, accuracy by layer\", fontsize=16)\n",
    "# plt.errorbar([\"ResNet50\", \"Layer1\"], acc_list, yerr=acc_std_list)\n",
    "# # plt.errorbar([\"0.5\", \"0.25\", \"0.1\", \"0.05\"], i1_corr_human_list, yerr=i1_corr_std_human_list)\n",
    "# plt.xlabel(\"ResNet50 Layer\")\n",
    "# plt.ylabel(\"i1 corr\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d507c0f-1982-46f7-aea7-92178231ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axhline(y=0.444472, label='full 100k dp', color='red')\n",
    "plt.errorbar([\"0.5\", \"0.25\", \"0.1\", \"0.05\"], acc_list, yerr=acc_std_list)\n",
    "# plt.errorbar([\"0.5\", \"0.25\", \"0.1\", \"0.05\"], i1_corr_human_list, yerr=i1_corr_std_human_list)\n",
    "plt.xlabel(\"subset ratio\")\n",
    "plt.ylabel(\"i1 corr\")\n",
    "plt.legend()\n",
    "plt.title(\"training size ablation for vbsl100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16031f-0910-490c-b3a3-99799b619498",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## subset testing for vbsl151 / no recording\n",
    "\n",
    "# # 'resnet50', 'alexnet', 'vgg16'\n",
    "# # 'resnet50', 'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft'\n",
    "# # 'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl'\n",
    "# # 'rn50_preIN_notexture_model_best', 'rn50_preIN_texture_model_best'\n",
    "# # 'rn50_preIN_notexture_sizeVar_best'\n",
    "# # 'rn50_preIN_notexture_sizeVar_2losses'\n",
    "\n",
    "# bio_i1s_list = [human_vbsl151, AJ_vbsl151]\n",
    "# data_root = '../../data/face_data/vbsl_151/'\n",
    "# # model_name_list = list(useful_stats[data_root].keys())\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_best']\n",
    "\n",
    "# num_rep = 1000\n",
    "# subset_list = [[0,1,2,3,4,5], [0,2], [1,3], [4,5],\n",
    "#                [0,1,2,3], [0,2,4,5], [1,3,4,5]]\n",
    "# subset_name_list = ['full', 'normal_face', 'inverted_face', 'reverse_contrast', \n",
    "#                    '1+2', '1+3', '2+3']\n",
    "\n",
    "# for model_name in model_name_list:\n",
    "#     print(model_name)\n",
    "#     model_stat = useful_stats[data_root][model_name]\n",
    "#     # get acc group\n",
    "#     tmp = model_stat['acc_per_img'].reshape((2,151)).mean(0)\n",
    "#     tmp_group = tmp[:150].reshape(6,25).mean(axis=1)\n",
    "#     for subset_id, subset in enumerate(subset_list):\n",
    "#         # get acc\n",
    "#         print(\"%s\\nacc: %.2f\" % (subset_name_list[subset_id], tmp_group[subset].mean()))\n",
    "        \n",
    "#         for bio_inedx, bio_i1s in enumerate(bio_i1s_list):\n",
    "#             # get model i1s\n",
    "#             i1_dists = model_stat['dist']\n",
    "#             i1_dists = np.concatenate((i1_dists[0], i1_dists[1]), axis=1)\n",
    "#             model_i1s = []\n",
    "#             for rep_index in range(5):\n",
    "#                 np.random.shuffle(i1_dists)\n",
    "#                 tmp = np.concatenate([i1_dists[:int(num_rep/2)].mean(0), \n",
    "#                                       i1_dists[int(num_rep/2):].mean(0)])\n",
    "#                 model_i1s.append(np.expand_dims(tmp, axis=0))\n",
    "#             model_i1s = np.concatenate(model_i1s, axis=0)\n",
    "            \n",
    "#             # get bio i1s\n",
    "#             bio_i1s = bio_i1s.squeeze()\n",
    "#             bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only\n",
    "            \n",
    "#             # get subset for model/bio i1s\n",
    "#             model_i1s = model_i1s.reshape((5,4,151))[:,:,:150].reshape((5,4,6,25))\n",
    "#             model_i1s = model_i1s[:,:,subset,:].reshape(5,-1)\n",
    "#             bio_i1s = bio_i1s.reshape((5,4,151))[:,:,:150].reshape((5,4,6,25))\n",
    "#             bio_i1s = bio_i1s[:,:,subset,:].reshape(5,-1)\n",
    "#             # print(model_i1s.shape, bio_i1s.shape)\n",
    "\n",
    "#             # calc i1 corr\n",
    "#             i1_corr = []\n",
    "#             model_internal = []\n",
    "#             bio_internal = []\n",
    "#             half_length = int(model_i1s.shape[1]/2)\n",
    "#             for rep_index in range(5):\n",
    "#                 corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "#                 corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "#                 corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "#                 corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "#                 # print(corr_1, corr_2, corr_3, corr_4)\n",
    "#                 i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "#                 model_internal.append(corr_3)\n",
    "#                 bio_internal.append(corr_4)\n",
    "#             print(\"i1 corr: %.2f+-%.2f, model: %.2f, bio: %.2f\" % (np.mean(np.array(i1_corr)), \n",
    "#                                                           np.std(np.array(i1_corr)),\n",
    "#                                                          np.mean(np.array(corr_3)),\n",
    "#                                                          np.mean(np.array(corr_4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04561002-56c1-48a5-b3d6-410a548e565b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## consistency between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65f2bb-9cd2-4cb6-a309-91104311fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(dict_i1_dists['resnet50-trained-pretrained-vbsl'].mean(axis=1).reshape(-1), \n",
    "                    dict_i1_dists['resnet50-trained-scratch-vbsl'].mean(axis=1).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f789d515-f64d-4822-9f25-c39e4ccc1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_i1_dists.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e928a6-6883-49bb-9ac6-92deb46d03c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calc i1s corr between models\n",
    "i1_corr_list = []\n",
    "for name_0 in model_name_list:\n",
    "    for name_1 in model_name_list:\n",
    "        # i1\n",
    "        _i1_corr, _ = scipy.stats.pearsonr(dict_i1_dists[name_0].mean(axis=1).reshape(-1), \n",
    "                                        dict_i1_dists[name_1].mean(axis=1).reshape(-1))\n",
    "        i1_corr_list.append(_i1_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d505b-a1be-4115-a00d-959d7eea124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1_corr_list = np.array(i1_corr_list).reshape((len(model_name_list), len(model_name_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d5b8c-89fd-4cbb-a2c9-7d7ddd04353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "img = ax.imshow(i1_corr_list)\n",
    "\n",
    "plt.imshow(i1_corr_list)\n",
    "model_name_list_abb = ['alexnet',\n",
    "                     'vgg16',\n",
    "                     'resnet50',\n",
    "                     'resnet50-SIN',\n",
    "                     'resnet50-SIN-IN',\n",
    "                     'resnet50-SIN-IN-ft',\n",
    "                      'trained-IN+vbsl',\n",
    "                      'trained-vbsl',\n",
    "                      'basal-notexture',\n",
    "                      'basal-texture',\n",
    "                      'basal-notexture-sizeVar']\n",
    "ax.set_xticks(np.arange(len(model_name_list_abb)))\n",
    "ax.set_yticks(np.arange(len(model_name_list_abb)))\n",
    "ax.set_xticklabels(model_name_list_abb, rotation=45)\n",
    "ax.set_yticklabels(model_name_list_abb, rotation=45)\n",
    "ax.set_title(\"correlations between model i1s - vbsl151\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5d37a-0954-44e4-bb55-9e8d75a3fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dict_scores['simplecnn-trained-vbsl']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3255858-44f4-48ed-99f0-4b504dc5f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sin_i1_corr_list, sin_conf_mat_jsd_list, label=\"in/sin\")\n",
    "plt.scatter(scratch_i1_corr_list, scratch_conf_mat_jsd_list, label=\"scratch\")\n",
    "plt.scatter(cross_i1_corr_list, cross_conf_mat_jsd_list, label=\"cross\")\n",
    "\n",
    "plt.xlabel(\"i1\")\n",
    "plt.ylabel(\"jsd on conf mat\")\n",
    "plt.title(\"JSD on conf mat vs. i1\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3156e2b-91f6-4af5-9881-0710b4d763e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc correlation of i1s\n",
    "scipy.stats.pearsonr(dists.mean(axis=1).reshape(-1), human_data.reshape(-1))\n",
    "# scipy.stats.pearsonr(np.absolute(dists.mean(axis=1).reshape(-1)), human_data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d38e10-b098-4a4f-980e-5f09a591aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dists.mean(axis=1).reshape(-1), human_data.reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d24d85-802c-4eeb-aff0-ea16cab5d634",
   "metadata": {
    "tags": []
   },
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2979-1cdc-4e57-bca2-d5dd43b29665",
   "metadata": {},
   "source": [
    "## plots for lunch talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3a135-08cf-4d7f-ac4d-fa1a0eb94d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_stats = {}\n",
    "import pickle\n",
    "with open('useful_stats_penn.pkl', 'rb') as f:\n",
    "    useful_stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8bbd5-5d56-498c-845b-b98d4a1718ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn50 \n",
    "plt.figure(figsize=(1.25*3, 6))\n",
    "plt.bar(['2D Object', 'GOR', 'GFR'], [0.949, 0.72122017, 0.58074166], \n",
    "        yerr=[0.0120, 0.02909256, 0.0242997])\n",
    "plt.ylim([0.5,1.0])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"resnet50 performances\")\n",
    "plt.savefig(f\"./figs/rn50_acc_2d.pdf\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cd0f4-5392-4b22-86e9-bb31a81c56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_ReadableNames), len(i1_mean_list), len(i1_std_list), len(color_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002a9d5-2889-4ff3-a7d5-9b61e7e1f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats[data_root][\"resnet50\"]['i1_corr_upright']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f628412-1ab6-46e4-ac5b-aac7cb4ebd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot i1 - all\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "index = 0\n",
    "subject_list = ['human', 'marmoset']\n",
    "model_group = ['pixel', 'resnet50_layer1'] + \\\n",
    "                ['rn50_preIN_texture_sizeVar_best', 'rn50_preIN_notexture_sizeVar_best',\n",
    "                    'resnet50-trained-pretrained-vbsl', 'rn50_vbsl-dist-ft_epoch15'] + \\\n",
    "                   ['vggface', 'rn50_FromScratch_texture_sizeVar_best', 'rn50_FromScratch_notexture_sizeVar_best',\n",
    "                   'resnet50-trained-scratch-vbsl']\n",
    "model_ReadableNames = ['pixle', 'v1'] + \\\n",
    "                        ['finetuned-Basel', 'finetuned-Basel-NoTexture', 'finetuned-AppleFaces', 'finetuned-AppleFaces-dist'] + \\\n",
    "                          ['FromScratch-vggface', 'FromScratch-Basel', 'FromScratch-Basel-NoTexture', 'FromScratch-AppleFaces'] + \\\n",
    "                          ['Ideal3D-pixel', 'Ideal3D-rn50', 'Ideal3D-rn50-AppleFaces-ft']\n",
    "color_list = ['tab:blue'] * 2 + ['tab:grey'] * 4 + ['tab:brown'] * 4 + \\\n",
    "            ['tab:olive'] * 3\n",
    "# read\n",
    "i1_mean_list = []\n",
    "i1_std_list = []\n",
    "for model_name in model_group:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr_upright']\n",
    "    i1_mean_list.append(i1_corr[index][0])\n",
    "    i1_std_list.append(i1_corr[index][1])\n",
    "i1_mean_list += [0.413778, 0.272167, 0.484827]\n",
    "i1_std_list += [0.070366, 0.020872, 0.011055]\n",
    "    \n",
    "# plot\n",
    "plt.figure(figsize=(2*len(model_group), 6))\n",
    "plt.bar(model_ReadableNames, i1_mean_list, \n",
    "        yerr=i1_std_list, color=color_list)\n",
    "for i, v in enumerate(i1_mean_list):\n",
    "    plt.text(i-0.1, v+0.015, str(v)[:5])\n",
    "plt.ylim([-0.1, 0.65])\n",
    "plt.xticks(rotation=20)\n",
    "subject = subject_list[index]\n",
    "plt.title(f\"upright AppleFaces: i1 correlation with {subject}\")\n",
    "plt.ylabel(\"i1 correlation\")\n",
    "data_name = data_root.split(\"/\")[-2]\n",
    "plt.axhline(y=-0.01589876, color='r', linestyle='-', label=\"resnet50\")\n",
    "plt.axhline(y=0, color='black', linestyle='-')\n",
    "\n",
    "plt.savefig(f\"./figs/ideal3d_i1_against_all.pdf\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94a946-9661-453c-af4d-e993d1c81a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_stats = {}\n",
    "import pickle\n",
    "with open('useful_stats_tuning.pkl', 'rb') as f:\n",
    "    useful_stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa1e59-4717-49a8-9559-adecd8498d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80695aff-2236-417e-b2b6-fa10e7ff357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning epoches - face epoch1\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "model_group = ['resnet50']\n",
    "for i in range(41):\n",
    "    model_group.append(f\"vbsl50k_step{(i+1)*15}\")\n",
    "    \n",
    "# read\n",
    "i1_mean_list = []\n",
    "acc_mean_list = []\n",
    "for model_name in model_group:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_mean_list.append(i1_corr[0][0])\n",
    "    \n",
    "    acc = useful_stats[data_root][model_name]['acc']\n",
    "    acc_mean_list.append(acc[0])\n",
    "\n",
    "xticks = []\n",
    "for i in range(42):\n",
    "    xticks.append((i)*15*256/2)\n",
    "# plot\n",
    "plt.plot(xticks, i1_mean_list, marker='o', markersize=3, label='i1 correlation')\n",
    "plt.plot(xticks, acc_mean_list, marker='o', markersize=3, label='acc')\n",
    "plt.xlabel(\"# of images\")\n",
    "plt.title(\"Elias-Neptune fine-tuning, 1 epoch\")\n",
    "plt.ylabel(\"GFR% | r(human)\")\n",
    "plt.ylim([-0.1,0.9])\n",
    "plt.legend()\n",
    "plt.xticks(rotation=20)\n",
    "plt.savefig(f\"./figs/finetuning_epoches_faces_epoch1.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34d045-4101-4dfd-8194-25f1211a0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning epoches - object epoch1\n",
    "data_root = '../../data/face_data/control_exp/objs/'\n",
    "model_group = ['resnet50']\n",
    "for i in range(41):\n",
    "    model_group.append(f\"vbsl50kobj_step{(i+1)*15}\")\n",
    "    \n",
    "# read\n",
    "i1_mean_list = []\n",
    "i1_std_list = []\n",
    "acc_mean_list = []\n",
    "acc_std_list = []\n",
    "for model_name in model_group:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_mean_list.append(i1_corr[0][0])\n",
    "    i1_std_list.append(i1_corr[0][1])\n",
    "    \n",
    "    acc = useful_stats[data_root][model_name]['acc']\n",
    "    acc_mean_list.append(acc[0])\n",
    "    acc_std_list.append(acc[1])\n",
    "\n",
    "xticks = []\n",
    "for i in range(42):\n",
    "    xticks.append((i)*15*256/2)\n",
    "# plot\n",
    "plt.plot(xticks, i1_mean_list, marker='o', markersize=3, label='i1 correlation')\n",
    "plt.plot(xticks, acc_mean_list, marker='o', markersize=3, label='acc')\n",
    "plt.xlabel(\"# of images\")\n",
    "plt.title(\"Camel-Elephant fine-tuning, 1 epoch\")\n",
    "plt.ylabel(\"GOR% | r(human)\")\n",
    "plt.ylim([-0.1,0.9])\n",
    "plt.legend()\n",
    "plt.xticks(rotation=20)\n",
    "plt.savefig(f\"./figs/finetuning_epoches_obj_epoch1.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09a7da-8d05-4f58-b437-dfa4d3c417f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## plots for penn talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e96791-d3f7-4ab2-941d-94775ad17f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_stats = {}\n",
    "import pickle\n",
    "with open('useful_stats_penn.pkl', 'rb') as f:\n",
    "    useful_stats = pickle.load(f)\n",
    "    \n",
    "# hierachy: [task_dir][model_name][acc/acc_per_img/dist/i1]\n",
    "# acc [list]: acc over all datapoints and trails -> [acc_mean, acc_std]\n",
    "# acc_per_img [array]: acc per image averaged over all trails -> shape [2, num_img_per_class]\n",
    "# dist [array]: all svm distance (note that the second class dist is negated) -> shape [2, num_repetition, num_img_per_class]\n",
    "# i1_5rep [array]: random split-half i1 with 5 repetition -> shape [5, 2*num_img_per_class]\n",
    "# i1 [array]: model i1 (the same as dist averaging over trails) -> shape [2, num_img_per_class]\n",
    "# i1_corr [list]: model i1 correlation with bio systems. For vbsl101, the order is [Bourgeois, Sausage, AJ]. \n",
    "# For vbsl151, the order is [Human, AJ]. For each corr, I record [i1_corr_mean, i1_corr_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5387f61-0434-49ae-b021-b5ebd354bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['../../data/face_data/vbsl_151/']['resnet50']['acc'], useful_stats['../../data/face_data/vbsl_151/']['resnet50']['i1_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4404fc-74a7-4254-a4cd-4fe1a859eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['../../data/face_data/control_exp/objs/']['resnet50']['acc'], useful_stats['../../data/face_data/control_exp/objs/']['resnet50']['i1_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decf867-5eea-4e64-a4dd-6befd0aaa9a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rn50 \n",
    "plt.figure(figsize=(1.25*len(model_group), 6))\n",
    "plt.bar(['GOR', 'GFR'], [0.72122017, 0.58074166], \n",
    "        yerr=[0.02909256, 0.0242997])\n",
    "plt.ylim([0.5,0.8])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"resnet50 performances\")\n",
    "plt.savefig(f\"./figs/rn50_acc.pdf\", dpi=500)\n",
    "\n",
    "plt.figure(figsize=(1.25*len(model_group), 6))\n",
    "plt.bar(['GOR', 'GFR'], [0.4222972, -0.009087089], \n",
    "        yerr=[0.02151, 0.0045915])\n",
    "# plt.ylim([0.5,0.8])\n",
    "plt.ylabel(\"i1 correlation\")\n",
    "plt.axhline(y=0, color='black')\n",
    "plt.title(\"resnet50 i1 correlation with human\")\n",
    "plt.savefig(f\"./figs/rn50_i1.pdf\", dpi=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28298567-580e-42fa-a76a-deae45631dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68d72d-1e64-4c6b-ac7d-3d1bfded1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats[data_root_list[4]]['resnet50']['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60805c3-6e88-4ead-a87f-c9dc5610e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_list = ['../../data/face_data/vbsl_151/', '../../data/face_data/control_exp/objs/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl151_sophie_praneeth/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/',\n",
    "                 '../../data/face_data/control_exp/ood/vbsl151_basel_ood/']\n",
    "model_group_list = [['rn50_preIN_texture_sizeVar_best', 'rn50_preIN_notexture_sizeVar_best',\n",
    "                    'resnet50-trained-pretrained-vbsl', 'rn50_vbsl-dist-ft_epoch15'],\n",
    "                   ['vggface', 'rn50_FromScratch_texture_sizeVar_best', 'rn50_FromScratch_notexture_sizeVar_best',\n",
    "                   'resnet50-trained-scratch-vbsl'],\n",
    "                   ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']]\n",
    "model_ReadableName_list = [['finetuned-Basel', 'finetuned-Basel-NoTexture', 'finetuned-AppleFaces', 'finetuned-AppleFaces-dist'],\n",
    "                          ['FromScratch-vggface', 'FromScratch-Basel', 'FromScratch-Basel-NoTexture', 'FromScratch-AppleFaces'],\n",
    "                          ['SIN', 'SIN+IN', 'SIN+IN with IN-finetuned']]\n",
    "dataset_name_list = ['AppleFaces vbsli*', 'Objects vbsli*', 'OOD-AppleFaces vbsli*',\n",
    "                    'OOD-Basel-NoTexture vbsli*', 'OOD-Basel vbsli*']\n",
    "resnet50_acc = [0.5807416666666666, 0.7212201754385963, \n",
    "                0.5027109649122807, 0.6554991228070176, 0.6924236842105265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7f8b2-c0b8-4954-8744-1197afa03f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(4, 5):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356956f-0c21-43a2-ab74-1aaf365d698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc - all\n",
    "for index in range(4, 5):\n",
    "    data_root = data_root_list[index]\n",
    "    model_group = ['rn50_preIN_texture_sizeVar_best', 'rn50_preIN_notexture_sizeVar_best',\n",
    "                        'resnet50-trained-pretrained-vbsl', 'rn50_vbsl-dist-ft_epoch15'] + \\\n",
    "                       ['vggface', 'rn50_FromScratch_texture_sizeVar_best', 'rn50_FromScratch_notexture_sizeVar_best',\n",
    "                       'resnet50-trained-scratch-vbsl'] + \\\n",
    "                       ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']\n",
    "    model_ReadableNames = ['finetuned-Basel', 'finetuned-Basel-NoTexture', 'finetuned-AppleFaces', 'finetuned-AppleFaces-dist'] + \\\n",
    "                              ['FromScratch-vggface', 'FromScratch-Basel', 'FromScratch-Basel-NoTexture', 'FromScratch-AppleFaces'] + \\\n",
    "                              ['SIN', 'SIN+IN', 'SIN+IN with IN-finetuned']\n",
    "    color_list = ['tab:grey'] * 4 + ['tab:brown'] * 4 + ['tab:olive'] * 3\n",
    "    # read numbers\n",
    "    acc_mean_list = []\n",
    "    acc_std_list = []\n",
    "    for model_name in model_group:\n",
    "        acc = useful_stats[data_root][model_name]['acc']\n",
    "        acc_mean_list.append(acc[0]*100)\n",
    "        acc_std_list.append(acc[1]*100)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(2*len(model_group), 6))\n",
    "    plt.bar(model_ReadableNames, acc_mean_list, \n",
    "            yerr=acc_std_list, color = color_list)\n",
    "\n",
    "    for i, v in enumerate(acc_mean_list):\n",
    "        plt.text(i-0.2, v+3, str(v)[:5])\n",
    "\n",
    "    plt.ylim([45, 100])\n",
    "    plt.xticks(rotation=10)\n",
    "    plt.title(dataset_name_list[index] + \" accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    data_name = data_root.split(\"/\")[-2]\n",
    "\n",
    "    plt.axhline(y=resnet50_acc[index]*100, color='r', linestyle='-', label=\"resnet50\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"./figs/{data_name}_all.pdf\", dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f859e6-81c8-4e52-a6e1-cde2d1f91964",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot acc - in groups\n",
    "for index in range(4, 5):\n",
    "    data_root = data_root_list[index]\n",
    "    for model_group_index, model_group in enumerate(model_group_list):\n",
    "        # read numbers\n",
    "        acc_mean_list = []\n",
    "        acc_std_list = []\n",
    "        for model_name in model_group:\n",
    "            acc = useful_stats[data_root][model_name]['acc']\n",
    "            acc_mean_list.append(acc[0]*100)\n",
    "            acc_std_list.append(acc[1]*100)\n",
    "\n",
    "        # plot\n",
    "        plt.figure(figsize=(2*len(model_group), 6))\n",
    "        plt.bar(model_ReadableName_list[model_group_index], acc_mean_list, yerr=acc_std_list)\n",
    "\n",
    "        for i, v in enumerate(acc_mean_list):\n",
    "            plt.text(i-0.2, v+3, str(v)[:5])\n",
    "\n",
    "        plt.ylim([45, 100])\n",
    "        plt.xticks(rotation=10)\n",
    "        plt.title(dataset_name_list[index] + \" accuracy\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        data_name = data_root.split(\"/\")[-2]\n",
    "\n",
    "        plt.axhline(y=resnet50_acc[index]*100, color='r', linestyle='-', label=\"resnet50\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(f\"./figs/{data_name}_group{model_group_index}.pdf\", dpi=500)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca7389-f002-4942-a00a-a0280dea5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['../../data/face_data/vbsl_151/']['resnet50']['i1_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802cf85-20ca-467f-8c11-17f62d15f5f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot i1 - in groups\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "index = 0\n",
    "subject_list = ['human', 'marmoset']\n",
    "for model_group_index, model_group in enumerate(model_group_list):\n",
    "    # read\n",
    "    i1_mean_list = []\n",
    "    i1_std_list = []\n",
    "    for model_name in model_group:\n",
    "        i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "        i1_mean_list.append(i1_corr[index][0])\n",
    "        i1_std_list.append(i1_corr[index][1])\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(2*len(model_group), 6))\n",
    "    plt.bar(model_ReadableName_list[model_group_index], \n",
    "            i1_mean_list, yerr=i1_std_list)\n",
    "    for i, v in enumerate(i1_mean_list):\n",
    "        plt.text(i-0.1, v+0.015, str(v)[:5])\n",
    "    plt.ylim([0, 0.6])\n",
    "    plt.xticks(rotation=10)\n",
    "    subject = subject_list[index]\n",
    "    plt.title(f\"AppleFaces: i1 correlation with {subject}\")\n",
    "    plt.ylabel(\"i1 correlation\")\n",
    "    data_name = data_root.split(\"/\")[-2]\n",
    "    \n",
    "    plt.axhline(y=0.009087089407458513, color='r', linestyle='-', label=\"resnet50\")\n",
    "    # plt.legend(bbox_to_anchor=[1.2, 1])\n",
    "    \n",
    "    plt.savefig(f\"./figs/{data_name}_group{model_group_index}_{subject}i1.pdf\", dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b199b-013e-44af-93ca-d317120150ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot i1 - all\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "index = 0\n",
    "subject_list = ['human', 'marmoset']\n",
    "model_group = ['rn50_preIN_texture_sizeVar_best', 'rn50_preIN_notexture_sizeVar_best',\n",
    "                    'resnet50-trained-pretrained-vbsl', 'rn50_vbsl-dist-ft_epoch15'] + \\\n",
    "                   ['vggface', 'rn50_FromScratch_texture_sizeVar_best', 'rn50_FromScratch_notexture_sizeVar_best',\n",
    "                   'resnet50-trained-scratch-vbsl'] + \\\n",
    "                   ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']\n",
    "model_ReadableNames = ['finetuned-Basel', 'finetuned-Basel-NoTexture', 'finetuned-AppleFaces', 'finetuned-AppleFaces-dist'] + \\\n",
    "                          ['FromScratch-vggface', 'FromScratch-Basel', 'FromScratch-Basel-NoTexture', 'FromScratch-AppleFaces'] + \\\n",
    "                          ['SIN', 'SIN+IN', 'SIN+IN with IN-finetuned']\n",
    "color_list = ['tab:grey'] * 4 + ['tab:brown'] * 4 + ['tab:olive'] * 3\n",
    "# read\n",
    "i1_mean_list = []\n",
    "i1_std_list = []\n",
    "for model_name in model_group:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_mean_list.append(i1_corr[index][0])\n",
    "    i1_std_list.append(i1_corr[index][1])\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(2*len(model_group), 6))\n",
    "plt.bar(model_ReadableNames, i1_mean_list, \n",
    "        yerr=i1_std_list, color=color_list)\n",
    "for i, v in enumerate(i1_mean_list):\n",
    "    plt.text(i-0.1, v+0.015, str(v)[:5])\n",
    "plt.ylim([0, 0.6])\n",
    "plt.xticks(rotation=10)\n",
    "subject = subject_list[index]\n",
    "plt.title(f\"AppleFaces: i1 correlation with {subject}\")\n",
    "plt.ylabel(\"i1 correlation\")\n",
    "data_name = data_root.split(\"/\")[-2]\n",
    "plt.axhline(y=0.009087089407458513, color='r', linestyle='-', label=\"resnet50\")\n",
    "plt.savefig(f\"./figs/{data_name}_all_{subject}i1.pdf\", dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727f5bf-09a0-4f5b-a5af-5a8878ebc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning epoches - face\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "model_group = ['resnet50']\n",
    "num_epoches = 12\n",
    "for i in range(num_epoches):\n",
    "    model_group.append(f'PennTuning-face-epoch{i}')\n",
    "    # model_names_list.append(f'PennTuning-obj-epoch{i}')\n",
    "\n",
    "# read\n",
    "i1_mean_list = []\n",
    "i1_std_list = []\n",
    "acc_mean_list = []\n",
    "acc_std_list = []\n",
    "for model_name in model_group:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_mean_list.append(i1_corr[0][0])\n",
    "    i1_std_list.append(i1_corr[0][1])\n",
    "    \n",
    "    acc = useful_stats[data_root][model_name]['acc']\n",
    "    acc_mean_list.append(acc[0])\n",
    "    acc_std_list.append(acc[1])\n",
    "    \n",
    "# plot\n",
    "plt.errorbar(np.arange(num_epoches+1), i1_mean_list, i1_std_list, label='i1 correlation')\n",
    "plt.errorbar(np.arange(num_epoches+1), acc_mean_list, acc_std_list, label='acc')\n",
    "plt.xlabel(\"finetuning epoches\")\n",
    "plt.title(\"finetuning for AppleFaces\")\n",
    "plt.ylim([-0.1,0.9])\n",
    "plt.legend()\n",
    "plt.savefig(f\"./figs/finetuning_epoches_faces.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df4c73-b248-4354-a765-55c486ca0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning epoches - obj\n",
    "data_root = '../../data/face_data/control_exp/objs/'\n",
    "model_group = ['resnet50']\n",
    "num_epoches = 12\n",
    "for i in range(num_epoches):\n",
    "    model_group.append(f'PennTuning-obj-epoch{i}')\n",
    "\n",
    "# read\n",
    "i1_mean_list = []\n",
    "i1_std_list = []\n",
    "acc_mean_list = []\n",
    "acc_std_list = []\n",
    "for model_name in model_group:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_mean_list.append(i1_corr[0][0])\n",
    "    i1_std_list.append(i1_corr[0][1])\n",
    "    \n",
    "    acc = useful_stats[data_root][model_name]['acc']\n",
    "    acc_mean_list.append(acc[0])\n",
    "    acc_std_list.append(acc[1])\n",
    "# plot\n",
    "plt.errorbar(np.arange(num_epoches+1), i1_mean_list, i1_std_list, label='i1 correlation')\n",
    "plt.errorbar(np.arange(num_epoches+1), acc_mean_list, acc_std_list, label='acc')\n",
    "plt.xlabel(\"finetuning epoches\")\n",
    "plt.title(\"finetuning for Objects\")\n",
    "plt.ylim([-0.1,0.9])\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f\"./figs/finetuning_epoches_objects.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a031bb-f0a0-4ad5-82fd-14a1535716fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91a06f-c673-4df4-927b-5c8b1a290f45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reg analysis - bar plot - in groups\n",
    "index = 0\n",
    "data_root = data_root_list[index]\n",
    "r2_list = [[0.07792108787342954, 0.2653578840672663, 0.4046336447971614, 0.452],\n",
    "           [0.02826135053361982, 0.025643561490320668, 0.2185898009488952, 0.49304382365514515],\n",
    "           [0.070180975320918, 0.006955316238228294, 0.03518525749237562]]\n",
    "\n",
    "for model_group_index, model_group in enumerate(model_group_list):\n",
    "    # read numbers\n",
    "    cur_r2_list = r2_list[model_group_index]\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(2*len(model_group), 6))\n",
    "    plt.bar(model_ReadableName_list[model_group_index], cur_r2_list)\n",
    "    plt.axhline(y=0.5687079406432649, label='human', color='red')\n",
    "    plt.axhline(y=0.28832485400284535, label='marmoset', color='green')\n",
    "    plt.axhline(y=0.0149, label='resnet50', color='yellow')\n",
    "\n",
    "    for i, v in enumerate(cur_r2_list):\n",
    "        plt.text(i-0.1, v+0.01, str(v)[:5])\n",
    "        \n",
    "    plt.ylim([0, 0.6])\n",
    "    plt.xticks(rotation=10)\n",
    "    plt.title(\"Regression of latent variables\")\n",
    "    plt.ylabel(\"r2\")\n",
    "    data_name = data_root.split(\"/\")[-2]\n",
    "    plt.legend(bbox_to_anchor=[1,1.01])\n",
    "    plt.savefig(f\"./figs/reg_analysis_r2_group{model_group_index}.pdf\", dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b58843-ebe0-4ea0-af9e-661b3fb9e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg analysis - bar plot - all\n",
    "index = 0\n",
    "data_root = data_root_list[index]\n",
    "r2_list = [0.07792108787342954, 0.2653578840672663, 0.4046336447971614, 0.452] +\\\n",
    "           [0.02826135053361982, 0.025643561490320668, 0.2185898009488952, 0.49304382365514515] +\\\n",
    "           [0.070180975320918, 0.006955316238228294, 0.03518525749237562]\n",
    "color_list = ['tab:grey'] * 4 + ['tab:brown'] * 4 + ['tab:olive'] * 3\n",
    "model_ReadableNames = ['finetuned-Basel', 'finetuned-Basel-NoTexture', 'finetuned-AppleFaces', 'finetuned-AppleFaces-dist'] + \\\n",
    "                          ['FromScratch-vggface', 'FromScratch-Basel', 'FromScratch-Basel-NoTexture', 'FromScratch-AppleFaces'] + \\\n",
    "                          ['SIN', 'SIN+IN', 'SIN+IN with IN-finetuned']\n",
    "# read numbers\n",
    "cur_r2_list = r2_list\n",
    "# plot\n",
    "plt.figure(figsize=(2*len(model_ReadableNames), 6))\n",
    "plt.bar(model_ReadableNames, cur_r2_list, color = color_list)\n",
    "plt.axhline(y=0.5687079406432649, label='human', color='red')\n",
    "plt.axhline(y=0.28832485400284535, label='marmoset', color='green')\n",
    "plt.axhline(y=0.0149, label='resnet50', color='yellow')\n",
    "for i, v in enumerate(cur_r2_list):\n",
    "    plt.text(i-0.1, v+0.01, str(v)[:5])\n",
    "\n",
    "plt.ylim([0, 0.6])\n",
    "plt.xticks(rotation=10)\n",
    "plt.title(\"Regression of latent variables\")\n",
    "plt.ylabel(\"r2\")\n",
    "data_name = data_root.split(\"/\")[-2]\n",
    "plt.legend(bbox_to_anchor=[1,1.01])\n",
    "\n",
    "plt.savefig(f\"./figs/reg_analysis_r2_all.pdf\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef369c6-1707-450e-8b2b-b48edd3b18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg analysis - significant regressor\n",
    "from matplotlib import colors\n",
    "regressors_list = [\"inversion\", \"contrast\", \"lighting\", \n",
    "                    \"rotation_x\", \"rotation_y\", \"size\"]\n",
    "data = np.array([[2, 2, 0, 2, 0, 2],\n",
    "                 [2, 1, 0, 2, 2, 0]])\n",
    "\n",
    "# create discrete colormap\n",
    "cmap = colors.ListedColormap(['black', 'rosybrown', 'red'])\n",
    "bounds = [0, 0.5, 1.5, 2]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(data.shape[1], data.shape[0]))\n",
    "\n",
    "ax.set_xticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "ax.set_yticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "ax.set_xticklabels(regressors_list, minor=False)\n",
    "ax.set_yticklabels(['human', 'marmoset'], minor=False)\n",
    "\n",
    "ax.pcolor(data, edgecolors='white', linestyle= 'dashed', linewidths=1, \n",
    "          cmap=cmap, norm=norm)\n",
    "# ax.imshow(data, cmap=cmap, norm=norm)\n",
    "# ax.imshow(data, cmap=\"Greens\")\n",
    "\n",
    "# ax.grid(which=\"minor\", axis='both', linewidth=2)\n",
    "# ax.tick_params(which=\"minor\", size=0)\n",
    "# ax.grid(which='minor', axis='both', linestyle='-', color='k', linewidth=2)\n",
    "plt.xlim((0, data.shape[1]))\n",
    "plt.title(\"Regression analysis of latent variables vs. i1\")\n",
    "plt.savefig(f\"./figs/reg_analysis_LatentVar_HumanMarmoset.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba9fe8-1815-4ab3-a2e5-22453d4d9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg analysis - significant regressor\n",
    "from matplotlib import colors\n",
    "regressors_list = [\"inversion\", \"contrast\", \"lighting\", \n",
    "                    \"rotation_x\", \"rotation_y\", \"size\"]\n",
    "data = np.array([[2, 2, 0, 2, 0, 2],\n",
    "                  [1, 2, 0, 0, 0, 2],\n",
    "                  [2, 2, 0, 0, 0, 0],\n",
    "                  [2, 2, 0, 0, 0, 0],\n",
    "                  [2, 2, 0, 2, 0, 2],\n",
    "                  [0, 0, 0, 0, 0, 1],\n",
    "                  [0, 0, 0, 0, 0, 0],\n",
    "                  [2, 2, 0, 0, 0, 0],\n",
    "                  [2, 2, 0, 2, 0, 0],\n",
    "                  [2, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0],\n",
    "                  [0, 1, 0, 0, 1, 0]][::-1])\n",
    "model_group = ['rn50_preIN_texture_sizeVar_best',\n",
    "                  'rn50_preIN_notexture_sizeVar_best',\n",
    "                  'resnet50-trained-pretrained-vbsl',\n",
    "                  'rn50_vbsl-dist-ft_epoch15'] +\\\n",
    "                 ['vggface',\n",
    "                  'rn50_FromScratch_texture_sizeVar_best',\n",
    "                  'rn50_FromScratch_notexture_sizeVar_best',\n",
    "                  'resnet50-trained-scratch-vbsl'] +\\\n",
    "                 ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']\n",
    "# create discrete colormap\n",
    "cmap = colors.ListedColormap(['black', 'rosybrown', 'red'])\n",
    "bounds = [0, 0.5, 1.5, 2]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(data.shape[1], data.shape[0]))\n",
    "\n",
    "ax.set_xticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "ax.set_yticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "ax.set_xticklabels(regressors_list, minor=False)\n",
    "ax.set_yticklabels((['human'] + model_ReadableNames)[::-1], minor=False)\n",
    "\n",
    "ax.pcolor(data, edgecolors='white', linestyle= 'dashed', linewidths=1, \n",
    "          cmap=cmap, norm=norm)\n",
    "# ax.imshow(data, cmap=cmap, norm=norm)\n",
    "# ax.imshow(data, cmap=\"Greens\")\n",
    "\n",
    "# ax.grid(which=\"minor\", axis='both', linewidth=2)\n",
    "# ax.tick_params(which=\"minor\", size=0)\n",
    "# ax.grid(which='minor', axis='both', linestyle='-', color='k', linewidth=2)\n",
    "plt.xlim((0, data.shape[1]))\n",
    "plt.title(\"Regression analysis of latent variables vs. i1\")\n",
    "plt.savefig(f\"./figs/reg_analysis_LatentVar_HumanModels.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4514418-8837-455f-a9d9-c5a344741f1d",
   "metadata": {},
   "source": [
    "## others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e61ff-7ef0-4542-b3d3-fafdb859509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "xx = [1, 3, 6, 9, 12, 15]\n",
    "# acc_list = [0.7947, 0.7538, 0.7464, 0.7464, 0.7428, 0.7791, 0.7550]\n",
    "means = acc_list \n",
    "plt.plot(xx, means, label = 'accuracy')\n",
    "for i, v in enumerate(means):\n",
    "    plt.text(xx[i]-0.20, v+0, \"%.2f\"%(v))\n",
    "\n",
    "means = i1_corr_human_list\n",
    "plt.plot(xx, means, label = 'i1 corr with human')\n",
    "for i, v in enumerate(means):\n",
    "    plt.text(xx[i]-0.20, v+0, \"%.2f\"%(v))\n",
    "    \n",
    "means = i1_corr_AJ_list\n",
    "plt.plot(xx, means, label = 'i1 corr with AJ')\n",
    "for i, v in enumerate(means):\n",
    "    plt.text(xx[i]-0.20, v+0, \"%.2f\"%(v))\n",
    "\n",
    "plt.title(\"ft epochs tuning for basal-pretrained+vbsl50k-finetuned\")\n",
    "plt.xlabel(\"ft epochs\")\n",
    "plt.legend(bbox_to_anchor=[1.02,1])\n",
    "plt.ylabel(\"acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d99c0e-b96b-4e8a-beeb-9d2e6bc4037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(['10', '100', '1000', '10000'], [0.6411, 0.6284, 0.6141, 0.6428], \n",
    "         c='blue', label='acc - with depth map pred')\n",
    "plt.axhline(y=0.63, \n",
    "            c='blue', label='acc - w/o depth map pred')\n",
    "plt.plot(['10', '100', '1000', '10000'], [0.3089, 0.2331, 0.3822, 0.2841],\n",
    "         c='red', label='i1 corr - with depth map pred')\n",
    "plt.axhline(y=0.32, \n",
    "            c='red', label='i1 corr - w/o depth map pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fe44e-51ed-4c6b-9274-903e1dd5ce77",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781eb9d5-160c-429f-abe6-eaff29da634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, rsatoolbox\n",
    "data = rsatoolbox.data.Dataset(numpy.random.rand(10, 5))\n",
    "rdms = rsatoolbox.rdm.calc_rdm(data)\n",
    "rsatoolbox.vis.show_rdm(rdms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051327d7-bb17-4896-8439-4a9ff94bad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a8ef0-a5c5-4173-bdfd-7749703aaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdms.dissimilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc0c01-72aa-4bed-abdf-cbf222284247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vbsp 101\n",
    "data_root = '../../data/face_data/vbsp_101/'\n",
    "exp_name_0 = '20210811_Var6vbsp_set0_im101_elias'\n",
    "exp_name_1 = '20210811_Var6vb_same_as_elias_sp_set0_im101_neptune'\n",
    "filename_postfix = ''\n",
    "\n",
    "model_name_list = ['resnet50', 'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft',\n",
    "                   'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl',\n",
    "                   'simplecnn-trained-vbsl']\n",
    "\n",
    "# model_name_list = ['resnet50', 'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']\n",
    "# 'resnet50-trained-pretrained-vbsl'\n",
    "# model_name_list = ['resnet50-trained-scratch-vbsl', 'simplecnn-trained-vbsl']\n",
    "\n",
    "rdms = {}\n",
    "for model_name in model_name_list:\n",
    "    # read feats\n",
    "    input_1 = torch.load(os.path.join(data_root,\n",
    "                                  exp_name_0+'_'+model_name+filename_postfix+'.pth'))\n",
    "    input_2 = torch.load(os.path.join(data_root,\n",
    "                                      exp_name_1+'_'+model_name+filename_postfix+'.pth'))\n",
    "    inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "    data = rsatoolbox.data.Dataset(inputs)\n",
    "    rdms[model_name] = rsatoolbox.rdm.calc_rdm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253af40-0dca-4499-8423-d0ad65e81fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_rdms = []\n",
    "for model_name_0 in model_name_list:\n",
    "    _corr_rdms = []\n",
    "    for model_name_1 in model_name_list:\n",
    "        _corr = scipy.stats.pearsonr(rdms[model_name_0].dissimilarities.squeeze(), \n",
    "                             rdms[model_name_1].dissimilarities.squeeze())\n",
    "        _corr_rdms.append(_corr[0])\n",
    "    corr_rdms.append(_corr_rdms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62146227-4eec-4bc3-aff6-f87e44b153b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = plt.imshow(corr_rdms, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label=\"corr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38e36f-e3e3-40db-a786-66ae32fec547",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57a134-6f29-4b30-8d45-7ff34f1adbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsatoolbox.vis.show_rdm(rdms['simplecnn-trained-vbsl'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e35bbe-e496-41ed-ac69-c9e69dc45ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsatoolbox.vis.show_rdm(rdms['resnet50-trained-pretrained-vbsl'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1af68-016a-451b-aeef-4c478232c47d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train/test on diff imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbde6b3-6f48-4b28-8b0f-313d5e5d3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare training data\n",
    "\n",
    "# # vbsl 101\n",
    "# data_root = '../../data/face_data/vbsl_101/'\n",
    "# exp_name_0 = '20210920_Var6vbsl_set0_im101_elias'\n",
    "# exp_name_1 = '20210920_Var6vbsl_set0_im101_neptune'\n",
    "\n",
    "# vbsl 200\n",
    "data_root = '../../data/face_data/vbsl_200_new_bg/'\n",
    "exp_name_0 = '2022105_Var6vbsl_set0_im200_elias'\n",
    "exp_name_1 = '2022105_Var6vbsl_set0_im200_neptune'\n",
    "filename_postfix = ''\n",
    "\n",
    "# model_name_list = ['resnet50', 'alexnet', 'vgg16']\n",
    "# model_name_list = ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']\n",
    "# model_name_list = ['resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'simplecnn-trained-vbsl']\n",
    "# model_name_list = ['rn50_preIN_notexture_model_best', 'rn50_preIN_texture_model_best']\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_best']\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_2losses', 'rn50_preIN_notexture_sizeVar_onlyDM']\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_onlyDM']\n",
    "\n",
    "model_name = 'resnet50-trained-scratch-vbsl'\n",
    "\n",
    "# read feats\n",
    "train_input_1 = torch.load(os.path.join(data_root,\n",
    "                              exp_name_0+'_'+model_name+filename_postfix+'.pth'))\n",
    "train_input_2 = torch.load(os.path.join(data_root,\n",
    "                              exp_name_1+'_'+model_name+filename_postfix+'.pth'))\n",
    "train_input_1 = train_input_1.reshape(len(train_input_1), -1)\n",
    "train_input_2 = train_input_2.reshape(len(train_input_2), -1)\n",
    "print(train_input_1.shape, train_input_2.shape)\n",
    "# rebalance: shuffle and remove\n",
    "torch.manual_seed(7)\n",
    "# prepare data\n",
    "train_output_1 = np.ones(len(train_input_1))\n",
    "train_output_2 = np.zeros(len(train_input_2))\n",
    "train_inputs = np.concatenate((train_input_1, train_input_2), axis=0)\n",
    "train_outputs = np.concatenate((train_output_1, train_output_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00c20a-1ad4-4855-9575-b4dfaa101fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare test data\n",
    "\n",
    "# vbsl 151\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "exp_name_0 = '20211011_Var6vbsl_set0_im151_elias'\n",
    "exp_name_1 = '20211011_Var6vbsl_set0_im151_neptune'\n",
    "\n",
    "# read feats\n",
    "test_input_1 = torch.load(os.path.join(data_root,\n",
    "                              exp_name_0+'_'+model_name+filename_postfix+'.pth'))\n",
    "test_input_2 = torch.load(os.path.join(data_root,\n",
    "                                  exp_name_1+'_'+model_name+filename_postfix+'.pth'))\n",
    "test_input_1 = test_input_1.reshape(len(test_input_1), -1)\n",
    "test_input_2 = test_input_2.reshape(len(test_input_2), -1)\n",
    "print(test_input_1.shape, test_input_2.shape)\n",
    "test_output_1 = np.ones(len(test_input_1))\n",
    "test_output_2 = np.zeros(len(test_input_2))\n",
    "test_inputs = np.concatenate((test_input_1, test_input_2), axis=0)\n",
    "test_outputs = np.concatenate((test_output_1, test_output_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95c027-8c1e-4beb-ad08-906ac0bd107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test classifiers\n",
    "\n",
    "num_rep = 100\n",
    "acc_per_img = np.nan * np.ones((num_rep, len(test_outputs))) \n",
    "dists = np.nan * np.ones((num_rep, len(test_outputs))) \n",
    "\n",
    "for rep_index in tqdm(range(num_rep)):\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "    scores = []\n",
    "\n",
    "    # iter through splits of cv\n",
    "    for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "        # split data\n",
    "        X_train = np.concatenate((train_input_1[train_index], train_input_2[train_index]), axis=0)\n",
    "        y_train = np.concatenate((train_output_1[train_index], train_output_2[train_index]), axis=0)\n",
    "        \n",
    "        # fit model\n",
    "        clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                             tol=1e-4,\n",
    "                             fit_intercept=True,\n",
    "                             C=1.0,\n",
    "                            max_iter = 20000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        # record score & dist - part 1\n",
    "        y_predict = clf.predict(test_input_1)\n",
    "        _acc_per_img = (y_predict == test_output_1).astype('float32')\n",
    "        acc_per_img[rep_index][:len(test_input_1)] = _acc_per_img\n",
    "        _dist = clf.decision_function(test_input_1)\n",
    "        dists[rep_index][:len(test_input_1)] = _dist\n",
    "        # record score & dist - part 2\n",
    "        y_predict = clf.predict(test_input_2)\n",
    "        _acc_per_img = (y_predict == test_output_2).astype('float32')\n",
    "        acc_per_img[rep_index][len(test_input_2):] = _acc_per_img\n",
    "        _dist = clf.decision_function(test_input_2)\n",
    "        dists[rep_index][len(test_input_2):] = _dist * (-1) # negate for diff sign\n",
    "        \n",
    "        # only use half of the training set \n",
    "        break\n",
    "acc_per_img = acc_per_img.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5e03e-4461-4ee2-b065-f129ae54bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stats -> vbsl151 subset analysis\n",
    "\n",
    "subset_list = [[0,2], [1,3], [4,5],\n",
    "               [0,1,2,3], [0,2,4,5], [1,3,4,5], [0,1,2,3,4,5]]\n",
    "subset_name_list = ['normal_face', 'inverted_face', 'reverse_contrast', \n",
    "                   '1+2', '1+3', '2+3', 'full']\n",
    "\n",
    "print(model_name)\n",
    "\n",
    "for subset_id, subset in enumerate(subset_list):\n",
    "    # get acc\n",
    "    tmp = acc_per_img.reshape((2,151)).mean(0)\n",
    "    tmp_group = tmp[:150].reshape(6,25).mean(axis=1)\n",
    "    print(\"%s\\nacc: %.2f\" % (subset_name_list[subset_id], tmp_group[subset].mean()))\n",
    "    \n",
    "    # get bio i1s\n",
    "    bio_i1s = human_i1s.squeeze()\n",
    "    # model i1s\n",
    "    i1_dists = dists\n",
    "    model_i1s = []\n",
    "    for rep_index in range(5):\n",
    "        np.random.shuffle(i1_dists)\n",
    "        tmp = np.concatenate([i1_dists[:int(num_rep/2)].mean(0), \n",
    "                              i1_dists[int(num_rep/2):].mean(0)])\n",
    "        model_i1s.append(np.expand_dims(tmp, axis=0))\n",
    "    model_i1s = np.concatenate(model_i1s, axis=0)\n",
    "    # get subset\n",
    "    model_i1s = model_i1s.reshape((5,4,151))[:,:,:150].reshape((5,4,6,25))\n",
    "    model_i1s = model_i1s[:,:,subset,:].reshape(5,-1)\n",
    "    bio_i1s = bio_i1s.reshape((5,4,151))[:,:,:150].reshape((5,4,6,25))\n",
    "    bio_i1s = bio_i1s[:,:,subset,:].reshape(5,-1)\n",
    "    \n",
    "    # print(model_i1s.shape, bio_i1s.shape)\n",
    "    \n",
    "    # calc i1 corr\n",
    "    i1_corr = []\n",
    "    model_internal = []\n",
    "    bio_internal = []\n",
    "    half_length = int(model_i1s.shape[1]/2)\n",
    "    for rep_index in range(5):\n",
    "        corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "        corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "        corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "        corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "        # print(corr_1, corr_2, corr_3, corr_4)\n",
    "        i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "        model_internal.append(corr_3)\n",
    "        bio_internal.append(corr_4)\n",
    "    print(\"i1 corr: %.2f+-%.2f, model: %.2f, bio: %.2f\" % (np.mean(np.array(i1_corr)), \n",
    "                                                  np.std(np.array(i1_corr)),\n",
    "                                                 np.mean(np.array(corr_3)),\n",
    "                                                 np.mean(np.array(corr_4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88732e0b-12bf-4eb1-9951-d3d061fc7127",
   "metadata": {
    "tags": []
   },
   "source": [
    "## train/test on subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74355e6f-bdbe-4190-b977-5b105a3ac481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vbsl 151\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "exp_name_0 = '20211011_Var6vbsl_set0_im151_elias'\n",
    "exp_name_1 = '20211011_Var6vbsl_set0_im151_neptune'\n",
    "\n",
    "# # vbsl 151 - obj\n",
    "# data_root = '../../data/face_data/control_exp/objs/'\n",
    "# exp_name_0 = '20211011_Var6vbsl_set0_im151_camel'\n",
    "# exp_name_1 = '20211011_Var6vbsl_set0_im151_elephant'\n",
    "\n",
    "filename_postfix = ''\n",
    "num_rep = 100\n",
    "\n",
    "# model_name_list = ['resnet50', 'alexnet', 'vgg16']\n",
    "# model_name_list = ['resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft']\n",
    "# model_name_list = ['resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'simplecnn-trained-vbsl']\n",
    "# model_name_list = ['rn50_preIN_notexture_model_best', 'rn50_preIN_texture_model_best']\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_best']\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_2losses', 'rn50_preIN_notexture_sizeVar_onlyDM']\n",
    "# model_name_list = ['rn50_preIN_notexture_sizeVar_onlyDM']\n",
    "\n",
    "model_name_list = ['rn50_preIN_notexture_sizeVar_best', 'resnet50', \n",
    "                  'resnet50-trained-pretrained-vbsl', \n",
    "                  'rn50_preIN_notexture_model_best']\n",
    "\n",
    "dict_scores = {}\n",
    "dict_i1_dists = {}\n",
    "dict_conf_mat = {}\n",
    "acc_per_img = {}\n",
    "\n",
    "subset_list = [[0,2], [1,3], [4,5],\n",
    "               [0,1,2,3], [0,2,4,5], [1,3,4,5]]\n",
    "subset_name_list = ['normal_face', 'inverted_face', 'reverse_contrast', \n",
    "                   '1+2', '1+3', '2+3']\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    # iter over subsets: \n",
    "    for subset_index in range(len(subset_list)):\n",
    "        subset = subset_list[subset_index]\n",
    "        subset_name = subset_name_list[subset_index]\n",
    "    \n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove\n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):\n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "    \n",
    "        # subsetting input\n",
    "        input_1 = input_1[:150].reshape((6,25,input_1.shape[1]))\n",
    "        input_1 = input_1[subset,:].reshape(-1,2048)\n",
    "        input_2 = input_2[:150].reshape((6,25,input_2.shape[1]))\n",
    "        input_2 = input_2[subset,:].reshape(-1,2048)\n",
    "        # subsetting output\n",
    "        output_1 = output_1[:150].reshape((6,25))\n",
    "        output_1 = output_1[subset,:].reshape(-1)\n",
    "        output_2 = output_2[:150].reshape((6,25))\n",
    "        output_2 = output_2[subset,:].reshape(-1)\n",
    "        \n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 101]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, subset_name, '%.4f+-%.4f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        \n",
    "        if model_name not in dict_i1_dists:\n",
    "            dict_i1_dists[model_name] = {}\n",
    "        if model_name not in acc_per_img:\n",
    "            acc_per_img[model_name] = {}\n",
    "        dict_i1_dists[model_name][subset_name] = dists\n",
    "        acc_per_img[model_name][subset_name] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350545b-d98b-4583-b866-304c1a5a048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "useful_stats_subset = {}\n",
    "useful_stats_subset['dist'] = dict_i1_dists\n",
    "useful_stats_subset['acc_per_img'] = acc_per_img\n",
    "\n",
    "with open('useful_stats_subset.pkl', 'wb') as f:\n",
    "    pickle.dump(useful_stats_subset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33358aa-9c4e-43a0-b582-28a6652f0d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calc i1 corr\n",
    "\n",
    "## subset testing for vbsl151 / no recording\n",
    "\n",
    "# 'resnet50', 'alexnet', 'vgg16'\n",
    "# 'resnet50', 'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft'\n",
    "# 'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl'\n",
    "# 'rn50_preIN_notexture_model_best', 'rn50_preIN_texture_model_best'\n",
    "# 'rn50_preIN_notexture_sizeVar_best'\n",
    "# 'rn50_preIN_notexture_sizeVar_2losses'\n",
    "\n",
    "bio_i1s_list = [human_vbsl151]\n",
    "data_root = '../../data/face_data/vbsl_151/'\n",
    "# model_name_list = list(useful_stats[data_root].keys())\n",
    "\n",
    "num_rep = 100\n",
    "subset_list = [[0,2], [1,3], [4,5],\n",
    "               [0,1,2,3], [0,2,4,5], [1,3,4,5]]\n",
    "subset_name_list = ['normal_face', 'inverted_face', 'reverse_contrast', \n",
    "                   '1+2', '1+3', '2+3']\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    print(model_name)\n",
    "    \n",
    "    for subset_id, subset in enumerate(subset_list):\n",
    "        subset_name = subset_name_list[subset_id]\n",
    "        # get acc\n",
    "        print(\"%s\\nacc: %.2f\" % (subset_name, useful_stats_subset['acc_per_img'][model_name][subset_name].mean()))\n",
    "        \n",
    "        for bio_inedx, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get model i1s\n",
    "            i1_dists = useful_stats_subset['dist'][model_name][subset_name]\n",
    "            i1_dists = np.concatenate((i1_dists[0], i1_dists[1]), axis=1)\n",
    "            model_i1s = []\n",
    "            for rep_index in range(5):\n",
    "                np.random.shuffle(i1_dists)\n",
    "                tmp = np.concatenate([i1_dists[:int(num_rep/2)].mean(0), \n",
    "                                      i1_dists[int(num_rep/2):].mean(0)])\n",
    "                model_i1s.append(np.expand_dims(tmp, axis=0))\n",
    "            model_i1s = np.concatenate(model_i1s, axis=0)\n",
    "            \n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only\n",
    "            \n",
    "            # get subset for model/bio i1s\n",
    "            # no need to subset model_i1s\n",
    "            # model_i1s = model_i1s.reshape((5,4,151))[:,:,:150].reshape((5,4,6,25))\n",
    "            # model_i1s = model_i1s[:,:,subset,:].reshape(5,-1)\n",
    "            bio_i1s = bio_i1s.reshape((5,4,151))[:,:,:150].reshape((5,4,6,25))\n",
    "            bio_i1s = bio_i1s[:,:,subset,:].reshape(5,-1)\n",
    "            # print(model_i1s.shape, bio_i1s.shape)\n",
    "\n",
    "            # calc i1 corr\n",
    "            i1_corr = []\n",
    "            model_internal = []\n",
    "            bio_internal = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                # print(corr_1, corr_2, corr_3, corr_4)\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                model_internal.append(corr_3)\n",
    "                bio_internal.append(corr_4)\n",
    "            print(\"i1 corr: %.2f+-%.2f, model: %.2f, bio: %.2f\\n\" % (np.mean(np.array(i1_corr)), \n",
    "                                                          np.std(np.array(i1_corr)),\n",
    "                                                         np.mean(np.array(corr_3)),\n",
    "                                                         np.mean(np.array(corr_4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b3e2c-e6d6-4ca7-8ab1-fc89b2160ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLC]",
   "language": "python",
   "name": "conda-env-DLC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
