{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from load_model import load_model\n",
    "from load_model_barlowtwins import load_barlowtwins_model\n",
    "\n",
    "from rn50_auxiliary_dm import rn50_auxiliary_dm\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment list summarized\n",
    "\n",
    "# Basic GFR/CTFR/GOR tasks \n",
    "exp_names_list_basics = [\n",
    "    # 1. (AppleMesh09) Apple GFR - AppleMesh00/AppleMesh01 neutral\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_AppleMesh00',\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/20211011_Var6vbsl_set0_im151_AppleMesh01',\n",
    "\n",
    "    # 2. (AppleMesh02) Apple GFR - AppleMesh00/AppleMesh01 neutral\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral',\n",
    "\n",
    "    # 3. (AppleMesh09) Apple GFR - AppleMesh03/Praneeth\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_AppleMesh03_praneeth/20230406_Var6vbsl_set0_im151_praneeth_dur200ms_lab',\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_AppleMesh03_praneeth/20230406_Var6vbsl_set0_im151_AppleMesh03_dur200ms_lab',\n",
    "\n",
    "    # 4. (AppleMesh09) Basel CTFR \n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_basel_ood/20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_dur200ms_lab',\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_basel_ood/20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_dur200ms_lab',\n",
    "\n",
    "    # 5. (AppleMesh09) Basel GFR\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_notexture_dur200ms_lab',\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_notexture_dur200ms_lab',\n",
    "]\n",
    "\n",
    "# complete GFR\n",
    "exp_names_list_GFR = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral',\n",
    "]\n",
    "\n",
    "# complete CTFR\n",
    "exp_names_list_CTFR = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh01_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh02_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh03_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh04_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh05_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh06_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh07_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh08_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh09_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh10_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh11_neutral',\n",
    "]\n",
    "\n",
    "# complete GTFR \n",
    "exp_names_list_GTFR = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh01_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh02_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh03_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh04_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh05_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh06_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh07_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh08_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh09_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh10_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh11_neutral',\n",
    "]\n",
    "\n",
    "# complete GER (AppleMesh03)\n",
    "exp_names_list_GER_AppleMesh03 = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_disgust_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/vbsle151_AppleMesh03_surprise_4',\n",
    "   ]\n",
    "\n",
    "# complete GER (AppleMesh00)\n",
    "exp_names_list_GER_AppleMesh00  = [ \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_disgust_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/vbsle151_AppleMesh00_surprise_4',\n",
    "    ]\n",
    "\n",
    "# complete CTER (AppleMesh00)\n",
    "exp_names_list_CTER_AppleMesh00 = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_disgust_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/vbsl151_AppleMesh00_surprise_4',\n",
    "]\n",
    "\n",
    "# complete GTER (AppleMesh00)\n",
    "exp_names_list_GTER_AppleMesh00 = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_neutral',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_happiness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_sadness_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_disgust_4'\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_fear_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_anger_4',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/vbsl151_AppleMesh00_surprise_4',\n",
    "]\n",
    "\n",
    "# complete Basel GFR (id10-21)\n",
    "exp_names_list_basel_GFR = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id10',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id11',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id12',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id13',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id14',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id15',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id16',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id17',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id18',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id19',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id20',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id21',\n",
    "]\n",
    "\n",
    "# complte Basel CTFR (id10-21)\n",
    "exp_names_list_basel_CTFR = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id10',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id11',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id12',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id13',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id14',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id15',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id16',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id17',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id18',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id19',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id20',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id21',\n",
    "]\n",
    "\n",
    "# complete Basel GFR (id988-999)\n",
    "exp_names_list_basel_GFR_ver2 = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id988',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id989',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id990',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id991',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id992',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id993',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id994',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id995',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id996',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id997',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id998',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/id999',\n",
    "]\n",
    "\n",
    "# complte Basel CTFR (id988-999)\n",
    "exp_names_list_basel_CTFR_ver2 = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id988',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id989',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id990',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id991',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id992',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id993',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id994',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id995',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id996',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id997',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id998',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/id999',\n",
    "]\n",
    "\n",
    "# LFW (upright, inverted)\n",
    "exp_names_list_lfw = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell/Bush',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell/Powell',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell_inverted/Bush',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell_inverted/Powell',\n",
    "]\n",
    "\n",
    "# YouTube Faces\n",
    "exp_names_list_ytface = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Stanca',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Beard',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Kennedy',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/Macdonald',\n",
    "]\n",
    "\n",
    "# complete GOR \n",
    "exp_names_list_GOR = [\n",
    "    # 1. (AppleMesh09) GOR - Camel/Elephant\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_camel',\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant',\n",
    "\n",
    "    # 2. GOR - Dog/Horse \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_dog_horse/vbsle_151_dog', \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_dog_horse/vbsle_151_horse',\n",
    "\n",
    "    # 3. GTOR - Camel/Elephant\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_gray_downsampled/camel_colored_gray',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_gray_downsampled/elephant_colored_gray',\n",
    "    \n",
    "    # 4. CTOR - Camel/Elephant\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_downsampled/camel_colored',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_downsampled/elephant_colored',\n",
    "]\n",
    "\n",
    "# ImageNet-based tasks (general object recognition)\n",
    "exp_names_list_imagenet = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/shark151/shark1',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/shark151/shark2',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/bird151/bird1',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/bird151/bird2',\n",
    "    \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/vehicle151/bike',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/vehicle151/car'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feautres for standard models \n",
    "\n",
    "# Specify experiment type \n",
    "exp_names_list = exp_names_list_GFR\n",
    "\n",
    "# Specify the list of \"model names\"\n",
    "model_names_list=[\n",
    "# 'off_the_shelf_barlowtwins_finetune_7way_EM_AppleMesh03_colorbg_seed77_model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_7way_EM_AppleMesh04_colorbg_seed77__model_best',\n",
    "# 'off_the_shelf_barlowtwins_finetune_7way_EM_AppleMesh08_colorbg_seed77__model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_4way_IDEM_AppleMesh02_AppleMesh03_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_4way_IDEM_AppleMesh02_AppleMesh04_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_4way_IDEM_AppleMesh03_AppleMesh08_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_6way_IDEM_AppleMesh02_AppleMesh03_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_6way_IDEM_AppleMesh02_AppleMesh04_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_6way_IDEM_AppleMesh03_AppleMesh08_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_8way_IDEM_AppleMesh02_AppleMesh03_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_8way_IDEM_AppleMesh02_AppleMesh04_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_8way_IDEM_AppleMesh03_AppleMesh08_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_10way_IDEM_AppleMesh02_AppleMesh03_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_10way_IDEM_AppleMesh02_AppleMesh04_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_10way_IDEM_AppleMesh03_AppleMesh08_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_12way_IDEM_AppleMesh02_AppleMesh03_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_12way_IDEM_AppleMesh02_AppleMesh04_colorbg_seed77_model_best',\n",
    "'off_the_shelf_barlowtwins_finetune_12way_IDEM_AppleMesh03_AppleMesh08_colorbg_seed77_model_best',\n",
    "]\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "filename_postfix = ''\n",
    "save_label = False\n",
    "\n",
    "for model_name in model_names_list:\n",
    "    # flatten & subsample for previous layers of resnet50\n",
    "    if 'layer' in model_name or \"subsampled\" in model_name:\n",
    "        if \"layerC2\" in model_name and \"layerC2_subsampled\" not in model_name:\n",
    "            subsample = False\n",
    "        else:\n",
    "            subsample = True\n",
    "    else:\n",
    "        subsample = False\n",
    "    \n",
    "    # load model\n",
    "    model = load_model(model_name)\n",
    "    model.eval()\n",
    "    \n",
    "    # add hook\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    if 'simplecnn' in model_name:\n",
    "        model.fc2.register_forward_hook(get_activation('feats'))\n",
    "    elif 'alexnet' in model_name:\n",
    "        if 'layer4' in model_name:\n",
    "            print(\"add hook in layer4\")\n",
    "            model.features[4].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer8' in model_name:\n",
    "            print(\"add hook in layer8\")\n",
    "            model.features[8].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer12' in model_name:\n",
    "            print(\"add hook in layer12\")\n",
    "            model.features[12].register_forward_hook(get_activation('feats'))\n",
    "        elif 'layerC2' in model_name:\n",
    "            model.classifier[2].register_forward_hook(get_activation('feats'))\n",
    "        else: # final layer\n",
    "            model.classifier[5].register_forward_hook(get_activation('feats'))\n",
    "    elif model_name == 'vgg16':\n",
    "        model.classifier[4].register_forward_hook(get_activation('feats'))\n",
    "    elif model_name == 'vggface':\n",
    "        model.fc7.register_forward_hook(get_activation('feats'))\n",
    "    elif 'onlyDM' in model_name:\n",
    "        model.depth_predictor.encoder[4].register_forward_hook(get_activation('feats'))\n",
    "    elif 'head' in model_name :\n",
    "        model.module.backbone.avgpool.register_forward_hook(get_activation('feats'))\n",
    "    elif 'remapping' in model_name :\n",
    "        model.module.backbone.avgpool.register_forward_hook(get_activation('feats'))\n",
    "    else: # resnet50\n",
    "        if 'layer1' in model_name:\n",
    "            print(\"add hook in layer1\")\n",
    "            model.layer1.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer2' in model_name:\n",
    "            print(\"add hook in layer2\")\n",
    "            model.layer2.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer3' in model_name:\n",
    "            print(\"add hook in layer3\")\n",
    "            model.layer3.register_forward_hook(get_activation('feats'))\n",
    "        elif 'layer4_no_pooling' in model_name:\n",
    "            print(\"add hook in layer4_no_pooling\")\n",
    "            model.layer4.register_forward_hook(get_activation('feats'))\n",
    "        else:\n",
    "            model.avgpool.register_forward_hook(get_activation('feats'))\n",
    "        \n",
    "    # load data\n",
    "    for exp_index, exp_name in enumerate(exp_names_list):\n",
    "        print(model_name, exp_name)\n",
    "        valdir = exp_name\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        _trans = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "        ## read & sort img filenames\n",
    "        all_filenames = []\n",
    "        # read img filenames\n",
    "        for filename in os.listdir(valdir):\n",
    "            if filename[-4:]=='.png':\n",
    "                # for basal dataset / new controled exps\n",
    "                assert(filename[:13]=='canvasvisible' or filename[:8]=='trialnum')\n",
    "                all_filenames.append(filename)\n",
    "            \n",
    "                \n",
    "        ## sort img filenames -> fix bug of sorting by value\n",
    "        # for basal dataset / new controled exps\n",
    "        if all_filenames[0][:13]=='canvasvisible':\n",
    "            all_filenames = sorted(all_filenames, key=lambda x: int(x[:-4].split(\"_\")[-1][5:]))\n",
    "        elif all_filenames[0][:8]=='trialnum':\n",
    "            all_filenames = sorted(all_filenames, key=lambda x: int(x[8:-4]))\n",
    "        else:\n",
    "            assert False, 'unsupported filename'\n",
    "        print(len(all_filenames))\n",
    "        \n",
    "        # extract feats\n",
    "        FEATS = []\n",
    "        LABELS = []\n",
    "        # loop through batches\n",
    "        for idx, filename in enumerate(all_filenames):\n",
    "            # read & transform img\n",
    "            img = Image.open(os.path.join(valdir, filename)).convert(\"RGB\")\n",
    "            img_trans = _trans(img)\n",
    "            \n",
    "            # move to device\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            inputs = img_trans.unsqueeze(0).to(device)  # Move inputs to the same device as the model\n",
    "            # forward pass [with feature extraction]\n",
    "            preds = model(inputs)\n",
    "            # preds = model.forward_single(inputs)\n",
    "            # add feats and preds to lists\n",
    "            # if 'simplecnn' in model_name:\n",
    "            #     activation['feats'] = F.relu(activation['feats'])\n",
    "            FEATS.append(activation['feats'].cpu().squeeze().unsqueeze(0).numpy())\n",
    "            if save_label:\n",
    "                LABELS.append(outputs.cpu().squeeze().unsqueeze(0).numpy())\n",
    "        FEATS = np.concatenate(FEATS, axis=0)\n",
    "        if save_label:\n",
    "            LABELS = np.concatenate(LABELS, axis=0)\n",
    "        print(FEATS.shape)\n",
    "        \n",
    "        if subsample:\n",
    "            FEATS = FEATS.reshape([FEATS.shape[0], -1])\n",
    "            if exp_index == 0: # use the same subset indexes for all exp\n",
    "                # sampled_indexes = np.random.permutation()\n",
    "                # sampled_indexes = np.random.permutation(FEATS.shape[1])[:2048]\n",
    "                sampled_indexes = np.random.choice(FEATS.shape[1], 2048, replace=False)\n",
    "            FEATS = FEATS[:, sampled_indexes]\n",
    "            print(f\"subsample to 2048 feats, {FEATS.shape}\")\n",
    "        \n",
    "        # save feats\n",
    "        filename = exp_name+'_'+model_name+filename_postfix+'.pth'\n",
    "        torch.save(FEATS, filename)\n",
    "        print(f'saving to {filename}\\n')\n",
    "        \n",
    "        if save_label:\n",
    "            filename = exp_name+'_'+model_name+filename_postfix+'_label.pth'\n",
    "            torch.save(LABELS, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human data simulation (7-way emotion)\n",
    "# exp_names_list_GER_AppleMesh00_fixedparams: multiway classficiation\n",
    "# (1) exp_names_list_GER_AppleMesh00_fixedparams\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Ahana/data/Emotion_Identity_Stimuli_HiRes4000/Emotion/'] * 21\n",
    "exp_name_list = [\n",
    "                ['im20_AppleMesh00_anger4_fixedparams', 'im20_AppleMesh00_disgust4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_anger4_fixedparams', 'im20_AppleMesh00_fear4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_anger4_fixedparams', 'im20_AppleMesh00_happiness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_anger4_fixedparams', 'im20_AppleMesh00_neutral_fixedparams'],\n",
    "                 ['im20_AppleMesh00_anger4_fixedparams', 'im20_AppleMesh00_sadness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_anger4_fixedparams', 'im20_AppleMesh00_surprise4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_disgust4_fixedparams', 'im20_AppleMesh00_fear4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_disgust4_fixedparams', 'im20_AppleMesh00_happiness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_disgust4_fixedparams', 'im20_AppleMesh00_neutral_fixedparams'],\n",
    "                 ['im20_AppleMesh00_disgust4_fixedparams', 'im20_AppleMesh00_sadness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_disgust4_fixedparams', 'im20_AppleMesh00_surprise4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_fear4_fixedparams', 'im20_AppleMesh00_happiness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_fear4_fixedparams', 'im20_AppleMesh00_neutral_fixedparams'],\n",
    "                 ['im20_AppleMesh00_fear4_fixedparams', 'im20_AppleMesh00_sadness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_fear4_fixedparams', 'im20_AppleMesh00_surprise4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_happiness4_fixedparams', 'im20_AppleMesh00_neutral_fixedparams'],\n",
    "                 ['im20_AppleMesh00_happiness4_fixedparams', 'im20_AppleMesh00_sadness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_happiness4_fixedparams', 'im20_AppleMesh00_surprise4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_neutral_fixedparams', 'im20_AppleMesh00_sadness4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_neutral_fixedparams', 'im20_AppleMesh00_surprise4_fixedparams'],\n",
    "                 ['im20_AppleMesh00_sadness4_fixedparams', 'im20_AppleMesh00_surprise4_fixedparams'],\n",
    "]\n",
    "emotion_names = ['anger4', 'disgust4', 'fear4', 'happiness4', 'neutral', 'sadness4', 'surprise4']\n",
    "num_classes = 7\n",
    "model_names_list = ['SL_colorbg_resnet50_finetune_7way_EM_AppleMesh02_seed77_model_best']\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in np.arange(1):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "        # read feats\n",
    "        inputs_all = []\n",
    "        labels_all = []\n",
    "        for class_idx, id_name in enumerate(emotion_names):\n",
    "            os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "            path = os.path.join(data_root, f'im20_AppleMesh00_{id_name}_fixedparams_{model_name}{filename_postfix}.pth')\n",
    "            print(f\"loading {path}\")\n",
    "            features = torch.load(path)\n",
    "            features = features.reshape(len(features), -1)\n",
    "            inputs_all.append(features)\n",
    "            labels_all.append(np.full(len(features), class_idx))\n",
    "        inputs_all = np.concatenate(inputs_all, axis=0)\n",
    "        labels_all = np.concatenate(labels_all, axis=0)\n",
    "        dists = np.nan * np.ones((2, num_rep, len(labels_all))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(labels_all))) \n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((7,7))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(inputs_all, labels_all)):\n",
    "                # split data\n",
    "                X_train = inputs_all[train_index]\n",
    "                X_test = inputs_all[test_index]\n",
    "                y_train = labels_all[train_index]\n",
    "                y_test = labels_all[test_index]\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                _score = (y_predict == y_test).mean()\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict, labels=np.arange(num_classes))\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[split_index, rep_index, test_index] = _acc_per_img\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "        #get task name\n",
    "        name1 = exp_name_0.split('_')\n",
    "        name2 = exp_name_1.split('_')\n",
    "        newname = name1[2] + name2[2]\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name][newname] = {}\n",
    "        useful_stats[data_root][model_name][newname]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name][newname]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name][newname]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label distribution:\", np.bincount(labels_all))\n",
    "per_class_acc = np.diag(conf_mat) / conf_mat.sum(axis=1)\n",
    "print(\"Per-class accuracy:\", per_class_acc)\n",
    "print(\"Mean per-class accuracy:\", per_class_acc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pixels\n",
    "\n",
    "for exp_name in exp_names_list:\n",
    "    valdir = exp_name\n",
    "\n",
    "    ## read & sort img filenames\n",
    "    all_filenames = []\n",
    "    # read img filenames\n",
    "    for filename in os.listdir(valdir):\n",
    "        if filename[-4:]=='.png':\n",
    "            # for basal dataset / new controled exps\n",
    "            # assert(filename[:13]=='canvasvisible' or filename[:8]=='trialnum')\n",
    "            all_filenames.append(filename)\n",
    "\n",
    "    ## sort img filenames -> fix bug of sorting by value\n",
    "    # for basal dataset / new controled exps\n",
    "    if all_filenames[0][:13]=='canvasvisible':\n",
    "        all_filenames = sorted(all_filenames, key=lambda x: int(x[:-4].split(\"_\")[-1][5:]))\n",
    "    elif all_filenames[0][:8]=='trialnum':\n",
    "        all_filenames = sorted(all_filenames, key=lambda x: int(x[8:-4]))\n",
    "    # else:\n",
    "    #     assert False, 'unsupported filename'\n",
    "    print(len(all_filenames))\n",
    "    \n",
    "    # extract feats\n",
    "    FEATS = []\n",
    "    # loop through batches\n",
    "    for idx, filename in enumerate(all_filenames):\n",
    "        # read & transform img\n",
    "        img = Image.open(os.path.join(valdir, filename)).convert('L')\n",
    "        img = img.resize((64, 64))\n",
    "        FEATS.append(np.array(img).reshape(-1))\n",
    "    FEATS = np.array(FEATS)\n",
    "    print(FEATS.shape)\n",
    "\n",
    "    # save feats\n",
    "    filename = exp_name+'_'+'pixel'+'.pth'\n",
    "    torch.save(FEATS, filename)\n",
    "    print(f'saving to {filename}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get bio i1s - GFR (AppleMesh00 vs AppleMesh01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file that contains biological i1 data\n",
    "\n",
    "# Human i1, GFR (AppleMesh00-AppleMesh01)\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_AppleMesh01/human_n_subs=37_20211011_Var6vbsl_set0_im151_AppleMesh00_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh01_dur200ms_lab_updated.json_I1_partition_splithalf_trial_binsize=35245_n_rep=5\"\n",
    "_path = \"../data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_AppleMesh00_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh01_dur200ms_lab_updated.json_n_rep=5\"\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_AppleMesh00_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh01_dur200ms_lab_updated.json_n_rep=5\"\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1_5rep = pickle.load(f).squeeze()\n",
    "\n",
    "# Monkey i1, GFR (AppleMesh00-AppleMesh01)\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_AppleMesh01/AJ_176_20211011_Var6vbsl_set0_im151_AppleMesh01_dur400ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh00_dur400ms_lab_updated.json_0_I1_partition_splithalf_trial_binsize=24008n_rep=5\"\n",
    "_path = \"../data/face_data/bio_data/avg-monkey-i1_splithalf\"\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/bio_data/avg-monkey-i1_splithalf\"\n",
    "with open(_path, 'rb') as f:\n",
    "    marmoset_i1_5rep = pickle.load(f).squeeze()\n",
    "\n",
    "# Human i1, GFR (AppleMesh00-AppleMesh01) - no rep\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_AppleMesh01/human_n_subs=37_20211011_Var6vbsl_set0_im151_AppleMesh00_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh01_dur200ms_lab_updated.json_I1_partition_trial_binsize=35245\"\n",
    "_path = \"../data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_AppleMesh00_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh01_dur200ms_lab_updated.json\"\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/bio_data/human-avg-sub_20211011_Var6vbsl_set0_im151_AppleMesh00_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh01_dur200ms_lab_updated.json\"\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1 = pickle.load(f).squeeze().reshape(-1)\n",
    "\n",
    "# Monkey i1, GFR (AppleMesh00-AppleMesh01) - no rep\n",
    "# _path = \"../../data/face_data/20211011_Var6vbsl_set0_im151_AppleMesh01/AJ_176_20211011_Var6vbsl_set0_im151_AppleMesh01_dur400ms_lab_updated.json_20211011_Var6vbsl_set0_im151_AppleMesh00_dur400ms_lab_updated.json_0_I1_partition_trial_binsize=24008\"\n",
    "_path = \"../data/face_data/bio_data/avg-monkey-i1\"\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/bio_data/avg-monkey-i1\"\n",
    "with open(_path, 'rb') as f:\n",
    "    marmoset_i1 = pickle.load(f).squeeze().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize \n",
    "def NormalizeData(data, data_max=None, data_min=None): # normalize to [0,1]\n",
    "    if data_max is None and data_min is None:\n",
    "        return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    else:\n",
    "        return (data - data_min) / (data_max - data_min)\n",
    "    \n",
    "is_normalized = True\n",
    "\n",
    "if is_normalized:\n",
    "    human_i1_5rep = NormalizeData(human_i1_5rep, 4, -4)\n",
    "    human_i1 = NormalizeData(human_i1, 4, -4)\n",
    "    marmoset_i1_5rep = NormalizeData(marmoset_i1_5rep, 4, -4)\n",
    "    marmoset_i1 = NormalizeData(marmoset_i1, 4, -4)\n",
    "human_i1_5rep.shape, marmoset_i1_5rep.shape, human_i1.shape, marmoset_i1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_i1_5rep.shape, marmoset_i1_5rep.shape, human_i1.shape, marmoset_i1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get human i1s - GOR (camel vs elephant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read human i1s - camel vs. elephant\n",
    "\n",
    "# Human experiment, using set0, im151 -- elephant, subs=31, 20211011\n",
    "_path = \"../../data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant/human_n_subs=31_20211011_Var6vbsl_set0_im151_camel_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_elephant_dur200ms_lab_updated.json_I1_partition_splithalf_trial_binsize=13738_n_rep=5\"\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/20211011_Var6vbsl_set0_im151_elephant/human_n_subs=31_20211011_Var6vbsl_set0_im151_camel_dur200ms_lab_updated.json_20211011_Var6vbsl_set0_im151_elephant_dur200ms_lab_updated.json_I1_partition_splithalf_trial_binsize=13738_n_rep=5\"\n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1s_obj_vbsl151 = pickle.load(f).squeeze()\n",
    "\n",
    "# Human experiment, using set1, im101 -- elephant, subs=26, 20220412 \n",
    "_path = \"../../data/face_data/control_exp/objs/20220412_Var6vb_same_as_camel_sp_set1_im101_elephant/human_n_subs=26_20220412_Var6vbsp_set1_im101_camel_dur200ms.json_20220412_Var6vb_same_as_camel_sp_set1_im101_elephant_dur200ms.json_I1_partition_splithalf_trial_binsize=10043_n_rep=5\"\n",
    "_path = \"/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/20220412_Var6vb_same_as_camel_sp_set1_im101_elephant/human_n_subs=26_20220412_Var6vbsp_set1_im101_camel_dur200ms.json_20220412_Var6vb_same_as_camel_sp_set1_im101_elephant_dur200ms.json_I1_partition_splithalf_trial_binsize=10043_n_rep=5\"  \n",
    "with open(_path, 'rb') as f:\n",
    "    human_i1s_obj_vbsp101 = pickle.load(f).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_normalized = True\n",
    "if is_normalized:\n",
    "    human_i1s_obj_vbsl151 = NormalizeData(human_i1s_obj_vbsl151)\n",
    "    human_i1s_obj_vbsp101 = NormalizeData(human_i1s_obj_vbsp101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_i1s_obj_vbsl151.shape, human_i1s_obj_vbsp101.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute model i1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) exp_names_list_basics\n",
    "\n",
    "useful_stats = {}\n",
    "\n",
    "data_root_list = [\n",
    "                '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/',\n",
    "                '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/',\n",
    "                '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_AppleMesh03_praneeth/',\n",
    "                '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_basel_ood/',\n",
    "                '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/ood/vbsl151_basel_ood_notexture/',\n",
    "                ]\n",
    "\n",
    "exp_name_list = [\n",
    "                ['20211011_Var6vbsl_set0_im151_AppleMesh00', '20211011_Var6vbsl_set0_im151_AppleMesh01'],\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral'],\n",
    "                ['20230406_Var6vbsl_set0_im151_praneeth_dur200ms_lab', '20230406_Var6vbsl_set0_im151_AppleMesh03_dur200ms_lab'],\n",
    "                ['20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_dur200ms_lab', '20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_dur200ms_lab'],\n",
    "                ['20230406_Var6vbsl_set0_im151_Baselmesh_ood_0_notexture_dur200ms_lab', '20230406_Var6vbsl_set0_im151_Baselmesh_ood_1_notexture_dur200ms_lab'],\n",
    "                ]\n",
    "\n",
    "for dataset_index in [0,1,2,3,4]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "        \n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) exp_names_list_GFR\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/'] * 66\n",
    "exp_name_list = [\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral'],\n",
    "                 ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral'],\n",
    "                 ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral'],\n",
    "                 ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral'],\n",
    "                 ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral'],\n",
    "                 ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral'],\n",
    "                 ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral'],\n",
    "                 ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral'],\n",
    "                 ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral'],\n",
    "                 ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral'],\n",
    "                 ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral'],\n",
    "                 ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral'],\n",
    "                 ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral'],\n",
    "                 ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral'],\n",
    "                 ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral'],\n",
    "                 ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral'],\n",
    "                 ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral'],\n",
    "                 ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral'],\n",
    "                 ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral'],\n",
    "                 ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral'],\n",
    "                 ['vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral', 'vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral'],\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh00/vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh01/vbsle151_AppleMesh01_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh02/vbsle151_AppleMesh02_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh03/vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh04/vbsle151_AppleMesh04_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh05/vbsle151_AppleMesh05_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral', 'vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral'],\n",
    "                ['vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh06/vbsle151_AppleMesh06_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral', 'vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral'],\n",
    "                ['vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh07/vbsle151_AppleMesh07_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral', 'vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral'],\n",
    "                ['vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh08/vbsle151_AppleMesh08_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral', 'vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral'],\n",
    "                ['vbsle151_AppleMesh09/vbsle151_AppleMesh09_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "                ['vbsle151_AppleMesh10/vbsle151_AppleMesh10_neutral', 'vbsle151_AppleMesh11/vbsle151_AppleMesh11_neutral'],\n",
    "]\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) exp_names_list_CTFR\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'] * 66\n",
    "exp_name_list = [\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh01_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh02_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh03_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh02_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh03_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh03_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh08_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh08_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh08_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh09_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh09_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh10_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "]\n",
    "\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) exp_names_list_GTFR\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/'] * 66\n",
    "exp_name_list = [\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh01_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh02_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh03_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh02_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh03_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh03_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh04_neutral'],\n",
    "                 ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh05_neutral'],\n",
    "                 ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                 ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh06_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh01_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh02_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh03_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh04_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh05_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh07_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh06_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh08_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh07_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh08_neutral', 'vbsl151_AppleMesh09_neutral'],\n",
    "                ['vbsl151_AppleMesh08_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh08_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh09_neutral', 'vbsl151_AppleMesh10_neutral'],\n",
    "                ['vbsl151_AppleMesh09_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "                ['vbsl151_AppleMesh10_neutral', 'vbsl151_AppleMesh11_neutral'],\n",
    "]\n",
    "    \n",
    "# specify which dataset to use by index \n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) exp_names_list_GER_AppleMesh03\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh03/'] * 21\n",
    "exp_name_list = [\n",
    "                ['vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh03_happiness_4'],\n",
    "                 ['vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh03_sadness_4'],\n",
    "                 ['vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh03_disgust_4'],\n",
    "                 ['vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh03_fear_4'],\n",
    "                 ['vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh03_anger_4'],\n",
    "                 ['vbsle151_AppleMesh03_neutral', 'vbsle151_AppleMesh03_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh03_happiness_4', 'vbsle151_AppleMesh03_sadness_4'],\n",
    "                 ['vbsle151_AppleMesh03_happiness_4', 'vbsle151_AppleMesh03_disgust_4'],\n",
    "                 ['vbsle151_AppleMesh03_happiness_4', 'vbsle151_AppleMesh03_fear_4'],\n",
    "                 ['vbsle151_AppleMesh03_happiness_4', 'vbsle151_AppleMesh03_anger_4'],\n",
    "                 ['vbsle151_AppleMesh03_happiness_4', 'vbsle151_AppleMesh03_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh03_sadness_4', 'vbsle151_AppleMesh03_disgust_4'],\n",
    "                 ['vbsle151_AppleMesh03_sadness_4', 'vbsle151_AppleMesh03_fear_4'],\n",
    "                 ['vbsle151_AppleMesh03_sadness_4', 'vbsle151_AppleMesh03_anger_4'],\n",
    "                 ['vbsle151_AppleMesh03_sadness_4', 'vbsle151_AppleMesh03_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh03_disgust_4', 'vbsle151_AppleMesh03_fear_4'],\n",
    "                 ['vbsle151_AppleMesh03_disgust_4', 'vbsle151_AppleMesh03_anger_4'],\n",
    "                 ['vbsle151_AppleMesh03_disgust_4', 'vbsle151_AppleMesh03_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh03_fear_4', 'vbsle151_AppleMesh03_anger_4'],\n",
    "                 ['vbsle151_AppleMesh03_fear_4', 'vbsle151_AppleMesh03_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh03_anger_4', 'vbsle151_AppleMesh03_surprise_4']\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]:\n",
    "\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        # cross-validation\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) exp_names_list_GER_AppleMesh00\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_AppleMesh00/'] * 21\n",
    "exp_name_list = [\n",
    "                ['vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh00_happiness_4'],\n",
    "                 ['vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh00_sadness_4'],\n",
    "                 ['vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh00_disgust_4'],\n",
    "                 ['vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh00_fear_4'],\n",
    "                 ['vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh00_anger_4'],\n",
    "                 ['vbsle151_AppleMesh00_neutral', 'vbsle151_AppleMesh00_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh00_happiness_4', 'vbsle151_AppleMesh00_sadness_4'],\n",
    "                 ['vbsle151_AppleMesh00_happiness_4', 'vbsle151_AppleMesh00_disgust_4'],\n",
    "                 ['vbsle151_AppleMesh00_happiness_4', 'vbsle151_AppleMesh00_fear_4'],\n",
    "                 ['vbsle151_AppleMesh00_happiness_4', 'vbsle151_AppleMesh00_anger_4'],\n",
    "                 ['vbsle151_AppleMesh00_happiness_4', 'vbsle151_AppleMesh00_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh00_sadness_4', 'vbsle151_AppleMesh00_disgust_4'],\n",
    "                 ['vbsle151_AppleMesh00_sadness_4', 'vbsle151_AppleMesh00_fear_4'],\n",
    "                 ['vbsle151_AppleMesh00_sadness_4', 'vbsle151_AppleMesh00_anger_4'],\n",
    "                 ['vbsle151_AppleMesh00_sadness_4', 'vbsle151_AppleMesh00_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh00_disgust_4', 'vbsle151_AppleMesh00_fear_4'],\n",
    "                 ['vbsle151_AppleMesh00_disgust_4', 'vbsle151_AppleMesh00_anger_4'],\n",
    "                 ['vbsle151_AppleMesh00_disgust_4', 'vbsle151_AppleMesh00_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh00_fear_4', 'vbsle151_AppleMesh00_anger_4'],\n",
    "                 ['vbsle151_AppleMesh00_fear_4', 'vbsle151_AppleMesh00_surprise_4'],\n",
    "                 ['vbsle151_AppleMesh00_anger_4', 'vbsle151_AppleMesh00_surprise_4']\n",
    "                ]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10, 11, 12, 13,14, 15, 16, 17, 18, 19, 20]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        # cross-validation\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) exp_names_list_CTER_AppleMesh00\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_colorbg/'] * 21\n",
    "exp_name_list = [\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_happiness_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_sadness_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_disgust_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_sadness_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_disgust_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_disgust_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_disgust_4', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_disgust_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_disgust_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_fear_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_fear_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_anger_4', 'vbsl151_AppleMesh00_surprise_4']\n",
    "]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        # cross-validation\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) exp_names_list_GTER_AppleMesh00\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151_texture_graybg/'] * 21\n",
    "exp_name_list = [\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_happiness_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_sadness_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_disgust_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_neutral', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_sadness_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_disgust_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_happiness_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_disgust_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_sadness_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_disgust_4', 'vbsl151_AppleMesh00_fear_4'],\n",
    "                ['vbsl151_AppleMesh00_disgust_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_disgust_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_fear_4', 'vbsl151_AppleMesh00_anger_4'],\n",
    "                ['vbsl151_AppleMesh00_fear_4', 'vbsl151_AppleMesh00_surprise_4'],\n",
    "                ['vbsl151_AppleMesh00_anger_4', 'vbsl151_AppleMesh00_surprise_4']\n",
    "]\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in [0, 1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17, 18, 19,20]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        # cross-validation\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) exp_names_list_basel_GFR\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/'] * 66\n",
    "exp_name_list = [\n",
    "                ['id10', 'id11'],\n",
    "                 ['id10', 'id12'],\n",
    "                 ['id10', 'id13'],\n",
    "                 ['id10', 'id14'],\n",
    "                 ['id10', 'id15'],\n",
    "                 ['id10', 'id16'],\n",
    "                 ['id11', 'id12'],\n",
    "                 ['id11', 'id13'],\n",
    "                 ['id11', 'id14'],\n",
    "                 ['id11', 'id15'],\n",
    "                 ['id11', 'id16'],\n",
    "                 ['id12', 'id13'],\n",
    "                 ['id12', 'id14'],\n",
    "                 ['id12', 'id15'],\n",
    "                 ['id12', 'id16'],\n",
    "                 ['id13', 'id14'],\n",
    "                 ['id13', 'id15'],\n",
    "                 ['id13', 'id16'],\n",
    "                 ['id14', 'id15'],\n",
    "                 ['id14', 'id16'],\n",
    "                 ['id15', 'id16'],\n",
    "                ['id10', 'id17'],\n",
    "                ['id10', 'id18'],\n",
    "                ['id10', 'id19'],\n",
    "                ['id10', 'id20'],\n",
    "                ['id10', 'id21'],\n",
    "                ['id11', 'id17'],\n",
    "                ['id11', 'id18'],\n",
    "                ['id11', 'id19'],\n",
    "                ['id11', 'id20'],\n",
    "                ['id11', 'id21'],\n",
    "                ['id12', 'id17'],\n",
    "                ['id12', 'id18'],\n",
    "                ['id12', 'id19'],\n",
    "                ['id12', 'id20'],\n",
    "                ['id12', 'id21'],\n",
    "                ['id13', 'id17'],\n",
    "                ['id13', 'id18'],\n",
    "                ['id13', 'id19'],\n",
    "                ['id13', 'id20'],\n",
    "                ['id13', 'id21'],\n",
    "                ['id14', 'id17'],\n",
    "                ['id14', 'id18'],\n",
    "                ['id14', 'id19'],\n",
    "                ['id14', 'id20'],\n",
    "                ['id14', 'id21'],\n",
    "                ['id15', 'id17'],\n",
    "                ['id15', 'id18'],\n",
    "                ['id15', 'id19'],\n",
    "                ['id15', 'id20'],\n",
    "                ['id15', 'id21'],\n",
    "                ['id16', 'id17'],\n",
    "                ['id16', 'id18'],\n",
    "                ['id16', 'id19'],\n",
    "                ['id16', 'id20'],\n",
    "                ['id16', 'id21'],\n",
    "                ['id17', 'id18'],\n",
    "                ['id17', 'id19'],\n",
    "                ['id17', 'id20'],\n",
    "                ['id17', 'id21'],\n",
    "                ['id18', 'id19'],\n",
    "                ['id18', 'id20'],\n",
    "                ['id18', 'id21'],\n",
    "                ['id19', 'id20'],\n",
    "                ['id19', 'id21'],\n",
    "                ['id20', 'id21'],\n",
    "] \n",
    "   \n",
    "model_acc_across_tasks = {model_name: [] for model_name in model_names_list}\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        model_acc_across_tasks[model_name].append(np.array(all_scores).mean())\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "# Print model accuracies across tasks \n",
    "for model_name, acc_list in model_acc_across_tasks.items():\n",
    "    print(model_name)\n",
    "    print('\\t'.join(f\"{acc}\" for acc in acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) exp_names_list_basel_CTFR\n",
    "\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/'] * 66\n",
    "exp_name_list = [\n",
    "                 ['id10', 'id11'],\n",
    "                 ['id10', 'id12'],\n",
    "                 ['id10', 'id13'],\n",
    "                 ['id10', 'id14'],\n",
    "                 ['id10', 'id15'],\n",
    "                 ['id10', 'id16'],\n",
    "                 ['id11', 'id12'],\n",
    "                 ['id11', 'id13'],\n",
    "                 ['id11', 'id14'],\n",
    "                 ['id11', 'id15'],\n",
    "                 ['id11', 'id16'],\n",
    "                 ['id12', 'id13'],\n",
    "                 ['id12', 'id14'],\n",
    "                 ['id12', 'id15'],\n",
    "                 ['id12', 'id16'],\n",
    "                 ['id13', 'id14'],\n",
    "                 ['id13', 'id15'],\n",
    "                 ['id13', 'id16'],\n",
    "                 ['id14', 'id15'],\n",
    "                 ['id14', 'id16'],\n",
    "                 ['id15', 'id16'],\n",
    "                ['id10', 'id17'],\n",
    "                ['id10', 'id18'],\n",
    "                ['id10', 'id19'],\n",
    "                ['id10', 'id20'],\n",
    "                ['id10', 'id21'],\n",
    "                ['id11', 'id17'],\n",
    "                ['id11', 'id18'],\n",
    "                ['id11', 'id19'],\n",
    "                ['id11', 'id20'],\n",
    "                ['id11', 'id21'],\n",
    "                ['id12', 'id17'],\n",
    "                ['id12', 'id18'],\n",
    "                ['id12', 'id19'],\n",
    "                ['id12', 'id20'],\n",
    "                ['id12', 'id21'],\n",
    "                ['id13', 'id17'],\n",
    "                ['id13', 'id18'],\n",
    "                ['id13', 'id19'],\n",
    "                ['id13', 'id20'],\n",
    "                ['id13', 'id21'],\n",
    "                ['id14', 'id17'],\n",
    "                ['id14', 'id18'],\n",
    "                ['id14', 'id19'],\n",
    "                ['id14', 'id20'],\n",
    "                ['id14', 'id21'],\n",
    "                ['id15', 'id17'],\n",
    "                ['id15', 'id18'],\n",
    "                ['id15', 'id19'],\n",
    "                ['id15', 'id20'],\n",
    "                ['id15', 'id21'],\n",
    "                ['id16', 'id17'],\n",
    "                ['id16', 'id18'],\n",
    "                ['id16', 'id19'],\n",
    "                ['id16', 'id20'],\n",
    "                ['id16', 'id21'],\n",
    "                ['id17', 'id18'],\n",
    "                ['id17', 'id19'],\n",
    "                ['id17', 'id20'],\n",
    "                ['id17', 'id21'],\n",
    "                ['id18', 'id19'],\n",
    "                ['id18', 'id20'],\n",
    "                ['id18', 'id21'],\n",
    "                ['id19', 'id20'],\n",
    "                ['id19', 'id21'],\n",
    "                ['id20', 'id21'],\n",
    "] \n",
    "   \n",
    "    \n",
    "model_acc_across_tasks = {model_name: [] for model_name in model_names_list}\n",
    "\n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        model_acc_across_tasks[model_name].append(np.array(all_scores).mean())\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "# Print model accuracies across tasks \n",
    "for model_name, acc_list in model_acc_across_tasks.items():\n",
    "    print(model_name)\n",
    "    print('\\t'.join(f\"{acc}\" for acc in acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) exp_names_list_basel_GFR_ver2 (id988-999)\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_no_texture/Basel_no_texture_test_1000ID/'] * 66\n",
    "exp_name_list = [\n",
    "                ['id988', 'id989'],\n",
    "                 ['id988', 'id990'],\n",
    "                 ['id988', 'id991'],\n",
    "                 ['id988', 'id992'],\n",
    "                 ['id988', 'id993'],\n",
    "                 ['id988', 'id994'],\n",
    "                 ['id989', 'id990'],\n",
    "                 ['id989', 'id991'],\n",
    "                 ['id989', 'id992'],\n",
    "                 ['id989', 'id993'],\n",
    "                 ['id989', 'id994'],\n",
    "                 ['id990', 'id991'],\n",
    "                 ['id990', 'id992'],\n",
    "                 ['id990', 'id993'],\n",
    "                 ['id990', 'id994'],\n",
    "                 ['id991', 'id992'],\n",
    "                 ['id991', 'id993'],\n",
    "                 ['id991', 'id994'],\n",
    "                 ['id992', 'id993'],\n",
    "                 ['id992', 'id994'],\n",
    "                 ['id993', 'id994'],\n",
    "                ['id988', 'id995'],\n",
    "                ['id988', 'id996'],\n",
    "                ['id988', 'id997'],\n",
    "                ['id988', 'id998'],\n",
    "                ['id988', 'id999'],\n",
    "                ['id989', 'id995'],\n",
    "                ['id989', 'id996'],\n",
    "                ['id989', 'id997'],\n",
    "                ['id989', 'id998'],\n",
    "                ['id989', 'id999'],\n",
    "                ['id990', 'id995'],\n",
    "                ['id990', 'id996'],\n",
    "                ['id990', 'id997'],\n",
    "                ['id990', 'id998'],\n",
    "                ['id990', 'id999'],\n",
    "                ['id991', 'id995'],\n",
    "                ['id991', 'id996'],\n",
    "                ['id991', 'id997'],\n",
    "                ['id991', 'id998'],\n",
    "                ['id991', 'id999'],\n",
    "                ['id992', 'id995'],\n",
    "                ['id992', 'id996'],\n",
    "                ['id992', 'id997'],\n",
    "                ['id992', 'id998'],\n",
    "                ['id992', 'id999'],\n",
    "                ['id993', 'id995'],\n",
    "                ['id993', 'id996'],\n",
    "                ['id993', 'id997'],\n",
    "                ['id993', 'id998'],\n",
    "                ['id993', 'id999'],\n",
    "                ['id994', 'id995'],\n",
    "                ['id994', 'id996'],\n",
    "                ['id994', 'id997'],\n",
    "                ['id994', 'id998'],\n",
    "                ['id994', 'id999'],\n",
    "                ['id995', 'id996'],\n",
    "                ['id995', 'id997'],\n",
    "                ['id995', 'id998'],\n",
    "                ['id995', 'id999'],\n",
    "                ['id996', 'id997'],\n",
    "                ['id996', 'id998'],\n",
    "                ['id996', 'id999'],\n",
    "                ['id997', 'id998'],\n",
    "                ['id997', 'id999'],\n",
    "                ['id998', 'id999'],\n",
    "] \n",
    "   \n",
    "model_acc_across_tasks = {model_name: [] for model_name in model_names_list}\n",
    "\n",
    "# specify which dataset to use by index \n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        model_acc_across_tasks[model_name].append(np.array(all_scores).mean())\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "# Print model accuracies across tasks \n",
    "for model_name, acc_list in model_acc_across_tasks.items():\n",
    "    print(model_name)\n",
    "    print('\\t'.join(f\"{acc}\" for acc in acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (12) exp_names_list_basel_CTFR_ver2 (id988-999)\n",
    "useful_stats = {}\n",
    "data_root_list = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/Basel_colored_texture/Basel_colored_texture_test_1000ID/'] * 66\n",
    "exp_name_list = [\n",
    "                ['id988', 'id989'],\n",
    "                 ['id988', 'id990'],\n",
    "                 ['id988', 'id991'],\n",
    "                 ['id988', 'id992'],\n",
    "                 ['id988', 'id993'],\n",
    "                 ['id988', 'id994'],\n",
    "                 ['id989', 'id990'],\n",
    "                 ['id989', 'id991'],\n",
    "                 ['id989', 'id992'],\n",
    "                 ['id989', 'id993'],\n",
    "                 ['id989', 'id994'],\n",
    "                 ['id990', 'id991'],\n",
    "                 ['id990', 'id992'],\n",
    "                 ['id990', 'id993'],\n",
    "                 ['id990', 'id994'],\n",
    "                 ['id991', 'id992'],\n",
    "                 ['id991', 'id993'],\n",
    "                 ['id991', 'id994'],\n",
    "                 ['id992', 'id993'],\n",
    "                 ['id992', 'id994'],\n",
    "                 ['id993', 'id994'],\n",
    "                ['id988', 'id995'],\n",
    "                ['id988', 'id996'],\n",
    "                ['id988', 'id997'],\n",
    "                ['id988', 'id998'],\n",
    "                ['id988', 'id999'],\n",
    "                ['id989', 'id995'],\n",
    "                ['id989', 'id996'],\n",
    "                ['id989', 'id997'],\n",
    "                ['id989', 'id998'],\n",
    "                ['id989', 'id999'],\n",
    "                ['id990', 'id995'],\n",
    "                ['id990', 'id996'],\n",
    "                ['id990', 'id997'],\n",
    "                ['id990', 'id998'],\n",
    "                ['id990', 'id999'],\n",
    "                ['id991', 'id995'],\n",
    "                ['id991', 'id996'],\n",
    "                ['id991', 'id997'],\n",
    "                ['id991', 'id998'],\n",
    "                ['id991', 'id999'],\n",
    "                ['id992', 'id995'],\n",
    "                ['id992', 'id996'],\n",
    "                ['id992', 'id997'],\n",
    "                ['id992', 'id998'],\n",
    "                ['id992', 'id999'],\n",
    "                ['id993', 'id995'],\n",
    "                ['id993', 'id996'],\n",
    "                ['id993', 'id997'],\n",
    "                ['id993', 'id998'],\n",
    "                ['id993', 'id999'],\n",
    "                ['id994', 'id995'],\n",
    "                ['id994', 'id996'],\n",
    "                ['id994', 'id997'],\n",
    "                ['id994', 'id998'],\n",
    "                ['id994', 'id999'],\n",
    "                ['id995', 'id996'],\n",
    "                ['id995', 'id997'],\n",
    "                ['id995', 'id998'],\n",
    "                ['id995', 'id999'],\n",
    "                ['id996', 'id997'],\n",
    "                ['id996', 'id998'],\n",
    "                ['id996', 'id999'],\n",
    "                ['id997', 'id998'],\n",
    "                ['id997', 'id999'],\n",
    "                ['id998', 'id999'],\n",
    "] \n",
    "   \n",
    "    \n",
    "model_acc_across_tasks = {model_name: [] for model_name in model_names_list}\n",
    "\n",
    "for dataset_index in range(66):\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "\n",
    "        # cross-validation\n",
    "        # [num_class, num_rep, num_img_per_class]\n",
    "        # [2, 1000, 151]\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                # train_index and test_index does not overlap... and \n",
    "                # print(train_index)\n",
    "                # print(test_index)\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                # print(len(y_test))\n",
    "                # print(len(test_index))\n",
    "                # pred_by_bg = extract_pred_by_bg(y_predict, test_index, unique_bg, imageidx_AppleMesh00, imageidx_AppleMesh01)\n",
    "                # # print(pred_by_bg)\n",
    "                # mat_pred_by_bg = mat_pred_by_bg + list(pred_by_bg.values())\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "        model_acc_across_tasks[model_name].append(np.array(all_scores).mean())\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists\n",
    "\n",
    "# Print model accuracies across tasks \n",
    "for model_name, acc_list in model_acc_across_tasks.items():\n",
    "    print(model_name)\n",
    "    print('\\t'.join(f\"{acc}\" for acc in acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (13) exp_names_list_lfw\n",
    "useful_stats = {}\n",
    "data_root_list = [    \n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/LFW_Bush_Powell_inverted/',\n",
    "]\n",
    "\n",
    "exp_name_list = [['Bush', 'Powell'],\n",
    "['Bush', 'Powell']]\n",
    "\n",
    "for dataset_index in [0,1]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (14) exp_names_list_ytface\n",
    "useful_stats = {}\n",
    "\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/',\n",
    "\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/YoutubeFaces/'\n",
    "]\n",
    "\n",
    "exp_name_list = [['Stanca', 'Beard'],\n",
    "['Kennedy', 'Macdonald']]\n",
    "\n",
    "for dataset_index in [0,1]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (15) exp_names_list_GOR\n",
    "useful_stats = {}\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle_151/vbsle151_dog_horse/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_gray_downsampled/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/object_data/GOR_colored_downsampled/'\n",
    "]\n",
    "exp_name_list = [\n",
    "                ['20211011_Var6vbsl_set0_im151_camel', '20211011_Var6vbsl_set0_im151_elephant'],\n",
    "                ['vbsle_151_dog', 'vbsle_151_horse'],\n",
    "                ['camel_colored_gray', 'elephant_colored_gray'],\n",
    "                ['camel_colored', 'elephant_colored']\n",
    "                 ]\n",
    "\n",
    "for dataset_index in [0,1,2,3]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        # cross-validation\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (16) exp_names_list_imagenet\n",
    "useful_stats = {}\n",
    "data_root_list = [\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/shark151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/bird151/',\n",
    "    '/mnt/smb/locker/issa-locker/users/Seojin/data/vehicle151'\n",
    "]\n",
    "exp_name_list = [\n",
    "                 ['shark1', 'shark2'],\n",
    "                 ['bird1', 'bird2'],\n",
    "                 ['bike', 'car']\n",
    "                 ]\n",
    "\n",
    "for dataset_index in [0,1,2]:\n",
    "    data_root = data_root_list[dataset_index]\n",
    "    exp_name_0 = exp_name_list[dataset_index][0]\n",
    "    exp_name_1 = exp_name_list[dataset_index][1]\n",
    "\n",
    "    filename_postfix = ''\n",
    "    num_rep = 100\n",
    "    \n",
    "    dict_scores = {}\n",
    "    dict_i1_dists = {}\n",
    "    dict_conf_mat = {}\n",
    "    acc_per_img = {}\n",
    "\n",
    "    for model_name in model_names_list:\n",
    "        mat_pred_by_bg = np.zeros((10,2)) # SL \n",
    "\n",
    "        # read feats\n",
    "        _path = os.path.join(data_root, exp_name_0+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_1 from {_path}\")\n",
    "        input_1 = torch.load(_path)\n",
    "        _path = os.path.join(data_root, exp_name_1+'_'+model_name+filename_postfix+'.pth')\n",
    "        print(f\"loading input_2 from {_path}\")\n",
    "        input_2 = torch.load(_path)\n",
    "        input_1 = input_1.reshape(len(input_1), -1)\n",
    "        input_2 = input_2.reshape(len(input_2), -1)\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # rebalance: shuffle and remove                                         \n",
    "        torch.manual_seed(7)\n",
    "        if len(input_1) != len(input_2):\n",
    "            if len(input_2)>len(input_1):                                                \n",
    "                input_3 = input_1\n",
    "                input_1 = input_2\n",
    "                input_2 = input_3\n",
    "                del input_3\n",
    "            idx = torch.randperm(input_1.shape[0])\n",
    "            input_1 = input_1[idx]\n",
    "            input_1 = input_1[:len(input_2)]\n",
    "\n",
    "        print(input_1.shape, input_2.shape)\n",
    "        # prepare data\n",
    "        output_1 = np.ones(len(input_1))\n",
    "        output_2 = np.zeros(len(input_2))\n",
    "\n",
    "        inputs = np.concatenate((input_1, input_2), axis=0)\n",
    "        outputs = np.concatenate((output_1, output_2), axis=0)\n",
    "\n",
    "        # cross-validation\n",
    "        dists = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "        all_scores = []\n",
    "        acc = np.nan * np.ones((2, num_rep, len(output_1))) \n",
    "\n",
    "        # iter num_rep\n",
    "        conf_mat = np.zeros((2,2))\n",
    "        for rep_index in tqdm(range(num_rep)):\n",
    "            cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "            scores = []\n",
    "\n",
    "            # iter through splits of cv\n",
    "            for split_index, (train_index, test_index) in enumerate(cv.split(input_1, output_1)):\n",
    "                # split data\n",
    "                X_train = np.concatenate((input_1[train_index], input_2[train_index]), axis=0)\n",
    "                X_test = np.concatenate((input_1[test_index], input_2[test_index]), axis=0)\n",
    "                y_train = np.concatenate((output_1[train_index], output_2[train_index]), axis=0)\n",
    "                y_test = np.concatenate((output_1[test_index], output_2[test_index]), axis=0)\n",
    "                # fit model\n",
    "                clf = svm.LinearSVC(penalty='l2', loss='hinge', dual=True,\n",
    "                                     tol=1e-4,\n",
    "                                     fit_intercept=True,\n",
    "                                     C=1.0,\n",
    "                                    max_iter = 20000)\n",
    "                clf.fit(X_train, y_train)\n",
    "                # record score\n",
    "                y_predict = clf.predict(X_test)\n",
    "                _score = (y_predict == y_test).sum() / len(y_predict)\n",
    "                _conf_mat = confusion_matrix(y_test, y_predict)\n",
    "                conf_mat += _conf_mat\n",
    "                scores.append(_score)\n",
    "                _acc_per_img = (y_predict == y_test).astype('float32')\n",
    "                acc[0][rep_index][test_index] = _acc_per_img[:len(test_index)]\n",
    "                acc[1][rep_index][test_index] = _acc_per_img[len(test_index):]\n",
    "                # record dist (how far a given sample is from the decision boundary of the classifier)\n",
    "                _class1_dist = clf.decision_function(input_1[test_index])\n",
    "                dists[0][rep_index][test_index] = _class1_dist\n",
    "                _class2_dist = clf.decision_function(input_2[test_index])\n",
    "                dists[1][rep_index][test_index] = _class2_dist * (-1) # negate the dist for second class\n",
    "            all_scores.append(np.array(scores).mean())\n",
    "\n",
    "        dists = dists/num_rep\n",
    "        print(model_name, '%.6f+-%.6f'%(np.array(all_scores).mean(), np.array(all_scores).std()))\n",
    "\n",
    "        dict_scores[model_name] = all_scores\n",
    "        dict_i1_dists[model_name] = dists\n",
    "        conf_mat = conf_mat / num_rep / 2\n",
    "        dict_conf_mat[model_name] = conf_mat\n",
    "        acc_per_img[model_name] = acc\n",
    "\n",
    "        # record useful stats\n",
    "        if data_root not in useful_stats:\n",
    "            useful_stats[data_root] = {}\n",
    "        if model_name not in useful_stats[data_root]:\n",
    "            useful_stats[data_root][model_name] = {}\n",
    "        useful_stats[data_root][model_name]['acc'] = [np.array(all_scores).mean(), np.array(all_scores).std()]\n",
    "        useful_stats[data_root][model_name]['acc_per_img'] = acc.mean(1)\n",
    "        useful_stats[data_root][model_name]['dist'] = dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print in-distribution and out-of-distribution acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ood_iid_acc(pairs, acc_values, ood_set):\n",
    "    \"\"\"\n",
    "    - pairs: list of 66 name pairs (e.g., [\"AppleMesh00_AppleMesh01\", \"AppleMesh00_AppleMesh02E\", ...])\n",
    "    - acc_values: list of 66 accuracy values\n",
    "    - ood_set: set of OOD IDs (e.g., {\"AppleMesh00\", \"AppleMesh01\"} for 2-ID OOD).\n",
    "    \n",
    "    Returns:\n",
    "    - overall_acc: all mean\n",
    "    - overall_std: all std\n",
    "    - ood_acc: OOD mean (for pairs not containing \"OOD IDs\").\n",
    "    - ood_std: OOD std\n",
    "    - iid_acc: IID mean\n",
    "    - iid_std: IID std\n",
    "    \"\"\"\n",
    "    ood_indices = []  # Pairs that DO NOT contain any OOD IDs\n",
    "    iid_indices = []  # Pairs that CONTAIN at least one OOD ID\n",
    "\n",
    "    for i, pair in enumerate(pairs):\n",
    "        name1, name2 = pair.split(\"_\")\n",
    "        # If neither name1 nor name2 is in OOD set, classify as OOD\n",
    "        if name1 not in ood_set and name2 not in ood_set:\n",
    "            ood_indices.append(i)\n",
    "        else:\n",
    "            iid_indices.append(i)\n",
    "\n",
    "    # Compute mean accuracies\n",
    "    overall_acc = np.mean(acc_values)\n",
    "    overall_std = np.std(acc_values)\n",
    "\n",
    "    ood_acc = np.mean([acc_values[i] for i in ood_indices]) if ood_indices else None\n",
    "    ood_std = np.std([acc_values[i] for i in ood_indices]) if ood_indices else None\n",
    "\n",
    "    iid_acc = np.mean([acc_values[i] for i in iid_indices]) if iid_indices else None\n",
    "    iid_std = np.std([acc_values[i] for i in iid_indices]) if iid_indices else None\n",
    "    print([acc_values[i] for i in ood_indices])\n",
    "    return overall_acc, overall_std, ood_acc, ood_std, iid_acc, iid_std, len(ood_indices), len(iid_indices)\n",
    "\n",
    "# Example usage\n",
    "pairs = [\n",
    "    \"AppleMesh00_AppleMesh01\", \"AppleMesh00_AppleMesh02\", \"AppleMesh00_AppleMesh03\", \"AppleMesh00_AppleMesh04\", \"AppleMesh00_AppleMesh05\", \"AppleMesh00_AppleMesh06\",\n",
    "    \"AppleMesh01_AppleMesh02\", \"AppleMesh01_AppleMesh03\", \"AppleMesh01_AppleMesh04\", \"AppleMesh01_AppleMesh05\", \"AppleMesh01_AppleMesh06\",\n",
    "    \"AppleMesh02_AppleMesh03\", \"AppleMesh02_AppleMesh04\", \"AppleMesh02_AppleMesh05\", \"AppleMesh02_AppleMesh06\", \"AppleMesh03_AppleMesh04\",\n",
    "    \"AppleMesh03_AppleMesh05\", \"AppleMesh03_AppleMesh06\", \"AppleMesh04_AppleMesh05\", \"AppleMesh04_AppleMesh06\", \"AppleMesh05_AppleMesh06\",\n",
    "    \"AppleMesh00_AppleMesh07\", \"AppleMesh00_AppleMesh08\", \"AppleMesh00_AppleMesh09\", \"AppleMesh00_AppleMesh10\", \"AppleMesh00_AppleMesh11\",\n",
    "    \"AppleMesh01_AppleMesh07\", \"AppleMesh01_AppleMesh08\", \"AppleMesh01_AppleMesh09\", \"AppleMesh01_AppleMesh10\", \"AppleMesh01_AppleMesh11\",\n",
    "    \"AppleMesh02_AppleMesh07\", \"AppleMesh02_AppleMesh08\", \"AppleMesh02_AppleMesh09\", \"AppleMesh02_AppleMesh10\", \"AppleMesh02_AppleMesh11\",\n",
    "    \"AppleMesh03_AppleMesh07\", \"AppleMesh03_AppleMesh08\", \"AppleMesh03_AppleMesh09\", \"AppleMesh03_AppleMesh10\", \"AppleMesh03_AppleMesh11\",\n",
    "    \"AppleMesh04_AppleMesh07\", \"AppleMesh04_AppleMesh08\", \"AppleMesh04_AppleMesh09\", \"AppleMesh04_AppleMesh10\", \"AppleMesh04_AppleMesh11\",\n",
    "    \"AppleMesh05_AppleMesh07\", \"AppleMesh05_AppleMesh08\", \"AppleMesh05_AppleMesh09\", \"AppleMesh05_AppleMesh10\", \"AppleMesh05_AppleMesh11\",\n",
    "    \"AppleMesh06_AppleMesh07\", \"AppleMesh06_AppleMesh08\", \"AppleMesh06_AppleMesh09\", \"AppleMesh06_AppleMesh10\", \"AppleMesh06_AppleMesh11\",\n",
    "    \"AppleMesh07_AppleMesh08\", \"AppleMesh07_AppleMesh09\", \"AppleMesh07_AppleMesh10\", \"AppleMesh07_AppleMesh11\",\n",
    "    \"AppleMesh08_AppleMesh09\", \"AppleMesh08_AppleMesh10\", \"AppleMesh08_AppleMesh11\", \"AppleMesh09_AppleMesh10\", \"AppleMesh09_AppleMesh11\", \"AppleMesh10_AppleMesh11\"\n",
    "]\n",
    "\n",
    "acc_values = [\n",
    "0.893467,\t0.936926,\t0.957427,\t0.882339,\t0.925035,\t0.981286,\t0.905658,\t0.922682,\t0.902667,\t0.926330,\t0.987154,\t0.824061,\t0.930411,\t0.936452,\t0.976455,\t0.947849,\t0.935982,\t0.982017,\t0.874466,\t0.982350,\t0.949014,\t0.980628,\t0.854192,\t0.940664,\t0.926195,\t0.963151,\t0.932549,\t0.975100,\t0.921263,\t0.911155,\t0.953658,\t0.934628,\t0.988645,\t0.812758,\t0.916327,\t0.950502,\t0.946234,\t0.981722,\t0.846096,\t0.921899,\t0.947048,\t0.942186,\t0.977653,\t0.910598,\t0.849870,\t0.952589,\t0.932289,\t0.962734,\t0.907123,\t0.881646,\t0.903197,\t0.956275,\t0.880066,\t0.968479,\t0.978896,\t0.979047,\t0.951364,\t0.932040,\t0.940130,\t0.964267,\t0.980344,\t0.980041,\t0.972848,\t0.884662,\t0.933679,\t0.938574,\n",
    "]\n",
    "\n",
    "ood_set = {\"AppleMesh02\",\"AppleMesh03\", \"AppleMesh04\", \"AppleMesh08\", \"AppleMesh11\", \"AppleMesh06\", \"AppleMesh05\", \"AppleMesh10\"}\n",
    "\n",
    "# Compute and print results\n",
    "overall_acc, overall_std, ood_acc, ood_std, iid_acc, iid_std, ood_len, iid_len = compute_ood_iid_acc(pairs, acc_values, ood_set)\n",
    "print((iid_len), (ood_len))\n",
    "print(f\"Overall Acc: {overall_acc:.8f}, Overall Std: {overall_std:.8f}\")\n",
    "print(f\"IID Acc: {iid_acc:.8f}, IID Std: {iid_std:.8f}\")\n",
    "print(f\"OOD Acc: {ood_acc:.8f}, OOD Std: {ood_std:.8f}\")\n",
    "print(f\"{overall_acc:.8f}\t{overall_std:.8f}\t{iid_acc:.8f}\t{iid_std:.8f}\t{ood_acc:.8f}\t{ood_std:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute i1 and i1_5rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_stats = {}\n",
    "import pickle\n",
    "with open('useful_stats_penn.pkl', 'rb') as f:\n",
    "    useful_stats = pickle.load(f)\n",
    "    \n",
    "# hierachy: [task_dir][model_name][acc/acc_per_img/dist/i1]\n",
    "# acc [list]: acc over all datapoints and trails -> [acc_mean, acc_std]\n",
    "# acc_per_img [array]: acc per image averaged over all trails -> shape [2, num_img_per_class]\n",
    "# dist [array]: all svm distance (note that the second class dist is negated) -> shape [2, num_repetition, num_img_per_class]\n",
    "# i1_5rep [array]: random split-half i1 with 5 repetition -> shape [5, 2*num_img_per_class]\n",
    "# i1 [array]: model i1 (the same as dist averaging over trails) -> shape [2, num_img_per_class]\n",
    "# i1_corr [list]: model i1 correlation with bio systems. For vbsl101, the order is [Bourgeois, Sausage, AJ]. \n",
    "# For vbsl151, the order is [Human, AJ]. For each corr, I record [i1_corr_mean, i1_corr_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute model i1 and i1_5rep\n",
    "num_rep = 100\n",
    "for data_root in useful_stats.keys():\n",
    "    for model_name in useful_stats[data_root].keys():\n",
    "        # pull SVM distances, shape (2, 100, N)\n",
    "        i1_dists = useful_stats[data_root][model_name]['dist']\n",
    "        print(i1_dists.size)\n",
    "        avg_i1s = i1_dists.mean(1) # shape (2, N)\n",
    "        i1_dists = np.concatenate((i1_dists[0], i1_dists[1]), axis=1)\n",
    "        model_i1s = []\n",
    "        # for each of 5 repeats, shuffle the 100 rows, average first and last 50 rows and concatenate\n",
    "        for rep_index in range(5):\n",
    "            np.random.shuffle(i1_dists)\n",
    "            tmp = np.concatenate([i1_dists[:int(num_rep/2)].mean(0), \n",
    "                                  i1_dists[int(num_rep/2):].mean(0)])\n",
    "            model_i1s.append(np.expand_dims(tmp, axis=0))\n",
    "        model_i1s = np.concatenate(model_i1s, axis=0)\n",
    "        \n",
    "        useful_stats[data_root][model_name]['i1_5rep'] = model_i1s\n",
    "        useful_stats[data_root][model_name]['i1'] = avg_i1s\n",
    "\n",
    "        # normalize\n",
    "        useful_stats[data_root][model_name]['i1_5rep'] = NormalizeData(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1'] = NormalizeData(avg_i1s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print overall and subset accuracies\n",
    "\n",
    "subset_list = [[0,2], [1,3], [4,5]]\n",
    "subset_name_list = ['normal_face', 'inverted_face', 'reverse_contrast']\n",
    "is_print_subset = True\n",
    "\n",
    "for data_root in useful_stats.keys():\n",
    "    print(data_root)\n",
    "    if data_root != '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_101/':\n",
    "\n",
    "        for model_name in useful_stats[data_root].keys():\n",
    "            # print acc\n",
    "            acc = useful_stats[data_root][model_name]['acc']\n",
    "            print(f\"{model_name}: %.4f%.4f\" % (acc[0]*100, acc[1]*100))\n",
    "            # print subset acc\n",
    "            tmp = useful_stats[data_root][model_name]['acc_per_img'].mean(0)\n",
    "            if is_print_subset:\n",
    "                tmp_group = tmp[:150].reshape(6,25).mean(axis=1)\n",
    "                for subset_id, subset in enumerate(subset_list):\n",
    "                    # get acc\n",
    "                    print(\"%s acc: %.4f\" % (subset_name_list[subset_id], tmp_group[subset].mean()*100))\n",
    "                    useful_stats[data_root][model_name][f'{subset_name_list[subset_id]}'] = tmp_group[subset].mean()\n",
    "                print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare model and bio i1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_upright_5rep_604(array): # (5, 604) to (5, 200)\n",
    "    return np.concatenate([array[:, 0:25], array[:, 50:75], \n",
    "                            array[:, 151:151+25], array[:, 151+50:151+75], \n",
    "                            array[:, 302:302+25], array[:, 302+50:302+75], \n",
    "                            array[:, 302+151:302+151+25], array[:, 302+151+50:302+151+75], ], axis=1) \n",
    "\n",
    "# -------------- SL -----------------\n",
    "def subset_inverted_5rep_604(array): # (5, 604) to (5, 200)\n",
    "    return np.concatenate([array[:, 25:50], array[:, 75:100], \n",
    "                            array[:, 151+25:151+50], array[:, 151+75:151+100], \n",
    "                            array[:, 302+25:302+50], array[:, 302+75:302+100], \n",
    "                            array[:, 302+151+25:302+151+50], array[:, 302+151+75:302+151+100], ], axis=1) \n",
    "\n",
    "# -------------- SL -----------------\n",
    "def subset_reverse_contrast_5rep_604(array): # (5, 604) to (5, 200)\n",
    "    return np.concatenate([array[:, 100:150],  \n",
    "                            array[:, 151+100:151+150],  \n",
    "                            array[:, 302+100:302+150], \n",
    "                            array[:, 302+151+100:302+151+150], ], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute noise-corrected i1 corr between model and bio i1s\n",
    "\n",
    "upright_only = False  # set true to compute for only upright images of vbsli*\n",
    "\n",
    "# select task \n",
    "bio_i1s_list = [human_i1_5rep, marmoset_i1_5rep] # GFR\n",
    "# bio_i1s_list = [human_i1_5rep]\n",
    "# bio_i1s_list = [human_i1s_vbsl]\n",
    "# bio_i1s_list = [human_i1s_obj_vbsl151] # GOR\n",
    "\n",
    "# select data root\n",
    "data_root = '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/' # GFR\n",
    "# data_root = '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/' # GOR\n",
    "\n",
    "\n",
    "for model_name in model_names_list:\n",
    "    # get model i1s\n",
    "    model_i1s = useful_stats[data_root][model_name]['i1_5rep']\n",
    "    if upright_only:\n",
    "        model_i1s = subset_upright_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_upright'] = np.zeros((len(bio_i1s_list), 2))\n",
    "    else:\n",
    "        useful_stats[data_root][model_name]['i1_corr'] = np.zeros((len(bio_i1s_list), 2))\n",
    "    for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "        # get bio i1s\n",
    "        bio_i1s = bio_i1s.squeeze()\n",
    "        #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "        bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "        if upright_only:\n",
    "            bio_i1s = subset_upright_5rep_604(bio_i1s)\n",
    "        i1_corr = []\n",
    "        half_length = int(model_i1s.shape[1]/2)\n",
    "        bio_internal = []\n",
    "        for rep_index in range(5):\n",
    "            corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "            corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "            corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "            corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "            print(corr_1, corr_2, corr_3, corr_4, 0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "            i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "            bio_internal.append(corr_4)\n",
    "        if upright_only:\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "        else:\n",
    "            useful_stats[data_root][model_name]['i1_corr'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "\n",
    "    # ------------------------------- SL -------------------------------\n",
    "    model_i1s_concat = np.concatenate((useful_stats[data_root][model_name]['i1'][0], useful_stats[data_root][model_name]['i1'][1]))\n",
    "    useful_stats[data_root][model_name]['i1_corr_diff_per_img'] = [np.zeros(len(model_i1s_concat)), np.zeros(len(model_i1s_concat))]\n",
    "    for img_index, model_i1_per_img in enumerate(model_i1s_concat) :\n",
    "            useful_stats[data_root][model_name]['i1_corr_diff_per_img'][0][img_index] = 1 - np.abs(model_i1s_concat[img_index] - human_i1[img_index])\n",
    "            useful_stats[data_root][model_name]['i1_corr_diff_per_img'][1][img_index] = 1 - np.abs(model_i1s_concat[img_index] - marmoset_i1[img_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_upright = True\n",
    "compute_inverted = True\n",
    "compute_reverse_contrast = True \n",
    "\n",
    "# data_root = '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/'\n",
    "# # data_root = '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/'\n",
    "# bio_i1s_list = [human_i1_5rep, marmoset_i1_5rep]\n",
    "# bio_i1s_list = [human_i1_5rep]\n",
    "# bio_i1s_list = [human_i1s_vbsl]\n",
    "# bio_i1s_list = [human_i1s_obj_vbsl151]\n",
    "\n",
    "# i1 corr - upright only \n",
    "for model_name in model_names_list:\n",
    "    # get model i1s\n",
    "    if compute_upright :\n",
    "        model_i1s = useful_stats[data_root][model_name]['i1_5rep'] \n",
    "        model_i1s = subset_upright_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_upright'] = np.zeros((len(bio_i1s_list), 2))\n",
    "        for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "            bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "            bio_i1s = subset_upright_5rep_604(bio_i1s)\n",
    "            print(model_name, bio_index)\n",
    "            i1_corr = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            bio_internal = []\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                print(corr_1, corr_2, corr_3, corr_4, 0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                bio_internal.append(corr_4)\n",
    "\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_upright'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "\n",
    "    if compute_inverted : \n",
    "        model_i1s = useful_stats[data_root][model_name]['i1_5rep']\n",
    "        model_i1s = subset_inverted_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_inverted'] = np.zeros((len(bio_i1s_list), 2))\n",
    "\n",
    "        for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "            bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "            bio_i1s = subset_inverted_5rep_604(bio_i1s)\n",
    "            print(model_name, bio_index)\n",
    "            i1_corr = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            bio_internal = []\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                print(corr_1, corr_2, corr_3, corr_4)\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                bio_internal.append(corr_4)\n",
    "\n",
    "\n",
    "            # print(np.mean(np.array(bio_internal)), np.std(np.array(bio_internal)))\n",
    "    \n",
    "            useful_stats[data_root][model_name]['i1_corr_inverted'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_inverted'][bio_index][1] = np.std(np.array(i1_corr))\n",
    "\n",
    "    if compute_reverse_contrast : \n",
    "        model_i1s = useful_stats[data_root][model_name]['i1_5rep']\n",
    "        model_i1s = subset_reverse_contrast_5rep_604(model_i1s)\n",
    "        useful_stats[data_root][model_name]['i1_corr_reverse_contrast'] = np.zeros((len(bio_i1s_list), 2))\n",
    "        for bio_index, bio_i1s in enumerate(bio_i1s_list):\n",
    "            # get bio i1s\n",
    "            bio_i1s = bio_i1s.squeeze()\n",
    "            #bio_i1s = np.nan_to_num(bio_i1s, nan=4) # for monkey_i1s_3 only # SL\n",
    "            bio_i1s = np.nan_to_num(bio_i1s) # for monkey_i1s_3 only\n",
    "            bio_i1s = subset_reverse_contrast_5rep_604(bio_i1s)\n",
    "            print(model_name, bio_index)\n",
    "            i1_corr = []\n",
    "            half_length = int(model_i1s.shape[1]/2)\n",
    "            bio_internal = []\n",
    "            for rep_index in range(5):\n",
    "                corr_1, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], bio_i1s[rep_index][half_length:])\n",
    "                corr_2, _ = scipy.stats.pearsonr(model_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                corr_3, _ = scipy.stats.pearsonr(model_i1s[rep_index][:half_length], model_i1s[rep_index][half_length:])\n",
    "                corr_4, _ = scipy.stats.pearsonr(bio_i1s[rep_index][half_length:], bio_i1s[rep_index][:half_length])\n",
    "                print(corr_1, corr_2, corr_3, corr_4, 0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                i1_corr.append(0.5*(corr_1+corr_2)/np.sqrt(corr_3*corr_4))\n",
    "                bio_internal.append(corr_4)\n",
    "\n",
    "            # print(np.mean(np.array(bio_internal)), np.std(np.array(bio_internal)))\n",
    "    \n",
    "            useful_stats[data_root][model_name]['i1_corr_reverse_contrast'][bio_index][0] = np.mean(np.array(i1_corr))\n",
    "            useful_stats[data_root][model_name]['i1_corr_reverse_contrast'][bio_index][1] = np.std(np.array(i1_corr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print acc and i1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print acc and i1s\n",
    "# data_root = '../../data/face_data/vbsl_151/'\n",
    "# data_root = '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/'\n",
    "# data_root = '/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/control_exp/objs/'\n",
    "\n",
    "# model_name_list = ['resnet50', 'alexnet', 'vggface',  # baseline\n",
    "#                     'resnet50-SIN', 'resnet50-SIN-IN', 'resnet50-SIN-IN-ft', # stylized imagenet\n",
    "#                     'rn50_preIN_notexture_sizeVar_best', 'rn50_preIN_texture_sizeVar_best', # basel finetuned\n",
    "#                    'rn50_FromScratch_notexture_sizeVar_best', 'rn50_FromScratch_texture_sizeVar_best', # basel FromScratch\n",
    "#                     'rn50_preIN_notexture_sizeVar_2losses', # DepthMap prediction\n",
    "#                    'resnet50-trained-pretrained-vbsl', 'resnet50-trained-scratch-vbsl', 'rn50_vbsl-dist-ft_epoch15'] # vbsl\n",
    "# model_name_list = ['vbsl50k_subset_0.5', 'vbsl50k_subset_0.25', 'vbsl50k_subset_0.1', 'vbsl50k_subset_0.05']\n",
    "# model_name_list = ['Basel_50k_2id',]\n",
    "# model_name_list = []\n",
    "# for i in range(41):\n",
    "#     step = (i+1)*15\n",
    "#     model_name_list.append(f'vbsl50k_step{step}')\n",
    "#     # model_name_list.append(f'vbsl50kobj_step{step}')\n",
    "# model_name_list = ['pixel']\n",
    "# model_name_list = ['resnet50', 'resnet50_layer1'] # SL\n",
    "# model_name_list = [\"resnet50\", \"resnet50_layer1\", \"resnet50_layer2\", \n",
    "#                     \"resnet50_layer3\", \"resnet50_layer4_no_pooling\"]\n",
    "# model_name_list = [\"rn50_preIN_texture_sizeVar_best\", \"rn50_preIN_notexture_sizeVar_best\", \"resnet50-trained-pretrained-vbsl\", \"rn50_vbsl-dist-ft_epoch15\"]\n",
    "\n",
    "acc_list = []\n",
    "acc_std_list = []\n",
    "\n",
    "\n",
    "i1_corr_human_list = []\n",
    "i1_corr_human_list_upright, i1_corr_human_list_inverted, i1_corr_human_list_reverse_contrast = [], [], []\n",
    "\n",
    "i1_corr_std_human_list = []\n",
    "i1_corr_std_human_list_upright, i1_corr_std_human_list_inverted, i1_corr_std_human_list_reverse_contrast = [], [], []\n",
    "\n",
    "i1_corr_AJ_list = []\n",
    "i1_corr_AJ_list_upright, i1_corr_AJ_list_inverted, i1_corr_AJ_list_reverse_contrast = [], [], []\n",
    "\n",
    "i1_corr_std_AJ_list = []\n",
    "i1_corr_std_AJ_list_upright, i1_corr_std_AJ_list_inverted, i1_corr_std_AJ_list_reverse_contrast = [], [], []\n",
    "\n",
    "for model_name in model_names_list:\n",
    "    i1_corr = useful_stats[data_root][model_name]['i1_corr']\n",
    "    i1_corr_upright = useful_stats[data_root][model_name]['i1_corr_upright']\n",
    "    i1_corr_inverted = useful_stats[data_root][model_name]['i1_corr_inverted']\n",
    "    i1_corr_reverse_contrast = useful_stats[data_root][model_name]['i1_corr_reverse_contrast']\n",
    "    print(i1_corr_reverse_contrast)\n",
    "    acc = useful_stats[data_root][model_name]['acc']\n",
    "    acc_list.append(acc[0])\n",
    "    acc_std_list.append(acc[1])\n",
    "    # print stats\n",
    "    print(f\"{model_name}\")\n",
    "    print(\"acc: %.6f%.6f\" % (acc[0],acc[1]))\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr):\n",
    "        print(f\"i1 #{i1_index}: %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list.append(cur_i1[0])\n",
    "            i1_corr_std_human_list.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list.append(cur_i1[1])\n",
    "    # ------------------ SL --------------------------\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr_upright):\n",
    "        print(f\"i1 #{i1_index} (upright): %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list_upright.append(cur_i1[0])\n",
    "            i1_corr_std_human_list_upright.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list_upright.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list_upright.append(cur_i1[1])\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr_inverted):\n",
    "        print(f\"i1 #{i1_index} (inverted): %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list_inverted.append(cur_i1[0])\n",
    "            i1_corr_std_human_list_inverted.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list_inverted.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list_inverted.append(cur_i1[1])\n",
    "    for i1_index, cur_i1 in enumerate(i1_corr_reverse_contrast):\n",
    "        print(f\"i1 #{i1_index} (reverse contrast): %.6f%.6f\" % (cur_i1[0],cur_i1[1]))\n",
    "        if i1_index == 0:\n",
    "            i1_corr_human_list_reverse_contrast.append(cur_i1[0])\n",
    "            i1_corr_std_human_list_reverse_contrast.append(cur_i1[1])\n",
    "        elif i1_index == 1:\n",
    "            i1_corr_AJ_list_reverse_contrast.append(cur_i1[0])\n",
    "            i1_corr_std_AJ_list_reverse_contrast.append(cur_i1[1])\n",
    "    # ------------------------------------------------\n",
    "       \n",
    "    # print subset acc\n",
    "    tmp = useful_stats[data_root][model_name]['acc_per_img'].mean(0)\n",
    "    if is_print_subset:\n",
    "        tmp_group = tmp[:150].reshape(6,25).mean(axis=1)\n",
    "        for subset_id, subset in enumerate(subset_list):\n",
    "            # get acc\n",
    "            print(\"%s acc: %.4f\" % (subset_name_list[subset_id], tmp_group[subset].mean()*100))\n",
    "    print()\n",
    "    # print(f\"{model_name} \\n%.2f/%.2f/%.2f\" % (i1_corr[0][0], i1_corr[1][0], i1_corr[2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('useful_stats_SL_20240724_faceobject_face_obj', 'rb') as f:\n",
    "    useful_stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/AppleMesh09/data/face_data/vbsl_151/']['SL_resnet50_finetune_vbsl_50k_face_obj_seed777_model_best_finetune_vbsl_50k_seed777_model_best_finetune_vbsl_50k_obj_seed777_model_best']['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_stats['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle151_AppleMesh00/vbsle_AppleMesh00_happiness_1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle151_AppleMesh00/vbsle_AppleMesh00_happiness_1', '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle151_AppleMesh00/vbsle_AppleMesh00_happiness_2', '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle151_AppleMesh00/vbsle_AppleMesh00_happiness_4', '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle151_AppleMesh00/vbsle_AppleMesh00_happiness_6', '/mnt/smb/locker/issa-locker/users/Seojin/data/face_data/vbsle151_AppleMesh00/vbsle_AppleMesh00_happiness_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_resnet = []\n",
    "acc_vgg = []\n",
    "acc_alexnet = []\n",
    "acc_obj50k = []\n",
    "acc_face50k = []\n",
    "acc_4way  = []\n",
    "            \n",
    "for dn in dataset_names : \n",
    "    acc_resnet.append(useful_stats[dn]['resnet50']['acc'][0])\n",
    "    acc_vgg.append(useful_stats[dn]['vgg16']['acc'][0])\n",
    "    acc_alexnet.append(useful_stats[dn]['alexnet']['acc'][0])\n",
    "    acc_obj50k.append(useful_stats[dn]['SL_resnet50_finetune_vbsl_50k_obj_seed777_model_best']['acc'][0])\n",
    "    acc_face50k.append(useful_stats[dn]['SL_resnet50_finetune_vbsl_50k_seed77_model_best']['acc'][0])\n",
    "    acc_4way .append(useful_stats[dn]['SL_resnet50_finetune_vbsl_50k_face_obj_all_seed777_model']['acc'][0])\n",
    "\n",
    "task_names = ['happiness_1', 'happiness_2', 'happiness_4','happiness_6','happiness_8']\n",
    "model_names = ['alexnet','vgg16','resnet50',   'obj50k', 'face50k', '4-way']\n",
    "\n",
    "# Combine all accuracies into a list of lists\n",
    "all_accuracies = [acc_alexnet, acc_vgg, acc_resnet, acc_obj50k, acc_face50k, acc_4way]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(11, 11))\n",
    "\n",
    "# Define colors for each model\n",
    "colors = ['lightgray','gray', 'darkslategray',  'green', 'blue', 'darkorange']\n",
    "for i, acc in enumerate(all_accuracies):\n",
    "    plt.plot(task_names, acc, marker='o', linestyle='-', markersize=12,linewidth=3, color=colors[i], label=model_names[i])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Tasks')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracies on Different Tasks')\n",
    "plt.legend(title=\"Models\", loc=\"best\")\n",
    "plt.ylim([0.5, 0.9])\n",
    "plt.xlabel('Tasks', fontsize=20, labelpad=15)          # Set x-axis label font size\n",
    "plt.ylabel('Accuracy', fontsize=20, labelpad=15)       # Set y-axis label font size\n",
    "plt.title('Accuracies on Different Degrees of Happiness', fontsize=25, pad=20)  # Set title font size\n",
    "plt.xticks(fontsize=15, rotation=0)                   # Set x-axis ticks font size\n",
    "plt.yticks([0.5, 0.6, 0.7, 0.8, 0.9], fontsize=15)                   # Set y-axis ticks font size\n",
    "\n",
    "# Adding a legend with a custom font size\n",
    "plt.legend(loc=\"best\", fontsize='xx-large')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from load_model import load_model\n",
    "from rn50_auxiliary_dm import rn50_auxiliary_dm\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom x positions for the tasks (e.g., 0, 1, 3, 5, 7 for uneven spacing)\n",
    "x_positions = [0, 5, 15, 25, 35]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(9, 10))\n",
    "\n",
    "# Define colors for each model\n",
    "colors = ['lightgray', 'gray', 'darkslategray', 'orange', 'green', 'blue']\n",
    "for i, acc in enumerate(all_accuracies):\n",
    "    plt.plot(x_positions, acc, marker='o', linestyle='-', markersize=9, linewidth=2.5, color=colors[i], label=model_names[i])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Tasks')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracies on Different Tasks')\n",
    "plt.legend(title=\"Models\", loc=\"best\")\n",
    "\n",
    "# Set custom x-ticks and labels\n",
    "plt.xticks(x_positions, task_names, fontsize=15, rotation=0)\n",
    "\n",
    "# Set y-axis limits and ticks\n",
    "plt.ylim([0.5, 0.9])\n",
    "plt.yticks([0.5, 0.6, 0.7, 0.8, 0.9], fontsize=15)\n",
    "\n",
    "# Adjust font sizes\n",
    "plt.xlabel('Tasks', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.title('Model Accuracies on Different Tasks', fontsize=23)\n",
    "\n",
    "# Adding a legend with a custom font size\n",
    "plt.legend(title=\"Models\", loc=\"best\", fontsize='xx-large')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = ['happiness_1', 'happiness_2', 'happiness_4','happiness_6','happiness_8']\n",
    "model_names = ['resnet50', 'vgg16', 'alexnet', 'obj 50k', 'face 50k', '4-way']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc - GFR\n",
    "models = [\"resnet50\", \"resnet50-layer1\", \"resnet50-layer2\", \"resnet50-layer3\", \"resnet50-layer4-no-pooling\"]\n",
    "models = [\"finetuned-Basel\", \"finetuned-Basel-NoTexture\", \"finetuned-AppleFaces\", \"finetuned-AppleFaces-dist\"]\n",
    "\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\"]\n",
    "models3 = [\"face50k\", \"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\", \"4-way\"]\n",
    "models = [\"face50k\", \"cat-face50k\", \"cat-obj-face50k\", \"multitask\", \"4-way\"]\n",
    "# models = []\n",
    "\n",
    "# for model_name in model_names_list :\n",
    "#     models.append(model_name.split(\"-\")[-1])\n",
    "\n",
    "plt.figure(figsize=(8, 8))  \n",
    "acc_list = [n / 100 for n in [57.8589, 60.0405, 85.8958]]\n",
    "acc_list = [n / 100 for n in [85.895, 61.1054, 60.2877, 83.2418, 82.7832,  68.6334, 77.0670]]\n",
    "\n",
    "acc_std_list = [n / 100 for n in [2.497, 2.7894, 1.5592]]\n",
    "# acc_std_list = [n / 100 for n in [1.55, 2.9224, 2.7483, 1.8827, 1.6929,  2.5420, 1.8957]]\n",
    "bars = plt.bar(models, acc_list, yerr=acc_std_list, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list):\n",
    "    yval = bar.get_height()\n",
    "    bar.set_color('lightblue')\n",
    "\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "# plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models],rotation=30, fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"accuracy\", fontsize=20)\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.axhline(y=57.8589/100, color='gray', linestyle='--', linewidth=2)\n",
    "# bars[-1].set_color('orange')\n",
    "# bars.set_color('lightblue')\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, accuracy\", fontsize=20)\n",
    "plt.title(\"GFR vbsl151 AppleMesh00-AppleMesh01\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc - GOR\n",
    "models = [\"resnet50\", \"resnet50-layer1\", \"resnet50-layer2\", \"resnet50-layer3\", \"resnet50-layer4-no-pooling\"]\n",
    "models = [\"finetuned-Basel\", \"finetuned-Basel-NoTexture\", \"finetuned-AppleFaces\", \"finetuned-AppleFaces-dist\"]\n",
    "\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\"]\n",
    "models3 = [\"face50k\", \"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]\n",
    "\n",
    "# models = []\n",
    "\n",
    "# for model_name in model_names_list :\n",
    "#     models.append(model_name.split(\"-\")[-1])\n",
    "\n",
    "plt.figure(figsize=(7, 8))  \n",
    "acc_list = [n / 100 for n in [72.5794, 85.6704, 69.7722]]\n",
    "# acc_list = [n / 100 for n in [69.7722, 72.1811, 83.5643, 67.9867, 77.4176, 84.3719, 82.3081]]\n",
    "\n",
    "acc_std_list = [n / 100 for n in [2.2267, 1.4935, 2.2411]]\n",
    "# acc_std_list = [n / 100 for n in [2.24, 2.3768, 1.8118, 2.5082, 2.0191, 1.5362, 1.9147]]\n",
    "bars = plt.bar(models, acc_list, yerr=acc_std_list, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list):\n",
    "    yval = bar.get_height()\n",
    "    bar.set_color(\"lightblue\")\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "# plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models],rotation=30, fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"accuracy\", fontsize=20)\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.axhline(y=72.5794/100, color='gray', linestyle='--', linewidth=2)\n",
    "# bars[-1].set_color('orange')\n",
    "# bars[0].set_color('lightblue')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, accuracy\", fontsize=20)\n",
    "plt.title(\"GOR vbsl151 camel-elephant\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc - AppleMesh03-praneeth]\n",
    "import matplotlib.pyplot as plt\n",
    "models = [\"resnet50\", \"resnet50-layer1\", \"resnet50-layer2\", \"resnet50-layer3\", \"resnet50-layer4-no-pooling\"]\n",
    "models = [\"finetuned-Basel\", \"finetuned-Basel-NoTexture\", \"finetuned-AppleFaces\", \"finetuned-AppleFaces-dist\"]\n",
    "\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\"]\n",
    "models3 = [\"face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\", \"4-way\"]\n",
    "\n",
    "# models = []\n",
    "\n",
    "# for model_name in model_names_list :\n",
    "#     models.append(model_name.split(\"-\")[-1])\n",
    "\n",
    "plt.figure(figsize=(9, 8))  \n",
    "acc_list = [n / 100 for n in [69.7722,77.4176, 84.3719, 82.308,     86.7465]]\n",
    "acc_list = [0.356536, 0.383913,0.427112 ,0.380207, 0.422545]\n",
    "acc_std_list = [0.023619,0.015610,0.023217,0.021730,0.024793]\n",
    "bars = plt.bar(models3, acc_list, yerr=acc_std_list, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list):\n",
    "    bar.set_color('dimgray')\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "# plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models3)), labels=[label.replace('-', '-\\n') for label in models3],rotation=30, fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=20)\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.axhline(y=0.4181, color='gray', linestyle='--', linewidth=2)\n",
    "bars[-1].set_color('orange')\n",
    "bars[-2].set_color('orange')\n",
    "\n",
    "bars[0].set_color('lightblue')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, accuracy\", fontsize=20)\n",
    "plt.title(\"GFR vbsl151 AppleMesh00-AppleMesh01, i1\", fontsize=20)\n",
    "plt.title(\"GOR vbsl151 camel-elephant, i1\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\"]\n",
    "models3 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]# Dummy data for demonstration purposes\n",
    "# Define the position of the bars\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "acc_list = [n / 100 for n in [72.5794,85.6704,69.77]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "acc_list_upright = [val / 100 for val in [75.24,97.57,71.23]]\n",
    "                    # [71.23,97.57,74.38]]\n",
    "acc_list_inverted = [val / 100 for val in [71.79, 83.6 ,70.83]]\n",
    "    # [70.83,83.6,71.2]]\n",
    "acc_list_reverse_contrast = [val / 100 for val in [70.56,75.61, 67.55]]\n",
    "# [67.55,75.61,70.22]]\n",
    "\n",
    "# Plotting each set of bars\n",
    "bars0 = ax.bar(x - width * 1.5, acc_list, width,label='all', color='blue', alpha=1.0, capsize=5)\n",
    "bars1 = ax.bar(x - width * 0.5 , acc_list_upright, width,label='upright', color='blue', alpha=0.65, capsize=5)\n",
    "bars2 = ax.bar(x +  width * 0.5, acc_list_inverted, width,  label='inverted', color='blue', alpha=0.3, capsize=5)\n",
    "bars3 = ax.bar(x + width * 1.5, acc_list_reverse_contrast, width, label='reverse contrast', color='blue', alpha=0.1, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bars in [bars0, bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('models', fontsize=18)\n",
    "ax.set_ylabel('accuracy', fontsize=18)\n",
    "ax.set_title('GOR vbsl151 camel-elephant', fontsize=22)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([label.replace('-', '-\\n') for label in models], rotation=30,fontsize=18)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "ax.legend(fontsize=15, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\"]\n",
    "models3 = [\"face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]\n",
    "# Define the position of the bars\n",
    "x = np.arange(len(models3))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "acc_list = [n / 100 for n in [85.8958, 82.7832, 68.6334, 77.0670]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "acc_list_upright = [val / 100 for val in [98.65\t, 98.3,83.73, 96.9]]\n",
    "                    # [71.23,97.57,74.38]]\n",
    "acc_list_inverted = [val / 100 for val in [76.39, 75.76, \t63.48, \t66.32]]\n",
    "    # [70.83,83.6,71.2]]\n",
    "acc_list_reverse_contrast = [val / 100 for val in [\t82.37,74, \t58.17\t, \t67.79]]\n",
    "# [67.55,75.61,70.22]]\n",
    "\n",
    "# Plotting each set of bars\n",
    "bars0 = ax.bar(x - width * 1.5, acc_list, width,label='all', color='blue', alpha=1.0, capsize=5)\n",
    "bars1 = ax.bar(x - width * 0.5 , acc_list_upright, width,label='upright', color='blue', alpha=0.65, capsize=5)\n",
    "bars2 = ax.bar(x +  width * 0.5, acc_list_inverted, width,  label='inverted', color='blue', alpha=0.3, capsize=5)\n",
    "bars3 = ax.bar(x + width * 1.5, acc_list_reverse_contrast, width, label='reverse contrast', color='blue', alpha=0.1, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bars in [bars0, bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('models', fontsize=18)\n",
    "ax.set_ylabel('accuracy', fontsize=18)\n",
    "ax.set_title('GFR vbsl151 AppleMesh00-AppleMesh01', fontsize=22)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([label.replace('-', '-\\n') for label in models3], rotation=30,fontsize=18)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "ax.legend(fontsize=15, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "\n",
    "acc_list_upright = [val/100 for val in [98.65,65.91]]\n",
    "acc_std_list_upright = []\n",
    "acc_list_inverted = [val/100 for val in [76.39,61.16]]\n",
    "acc_std_list_inverted = []\n",
    "acc_list_reverse_contrast = [val/100 for val in [82.37,52.9]]\n",
    "acc_std_list_reverse_contrast = []\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, acc_list_upright, capsize=5)\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list_upright):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"acc\", fontsize=20)\n",
    "plt.ylim(0.0, 1)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50 (upright only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, acc_list_inverted, capsize=5)\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list_inverted):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "# plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"acc\", fontsize=20)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50 (inverted only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models, acc_list_reverse_contrast, capsize=5)\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list_reverse_contrast):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"acc\", fontsize=20)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, (reverse contrast only)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot i1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\"]\n",
    "models3 = [\"face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]\n",
    "\n",
    "plt.figure(figsize=(7, 8)) \n",
    "i1_corr_human_list = [-0.000972,0.157688, 0.485140]\n",
    "i1_corr_std_human_list = [0.002378, 0.016036, 0.006226]\n",
    "# [0.023619, 0.020221, 0.023948]\n",
    "bars = plt.bar(models, i1_corr_human_list, yerr=i1_corr_std_human_list, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list):\n",
    "    yval = bar.get_height()\n",
    "    bar.set_color('dimgray')\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "#plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=15)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=30, fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.axhline(y=-0.000972, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"GFR vbsl151 AppleMesh00-AppleMesh01, i1\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------- SL -------------------------------------\n",
    "plt.figure(figsize=(7, 8)) \n",
    "i1_corr_human_list = [0.418159,0.398955, 0.356536]\n",
    "i1_corr_std_human_list = [0.021829, 0.020221, 0.023619]\n",
    "# [0.023619, 0.020221, 0.023948]\n",
    "bars = plt.bar(models, i1_corr_human_list, yerr=i1_corr_std_human_list, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list):\n",
    "    yval = bar.get_height()\n",
    "    bar.set_color('dimgray')\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "\n",
    "#plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=15)\n",
    "plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=30, fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.axhline(y=0.418159, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"GOR vbsl151 camel-elephant, i1\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc - AppleMesh03-praneeth\n",
    "models = [\"resnet50\", \"resnet50-layer1\", \"resnet50-layer2\", \"resnet50-layer3\", \"resnet50-layer4-no-pooling\"]\n",
    "models = [\"finetuned-Basel\", \"finetuned-Basel-NoTexture\", \"finetuned-AppleFaces\", \"finetuned-AppleFaces-dist\"]\n",
    "\n",
    "models = [\"resnet\", \"obj50k\", \"face50k\"]\n",
    "models2 = [\"face50k\",\"cat50k\", \"cat-obj50k\", \"cat-face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]\n",
    "models3 = [\"face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]\n",
    "\n",
    "# models = []\n",
    "\n",
    "# for model_name in model_names_list :\n",
    "#     models.append(model_name.split(\"-\")[-1])\n",
    "\n",
    "plt.figure(figsize=(11, 8))  \n",
    "acc_list = [0.485140, 0.004014,0.070360,0.442748,0.517701,0.365679, 0.538343]\n",
    "# acc_list = [0.356536, 0.355510,0.427566,0.304946,0.383913,0.427112,0.380207]\n",
    "acc_std_list = [0.006226, 0.017121 ,0.005082 ,0.013043 ,0.015055 ,0.010541, 0.011796]\n",
    "# acc_std_list = [0.0236190, 0.011726 ,0.017798 ,0.029011 ,0.015610 ,0.023217, 0.021730]\n",
    "\n",
    "\n",
    "\n",
    "bars = plt.bar(models2, acc_list, yerr=acc_std_list, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, acc_list):\n",
    "    yval = bar.get_height()\n",
    "    bar.set_color('dimgray')\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=20)\n",
    "# plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=18)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models2)), labels=[label.replace('-', '-\\n') for label in models2],rotation=30, fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.xlabel(\"model\", fontsize=20)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=20)\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.axhline(y=-0.000972, color='gray', linestyle='--', linewidth=2)\n",
    "bars[-1].set_color('orange')\n",
    "bars[0].set_color('lightblue')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, accuracy\", fontsize=20)\n",
    "plt.title(\"GFR vbsl151 AppleMesh00-AppleMesh01, i1\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SL\n",
    "models3 = [\"face50k\", \"cat-obj-face50k\", \"cat-face-obj50k\", \"multitask\"]\n",
    "\n",
    "i1_corr_human_list_upright = [0.191045, 0.512367, 0.361097, 0.421580]\n",
    "# [0.424810,0.512017,0.347575]\n",
    "i1_corr_std_human_list_upright = [0.472004,0.392035,0.493194]\n",
    "# [0.035555, 0.030237, 0.031485]\n",
    "i1_corr_human_list_inverted = [0.28614,0.250046,0.335397,0.454984]\n",
    "# [0.035555, 0.030237, 0.031485]\n",
    "i1_corr_std_human_list_inverted = [0.015472,0.037951,0.019945]\n",
    "# [0.034771,0.033141, 0.029989]\n",
    "i1_corr_human_list_reverse_contrast = [0.365510, 0.361112  , 0.08786, 0.318961]\n",
    "i1_corr_std_human_list_reverse_contrast = [0.007847, 0.017272, 0.011585]\n",
    "# [0.010393,0.007654,0.014628]\n",
    "\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models3, i1_corr_human_list_upright, yerr=i1_corr_std_human_list_upright, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list_upright):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=15)\n",
    "\n",
    "#plt.xticks(ticks=np.arange(len(models)), labels=[label.replace('-', '-\\n') for label in models], rotation=45, ha='right', fontsize=15)\n",
    "plt.xticks(ticks=np.arange(len(models3)), labels=[label.replace('-', '-\\n') for label in models3], fontsize=18)\n",
    "\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GOR\\nvbsli*151, (upright only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models3, i1_corr_human_list_inverted, yerr=i1_corr_std_human_list_inverted, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list_inverted):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=15)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models3)), labels=[label.replace('-', '-\\n') for label in models3], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GFR\\nvbsli*151, (inverted only)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 8)) \n",
    "\n",
    "bars = plt.bar(models3, i1_corr_human_list_reverse_contrast, yerr=i1_corr_std_human_list_reverse_contrast, capsize=5, color='green')\n",
    "# Add text annotations for each bar\n",
    "for bar, acc in zip(bars, i1_corr_human_list_reverse_contrast):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.6 , yval, f'{acc:.2f}', ha='left', va='bottom', fontsize=15)\n",
    "\n",
    "plt.xticks(ticks=np.arange(len(models3)), labels=[label.replace('-', '-\\n') for label in models3], fontsize=18)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"model\", fontsize=18)\n",
    "# plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"i1\", fontsize=18)\n",
    "plt.ylim(0.0, 1)\n",
    "plt.legend()\n",
    "plt.title(\"ResNet50 from scratch, human i1 corr\", fontsize=20)\n",
    "plt.title(\"Finetuned ResNet50, tested on GFR\\nvbsli*151, (reverse contrast only)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "models = [\"finetuned-AppleFaces50k\", \"finetuned-Object50k\", \"vAppleMesh10lla resnet\"]\n",
    "i1_corr_human_list = [0.485140, 0.517701   , 0.365679, 0.538343]\n",
    "# Define the position of the bars\n",
    "x = np.arange(len(models3))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "\n",
    "# Plotting each set of bars\n",
    "bars0 = ax.bar(x - width * 1.5, i1_corr_human_list, width,label='all', color='green', alpha=1.0, capsize=5)\n",
    "bars1 = ax.bar(x - width * 0.5 , i1_corr_human_list_upright, width,label='upright', color='green', alpha=0.65, capsize=5)\n",
    "bars2 = ax.bar(x +  width * 0.5, i1_corr_human_list_inverted, width,  label='inverted', color='green', alpha=0.3, capsize=5)\n",
    "bars3 = ax.bar(x + width * 1.5, i1_corr_human_list_reverse_contrast, width, label='reverse contrast', color='green', alpha=0.1, capsize=5)\n",
    "\n",
    "# Add text annotations for each bar\n",
    "for bars in [bars0, bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('models', fontsize=18)\n",
    "ax.set_ylabel('i1', fontsize=18)\n",
    "ax.set_title('Finetuned ResNet50, tested on GOR vbsli*151', fontsize=22)\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_xticklabels([label.replace('-', '-\\n') for label in models3], rotation=30,fontsize=18)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "ax.legend(fontsize=15, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot category effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj50k vs cat-obj50k\n",
    "models = ['face50k', 'cat-face50k']\n",
    "tasks = ['GOR 151', 'GFR 151', 'ood AppleMesh03-praneeth', 'ood Basel-texture', 'ood Basel-no texture', 'GOR i1', 'GFR i1']\n",
    "\n",
    "plt.figure(figsize=(13, 8))  \n",
    "acc_list1 = [n/100 for n in [69.7722, 85.8958, 68.0398, 74.0292, 74.9414, 0.356536 * 100, 0.485140 * 100]]\n",
    "acc_list2 = [n/100 for n in [67.9867, 83.2418, 66.9641, 71.5211, 76.2519, 0.304946 * 100, 0.442748* 100]]\n",
    "acc_std_list1 = [n/100 for n in [2.2411, 1.5592, 2.1830, 2.299, 2.11786, 0.023619 * 100, 0.006226 * 100]]\n",
    "acc_std_list2 = [n/100 for n in [2.5082, 1.8827, 1.9066, 2.0418, 1.7854, 0.029011 * 100, 0.013043 * 100]]\n",
    "\n",
    "# Positioning of bars\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(tasks))\n",
    "\n",
    "bars1 = plt.bar(x - bar_width/2, acc_list1, bar_width, yerr=acc_std_list1, capsize=5, label=models[0], color='lightblue')\n",
    "bars2 = plt.bar(x + bar_width/2, acc_list2, bar_width, yerr=acc_std_list2, capsize=5, label=models[1])\n",
    "\n",
    "# change color of the last four bars to grey\n",
    "for bar in bars1[-2:]:\n",
    "    bar.set_color('lightgrey')\n",
    "for bar in bars2[-2:]:\n",
    "    bar.set_color('grey')\n",
    "\n",
    "# add text annotations\n",
    "for bar, acc in zip(bars1, acc_list1):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.5, yval + 0.02, f'{acc:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "for bar, acc in zip(bars2, acc_list2):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.5, yval + 0.02, f'{acc:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.xticks(ticks=x, labels=[label.replace('-', '-\\n') for label in tasks], rotation=30, fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"task\", fontsize=20)\n",
    "plt.ylabel(\"accuracy\", fontsize=20)\n",
    "plt.ylim(0,1)\n",
    "plt.legend(models, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=15)\n",
    "\n",
    "# add a second y-axis\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.set_ylabel(\"i1\", fontsize=20)\n",
    "ax2.yaxis.set_ticks([])\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "# plt.axhline(y=-0.000972, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "# ax2.legend(models, bbox_to_anchor=(1.05, 1), loc='upper right', fontsize=15)\n",
    "\n",
    "plt.title(\"Comparing models w/ & w/o category training\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj50k vs cat-obj50k\n",
    "models = ['face-obj50k', 'cat-face-obj50k']\n",
    "tasks = ['GOR 151', 'GFR 151', 'ood AppleMesh03-praneeth', 'ood Basel-texture', 'ood Basel-no texture', 'GOR i1', 'GFR i1']\n",
    "\n",
    "plt.figure(figsize=(13, 8))  \n",
    "acc_list1 = [n/100 for n in [87.1642, 68.0978 ,59.0477, 69.2275,\t73.1752 ,0.450757 *100,0.239189*100]]\n",
    "acc_list2 = [n/100 for n in [84.3719, 68.6334 ,57.9432, 71.0934,\t69.3325 ,0.427112*100, 0.244190*100]]\n",
    "acc_std_list1 = [n/100 for n in [ 1.6079,  2.4525 , 2.3252,  2.7898 , 2.0581 , 0.022016*100  ,0.008785*100]]\n",
    "acc_std_list2 = [n/100 for n in [ 1.5362  ,2.5420,  2.4381,  2.2071 , 2.358 , 0.023217*100  ,0.016437*100]]\n",
    "\n",
    "# Positioning of bars\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(tasks))\n",
    "\n",
    "bars1 = plt.bar(x - bar_width/2, acc_list1, bar_width, yerr=acc_std_list1, capsize=5, label=models[0], color='lightblue')\n",
    "bars2 = plt.bar(x + bar_width/2, acc_list2, bar_width, yerr=acc_std_list2, capsize=5, label=models[1])\n",
    "\n",
    "# change color of the last four bars to grey\n",
    "for bar in bars1[-2:]:\n",
    "    bar.set_color('lightgrey')\n",
    "for bar in bars2[-2:]:\n",
    "    bar.set_color('grey')\n",
    "\n",
    "# add text annotations\n",
    "for bar, acc in zip(bars1, acc_list1):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.5, yval + 0.02, f'{acc:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "for bar, acc in zip(bars2, acc_list2):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() * 0.5, yval + 0.02, f'{acc:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.xticks(ticks=x, labels=[label.replace('-', '-\\n') for label in tasks], rotation=30, fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"task\", fontsize=20)\n",
    "plt.ylabel(\"accuracy\", fontsize=20)\n",
    "plt.ylim(0,1)\n",
    "plt.legend(models, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=15)\n",
    "\n",
    "# add a second y-axis\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.set_ylabel(\"i1\", fontsize=20)\n",
    "ax2.yaxis.set_ticks([])\n",
    "\n",
    "# Set the range of y-axis from 0 to 1\n",
    "# plt.axhline(y=-0.000972, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "# ax2.legend(models, bbox_to_anchor=(1.05, 1), loc='upper right', fontsize=15)\n",
    "\n",
    "plt.title(\"Comparing models w/ & w/o category training\", fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLC]",
   "language": "python",
   "name": "conda-env-DLC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
